{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.simpleprofiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "# Contains code from:\n",
    "# fastai - Apache License 2.0 - Copyright (c) 2023 fast.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Profiler\n",
    "> Callbacks which add a simple profiler to fastai. Inspired by PyTorch Lightning's SimpleProfiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import locale\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from packaging.version import parse\n",
    "\n",
    "from fastcore.foundation import docs\n",
    "from fastcore.basics import mk_class, noop, in_notebook\n",
    "\n",
    "import fastai\n",
    "from fastai.learner import Learner, Recorder\n",
    "from fastai.callback.core import *\n",
    "\n",
    "from fastxtend.imports import *\n",
    "from fastxtend.utils import scale_time\n",
    "\n",
    "if in_notebook():\n",
    "    from IPython.display import display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since simple profiler changes the fastai data loading loop, it is not imported by any of the fastxtend all imports. It needs to be imported seperately:\n",
    "\n",
    "```python\n",
    "from fastxtend.callback import simpleprofiler\n",
    "```\n",
    "\n",
    "::: {.callout-note}\n",
    "Simple Profiler is currently untested on distributed training.\n",
    ":::\n",
    "\n",
    "Jump to usage [examples](#examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "Fastai callbacks do not have an event which is called directly before drawing a batch. Simple Profiler adds a new callback event called `before_draw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Simple Profiler imported, a callback can implement actions on the following events:\n",
    "\n",
    "- `after_create`: called after the `Learner` is created\n",
    "- `before_fit`: called before starting training or inference, ideal for initial setup.\n",
    "- `before_epoch`: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch.\n",
    "- `before_train`: called at the beginning of the training part of an epoch.\n",
    "- `before_draw`: called at the beginning of each batch, just before drawing said batch. \n",
    "- `before_batch`: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).\n",
    "- `after_pred`: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.\n",
    "- `after_loss`: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).\n",
    "- `before_backward`: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)\n",
    "- `before_step`: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).\n",
    "- `after_step`: called after the step and before the gradients are zeroed.\n",
    "- `after_batch`: called at the end of a batch, for any clean-up before the next one.\n",
    "- `after_train`: called at the end of the training phase of an epoch.\n",
    "- `before_validate`: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.\n",
    "- `after_validate`: called at the end of the validation part of an epoch.\n",
    "- `after_epoch`: called at the end of an epoch, for any clean-up before the next one.\n",
    "- `after_fit`: called at the end of training, for final clean-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement before_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add `before_draw` as a callable event, first it needs to be added to both the `_inner_loop` and `_events` lists of fastai events (fastai 2.7.0 adds new backward events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "if parse(fastai.__version__) >= parse('2.7.0'):\n",
    "    _inner_loop = \"before_draw before_batch after_pred after_loss before_backward after_cancel_backward after_backward before_step after_step after_cancel_batch after_batch\".split()\n",
    "else:\n",
    "    _inner_loop = \"before_draw before_batch after_pred after_loss before_backward before_step after_step after_cancel_batch after_batch\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "if parse(fastai.__version__) >= parse('2.7.0'):\n",
    "    _events = L.split('after_create before_fit before_epoch before_train before_draw before_batch after_pred after_loss \\\n",
    "        before_backward after_cancel_backward after_backward before_step after_cancel_step after_step \\\n",
    "        after_cancel_batch after_batch after_cancel_train after_train before_validate after_cancel_validate \\\n",
    "        after_validate after_cancel_epoch after_epoch after_cancel_fit after_fit')\n",
    "else:\n",
    "    _events = L.split('after_create before_fit before_epoch before_train before_draw before_batch after_pred after_loss \\\n",
    "        before_backward before_step after_cancel_step after_step after_cancel_batch after_batch after_cancel_train \\\n",
    "        after_train before_validate after_cancel_validate after_validate after_cancel_epoch \\\n",
    "        after_epoch after_cancel_fit after_fit')\n",
    "\n",
    "mk_class('event', **_events.map_dict(),\n",
    "         doc=\"All possible events as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, `Callback` needs to be modified to be aware of the new event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "@patch\n",
    "def __call__(self:Callback, event_name):\n",
    "    \"Call `self.{event_name}` if it's defined\"\n",
    "    _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n",
    "            (self.run_valid and not getattr(self, 'training', False)))\n",
    "    res = None\n",
    "    if self.run and _run:\n",
    "        try: res = getattr(self, event_name, noop)()\n",
    "        except (CancelBatchException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n",
    "        except Exception as e:\n",
    "            e.args = [f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}']\n",
    "            raise\n",
    "    if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `Learner._call_one` needs to patch to be aware of the `before_draw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "@patch\n",
    "def _call_one(self:Learner, event_name):\n",
    "    if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n",
    "    for cb in self.cbs.sorted('order'): cb(event_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `Learner.all_batches` can be modified to call `before_draw` when iterating through a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "@patch\n",
    "def all_batches(self:Learner):\n",
    "    self.n_iter = len(self.dl)\n",
    "    if hasattr(self, 'simple_profiler'):\n",
    "        self.it = iter(self.dl)\n",
    "        for i in range(self.n_iter):\n",
    "            self(\"before_draw\")\n",
    "            self.one_batch(i, next(self.it))\n",
    "        del(self.it)\n",
    "    else:\n",
    "        for o in enumerate(self.dl): self.one_batch(*o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While testing hasn't shown any negative side effects of this approach, `all_batches` only uses the new batch drawing implementation if `SimpleProfilerCallback` is in the list of callbacks, and reverts back to the original method if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_loop = ['Start Fit', 'before_fit', 'Start Epoch Loop', 'before_epoch', 'Start Train', 'before_train',\n",
    "         'Start Batch Loop', 'before_draw', 'before_batch', 'after_pred', 'after_loss', 'before_backward',\n",
    "         'before_step', 'after_step', 'after_cancel_batch', 'after_batch','End Batch Loop', 'End Train',\n",
    "         'after_cancel_train', 'after_train', 'Start Valid', 'before_validate', 'Start Batch Loop',\n",
    "         '**CBs same as train batch**', 'End Batch Loop', 'End Valid', 'after_cancel_validate',\n",
    "         'after_validate', 'End Epoch Loop', 'after_cancel_epoch', 'after_epoch', 'End Fit',\n",
    "         'after_cancel_fit', 'after_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@patch\n",
    "def show_training_loop(self:Learner):\n",
    "    indent = 0\n",
    "    for s in _loop:\n",
    "        if s.startswith('Start'): print(f'{\" \"*indent}{s}'); indent += 2\n",
    "        elif s.startswith('End'): indent -= 2; print(f'{\" \"*indent}{s}')\n",
    "        else: print(f'{\" \"*indent} - {s:15}:', self.ordered_cbs(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Profiler Callbacks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_phase = ['fit', 'epoch', 'train', 'valid']\n",
    "_epoch = ['train', 'valid']\n",
    "_train = ['draw', 'batch', 'forward', 'loss', 'backward', 'opt_step', 'zero_grad']\n",
    "_valid = ['draw', 'batch', 'predict', 'loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleProfilerPostCallback(Callback):\n",
    "    \"Pair with `SimpleProfilerCallback` to profile training performance. Removes itself after training is over.\"\n",
    "    order,remove_on_fetch = Recorder.order-1,True\n",
    "    def __init__(self, samples_per_second=True):\n",
    "        store_attr()\n",
    "        self._phase,self._train,self._valid = _phase,_train,_valid\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.profiler = self.learn.simple_profiler\n",
    "        self.has_logger = self.profiler.has_logger\n",
    "        self.n_train_batches = len(self.dls.train)\n",
    "        self.n_valid_batches = len(self.dls.valid)\n",
    "\n",
    "    def after_train(self):\n",
    "        self.profiler._raw_values['train'].append(time.perf_counter() - self.profiler._train_start)\n",
    "\n",
    "    def after_validate(self):\n",
    "        self.profiler._raw_values['valid'].append(time.perf_counter() - self.profiler._validate_start)\n",
    "\n",
    "    def after_pred(self):\n",
    "        if self.training:\n",
    "            self.profiler._raw_values['train_forward'].append(time.perf_counter() - self.profiler._train_batch_start)\n",
    "        else:\n",
    "            self.profiler._raw_values['valid_predict'].append(time.perf_counter() - self.profiler._valid_batch_start)\n",
    "\n",
    "        if self.training:\n",
    "            self.profiler._train_loss_start = time.perf_counter()\n",
    "        else:\n",
    "            self.profiler._valid_loss_start = time.perf_counter()\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.training:\n",
    "            self.profiler._raw_values['train_loss'].append(time.perf_counter() - self.profiler._train_loss_start)\n",
    "        else:\n",
    "            self.profiler._raw_values['valid_loss'].append(time.perf_counter() - self.profiler._valid_loss_start)\n",
    "\n",
    "    def after_step(self):\n",
    "        self.profiler._raw_values['train_opt_step'].append(time.perf_counter() - self.profiler._step_start)\n",
    "        self.profiler._zero_start = time.perf_counter()\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training:\n",
    "            self.profiler._raw_values['train_batch'].append(time.perf_counter() - self.profiler._train_batch_start)\n",
    "            if self.samples_per_second:\n",
    "                self.profiler._raw_values['train_bs'].append(find_bs(self.learn.xb))\n",
    "                if self.has_logger:\n",
    "                    self.profiler._log_after_batch()\n",
    "        else:\n",
    "            self.profiler._raw_values['valid_batch'].append(time.perf_counter() - self.profiler._valid_batch_start)\n",
    "            if self.samples_per_second:\n",
    "                self.profiler._raw_values['valid_bs'].append(find_bs(self.learn.xb))\n",
    "\n",
    "    def after_epoch(self):\n",
    "        self.profiler._raw_values['epoch'].append(time.perf_counter() - self.profiler._epoch_start)\n",
    "\n",
    "    def after_fit(self):\n",
    "        self.profiler._raw_values['fit'].append(time.perf_counter() - self.profiler._fit_start)\n",
    "        self.profiler._generate_report()\n",
    "        if self.has_logger: self.profiler._log_after_fit()\n",
    "        if not hasattr(self.learn, 'lr_finder'):\n",
    "            self.profiler._display_report()\n",
    "            self.learn.remove_cbs([SimpleProfilerCallback, SimpleProfilerPostCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleProfilerCallback(Callback):\n",
    "    \"\"\"\n",
    "    Adds a simple profiler to the fastai `Learner`. Optionally showing formatted report or saving unformatted results as csv.\n",
    "\n",
    "    Pair with SimpleProfilerPostCallback to profile training performance.\n",
    "\n",
    "    Post fit, access report & results via `Learner.simple_profile_report` & `Learner.simple_profile_results`.\n",
    "    \"\"\"\n",
    "    order,remove_on_fetch = TrainEvalCallback.order+1,True\n",
    "    def __init__(self,\n",
    "        show_report=True, # Display formatted report post profile\n",
    "        plain=False, # For Jupyter Notebooks, display plain report\n",
    "        markdown=False, # Display markdown formatted report\n",
    "        save_csv=False,  # Save raw results to csv\n",
    "        csv_name='simple_profile.csv', # CSV save location\n",
    "        logger_callback='wandb' # Log report and samples/second to `logger_callback` using `Callback.name`\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.csv_name = Path(csv_name)\n",
    "        self._phase,self._train,self._valid = _phase,_train,_valid\n",
    "        self._log_after_batch = getattr(self, f'_{self.logger_callback}_log_after_batch', noop)\n",
    "        self._log_after_fit   = getattr(self, f'_{self.logger_callback}_log_after_fit', noop)\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.has_logger = hasattr(self.learn, self.logger_callback) and not hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\")\n",
    "        self._raw_values = dict()\n",
    "        for p in _phase:\n",
    "            self._raw_values[p] = []\n",
    "        for p in _epoch:\n",
    "            for a in getattr(self, f'_{p}'):\n",
    "                self._raw_values[f'{p}_{a}'] = []\n",
    "            self._raw_values[f'{p}_bs'] = []\n",
    "\n",
    "        self._fit_start = time.perf_counter()\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self._epoch_start = time.perf_counter()\n",
    "\n",
    "    def before_train(self):\n",
    "        self._train_start = time.perf_counter()\n",
    "\n",
    "    def before_validate(self):\n",
    "        self._validate_start = time.perf_counter()\n",
    "\n",
    "    def before_draw(self):\n",
    "        if self.training:\n",
    "            self._train_draw_start = time.perf_counter()\n",
    "        else:\n",
    "            self._valid_draw_start = time.perf_counter()\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.training:\n",
    "            self._raw_values['train_draw'].append(time.perf_counter() - self._train_draw_start)\n",
    "        else:\n",
    "            self._raw_values['valid_draw'].append(time.perf_counter() - self._valid_draw_start)\n",
    "\n",
    "        if self.training:\n",
    "            self._train_batch_start = time.perf_counter()\n",
    "        else:\n",
    "            self._valid_batch_start = time.perf_counter()\n",
    "\n",
    "    def before_backward(self):\n",
    "        self._backward_start = time.perf_counter()\n",
    "\n",
    "    def before_step(self):\n",
    "        self._raw_values['train_backward'].append(time.perf_counter() - self._backward_start)\n",
    "        self._step_start = time.perf_counter()\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training: self._raw_values['train_zero_grad'].append(time.perf_counter() - self._zero_start)\n",
    "\n",
    "    def _train_samples_per_second(self, action):\n",
    "        if action =='draw':\n",
    "            bs = self._raw_values['train_bs'][-1]\n",
    "            batch = self._raw_values['train_batch'][-1]\n",
    "            return bs/(batch+self._raw_values[f'train_draw'][-1]) - bs/batch\n",
    "        else:\n",
    "            return self._raw_values[f'train_bs'][-1]/self._raw_values[f'train_{action}'][-1]\n",
    "\n",
    "    def _generate_report(self):\n",
    "        total_time = self._raw_values['fit'][0]\n",
    "        self.report = pd.DataFrame(columns=['Phase', 'Action', 'Step', 'Mean Duration', 'Duration Std Dev',\n",
    "                                            'Number of Calls', 'Samples/Second', 'Total Time', 'Percent of Total'])\n",
    "\n",
    "        for p in _phase:\n",
    "            if p == 'fit':\n",
    "                self._append_to_df(['fit', p, p, 0, 0, 1, '-', total_time, f'{self._calc_percent(total_time):.0%}'])\n",
    "            else:\n",
    "                if p in _epoch:\n",
    "                    self._append_to_df(self._create_overview_row('fit', 'epoch', p, self._raw_values[p], np.array(self._raw_values[f'{p}_bs'])))\n",
    "                else:\n",
    "                    self._append_to_df(self._create_overview_row('fit', p, p, self._raw_values[p], None))\n",
    "\n",
    "        for p in _epoch:\n",
    "            bs = np.array(self._raw_values[f'{p}_bs'])\n",
    "            for i, s in enumerate(getattr(self, f'_{p}')):\n",
    "                if s in ['draw', 'batch']: a = s\n",
    "                self._append_to_df(self._create_detail_row(p, a, s, self._raw_values[f'{p}_{s}'], bs if s in _train else None))\n",
    "\n",
    "        self.learn.simple_profile_results = self.report.copy()\n",
    "        for c in ['Mean Duration', 'Duration Std Dev', 'Total Time']:\n",
    "            self.report[c] = self.report[c].apply(scale_time)\n",
    "        self.report[['Phase', 'Action']] = self.report[['Phase', 'Action']].where(~self.report[['Phase', 'Action']].duplicated(), '')\n",
    "        self.report['Phase']  = self.report['Phase'].where(~self.report['Phase'].duplicated(), '')\n",
    "        self.report['Step']   = self.report['Step'].where(self.report['Step'] != self.report['Action']).fillna('')\n",
    "        self.report['Action'] = self.report['Action'].where(self.report['Phase'] != self.report['Action']).fillna('')\n",
    "\n",
    "        self.learn.simple_profile_report = self.report\n",
    "\n",
    "    def _display_report(self):\n",
    "        if self.show_report:\n",
    "            if self.markdown: print(self.report.to_markdown(index=False))\n",
    "            else:\n",
    "                if in_notebook() and not self.plain:\n",
    "                    with pd.option_context('display.max_rows', len(self.report.index)):\n",
    "                        s = self.report.style.set_caption(\"Simple Profiler Results\").hide_index()\n",
    "                        display(s)\n",
    "                else:\n",
    "                    print('Simple Profiler Results')\n",
    "                    print(self.report.to_string(index=False))\n",
    "\n",
    "        if self.save_csv:\n",
    "            self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            self.learn.simple_profile_results.to_csv(self.path/self.csv_name, index=False)\n",
    "\n",
    "    def _append_to_df(self, row):\n",
    "        self.report.loc[len(self.report.index)] = row\n",
    "\n",
    "    def _calc_percent(self, time):\n",
    "        return time / self._raw_values['fit'][0]\n",
    "\n",
    "    def _create_overview_row(self, phase, action, step, input, bs=None):\n",
    "        if bs is not None:\n",
    "            draw = np.array(self._raw_values[f'{step}_draw'])\n",
    "            batch = np.array(self._raw_values[f'{step}_batch'])\n",
    "            sam_per_sec = f'{int(np.around(np.mean(bs/(draw+batch)))):,d}'\n",
    "        else:\n",
    "            sam_per_sec = '-'\n",
    "        return [phase, action, step, np.mean(input), np.std(input), len(input), sam_per_sec,\n",
    "                np.sum(input), f'{self._calc_percent(np.sum(input)):.0%}']\n",
    "\n",
    "    def _create_detail_row(self, phase, action, step, input, bs=None):\n",
    "        if bs is None or step=='zero_grad': sam_per_sec = '-'\n",
    "        elif action=='draw':\n",
    "            batch = np.array(self._raw_values[f'{phase}_batch'])\n",
    "            sam_per_sec = f'{int(np.around(np.mean(bs/(np.array(input)+batch) - bs/batch))):,d}'\n",
    "        else:\n",
    "            sam_per_sec = f'{int(np.around(np.mean(bs/np.array(input)))):,d}'\n",
    "        return [phase, action, step, np.mean(input), np.std(input), len(input), sam_per_sec,\n",
    "                np.sum(input), f'{self._calc_percent(np.sum(input)):.0%}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Method -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def profile(self:Learner,\n",
    "        show_report=True, # Display formatted report post profile\n",
    "        plain=False, # For Jupyter Notebooks, display plain report\n",
    "        markdown=False, # Display markdown formatted report\n",
    "        save_csv=False,  # Save raw results to csv\n",
    "        csv_name='simple_profile.csv', # CSV save location\n",
    "        samples_per_second=True, # Log samples/second for all actions & steps\n",
    "        logger_callback='wandb' # Log report and samples/second to `logger_callback` using `Callback.name`\n",
    "    ):\n",
    "    \"Run Simple Profiler when training. Simple Profiler removes itself when finished.\"\n",
    "    self.add_cbs([SimpleProfilerCallback(show_report, plain, markdown, save_csv, csv_name, logger_callback),\n",
    "                  SimpleProfilerPostCallback(samples_per_second)])\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Simple Profiler report contains the following items divided in three Phases (Fit, Train, & Valid)\n",
    "\n",
    "Fit:\n",
    "\n",
    "- `fit`:  total time fitting the model takes.\n",
    "- `epoch`: duration of both training and validation epochs. Often epoch total time is the same amount of elapsed time as fit.\n",
    "- `train`: duration of each training epoch.\n",
    "- `valid`: duration of each validation epoch.\n",
    "\n",
    "Train:\n",
    "\n",
    "- `draw`: time spent waiting for a batch to be drawn. Measured from `before_draw` to `before_batch`. Ideally this value should be as close to zero as possible. \n",
    "- `batch`: total duration of all batch steps except drawing the batch. Measured from `before_batch` to `after_batch`.\n",
    "- `forward`: duration of the forward pass and any additional batch modifications. Measured from `before_batch` to `after_pred`.\n",
    "- `loss`: duration of calculating loss. Measured from `after_pred` to `after_loss`.\n",
    "- `backward`: duration of the backward pass. Measured from `before_backward` to `before_step`.\n",
    "- `opt_step`: duration of the optimizer step. Measured from `before_step` to `after_step`.\n",
    "- `zero_grad`: duration of the zero_grad step. Measured from `after_step` to `after_batch`.\n",
    "\n",
    "Valid:\n",
    "\n",
    "- `draw`: time spent waiting for a batch to be drawn. Measured from `before_draw` to `before_batch`. Ideally this value should be as close to zero as possible. \n",
    "- `batch`: total duration of all batch steps except drawing the batch. Measured from `before_batch` to `after_batch`.\n",
    "- `predict`: duration of the prediction pass and any additional batch modifications. Measured from `before_batch` to `after_pred`.\n",
    "- `loss`: duration of calculating loss. Measured from `after_pred` to `after_loss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "The example is trained on Imagenette with an image size of 256 and batch size of 64 on a SageMaker Studio Lab T4 four CPU instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.learner import Learner\n",
    "from fastai.vision.augment import Resize\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models.xresnet import xresnet18, xse_resnet50\n",
    "from fastxtend.callback.channelslast import *\n",
    "from fastxtend.metrics import *\n",
    "from fastxtend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                    splitter=GrandparentSplitter(valid_name='val'),\n",
    "                    get_items=get_image_files, get_y=parent_label,\n",
    "                    item_tfms=Resize(256),\n",
    "                    batch_tfms=[Normalize.from_stats(*imagenet_stats)])\n",
    "dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.526267</td>\n",
       "      <td>1.588631</td>\n",
       "      <td>0.509554</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.044853</td>\n",
       "      <td>0.949273</td>\n",
       "      <td>0.705732</td>\n",
       "      <td>02:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9b9f4_\">\n",
       "  <caption>Simple Profiler Results</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Phase</th>\n",
       "      <th class=\"col_heading level0 col1\" >Action</th>\n",
       "      <th class=\"col_heading level0 col2\" >Step</th>\n",
       "      <th class=\"col_heading level0 col3\" >Mean Duration</th>\n",
       "      <th class=\"col_heading level0 col4\" >Duration Std Dev</th>\n",
       "      <th class=\"col_heading level0 col5\" >Number of Calls</th>\n",
       "      <th class=\"col_heading level0 col6\" >Samples/Second</th>\n",
       "      <th class=\"col_heading level0 col7\" >Total Time</th>\n",
       "      <th class=\"col_heading level0 col8\" >Percent of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row0_col0\" class=\"data row0 col0\" >fit</td>\n",
       "      <td id=\"T_9b9f4_row0_col1\" class=\"data row0 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "      <td id=\"T_9b9f4_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_9b9f4_row0_col4\" class=\"data row0 col4\" >-</td>\n",
       "      <td id=\"T_9b9f4_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_9b9f4_row0_col6\" class=\"data row0 col6\" >-</td>\n",
       "      <td id=\"T_9b9f4_row0_col7\" class=\"data row0 col7\" >330.2 s</td>\n",
       "      <td id=\"T_9b9f4_row0_col8\" class=\"data row0 col8\" >100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row1_col0\" class=\"data row1 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row1_col1\" class=\"data row1 col1\" >epoch</td>\n",
       "      <td id=\"T_9b9f4_row1_col2\" class=\"data row1 col2\" ></td>\n",
       "      <td id=\"T_9b9f4_row1_col3\" class=\"data row1 col3\" >165.1 s</td>\n",
       "      <td id=\"T_9b9f4_row1_col4\" class=\"data row1 col4\" >1.160 s</td>\n",
       "      <td id=\"T_9b9f4_row1_col5\" class=\"data row1 col5\" >2</td>\n",
       "      <td id=\"T_9b9f4_row1_col6\" class=\"data row1 col6\" >-</td>\n",
       "      <td id=\"T_9b9f4_row1_col7\" class=\"data row1 col7\" >330.2 s</td>\n",
       "      <td id=\"T_9b9f4_row1_col8\" class=\"data row1 col8\" >100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row2_col1\" class=\"data row2 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row2_col2\" class=\"data row2 col2\" >train</td>\n",
       "      <td id=\"T_9b9f4_row2_col3\" class=\"data row2 col3\" >148.6 s</td>\n",
       "      <td id=\"T_9b9f4_row2_col4\" class=\"data row2 col4\" >1.113 s</td>\n",
       "      <td id=\"T_9b9f4_row2_col5\" class=\"data row2 col5\" >2</td>\n",
       "      <td id=\"T_9b9f4_row2_col6\" class=\"data row2 col6\" >66</td>\n",
       "      <td id=\"T_9b9f4_row2_col7\" class=\"data row2 col7\" >297.1 s</td>\n",
       "      <td id=\"T_9b9f4_row2_col8\" class=\"data row2 col8\" >90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row3_col0\" class=\"data row3 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row3_col2\" class=\"data row3 col2\" >valid</td>\n",
       "      <td id=\"T_9b9f4_row3_col3\" class=\"data row3 col3\" >16.56 s</td>\n",
       "      <td id=\"T_9b9f4_row3_col4\" class=\"data row3 col4\" >47.87ms</td>\n",
       "      <td id=\"T_9b9f4_row3_col5\" class=\"data row3 col5\" >2</td>\n",
       "      <td id=\"T_9b9f4_row3_col6\" class=\"data row3 col6\" >3,019</td>\n",
       "      <td id=\"T_9b9f4_row3_col7\" class=\"data row3 col7\" >33.11 s</td>\n",
       "      <td id=\"T_9b9f4_row3_col8\" class=\"data row3 col8\" >10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row4_col0\" class=\"data row4 col0\" >train</td>\n",
       "      <td id=\"T_9b9f4_row4_col1\" class=\"data row4 col1\" >draw</td>\n",
       "      <td id=\"T_9b9f4_row4_col2\" class=\"data row4 col2\" ></td>\n",
       "      <td id=\"T_9b9f4_row4_col3\" class=\"data row4 col3\" >7.803ms</td>\n",
       "      <td id=\"T_9b9f4_row4_col4\" class=\"data row4 col4\" >54.23ms</td>\n",
       "      <td id=\"T_9b9f4_row4_col5\" class=\"data row4 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_9b9f4_row4_col7\" class=\"data row4 col7\" >2.294 s</td>\n",
       "      <td id=\"T_9b9f4_row4_col8\" class=\"data row4 col8\" >1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row5_col0\" class=\"data row5 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row5_col1\" class=\"data row5 col1\" >batch</td>\n",
       "      <td id=\"T_9b9f4_row5_col2\" class=\"data row5 col2\" ></td>\n",
       "      <td id=\"T_9b9f4_row5_col3\" class=\"data row5 col3\" >967.9ms</td>\n",
       "      <td id=\"T_9b9f4_row5_col4\" class=\"data row5 col4\" >10.47ms</td>\n",
       "      <td id=\"T_9b9f4_row5_col5\" class=\"data row5 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row5_col6\" class=\"data row5 col6\" >66</td>\n",
       "      <td id=\"T_9b9f4_row5_col7\" class=\"data row5 col7\" >284.6 s</td>\n",
       "      <td id=\"T_9b9f4_row5_col8\" class=\"data row5 col8\" >86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row6_col0\" class=\"data row6 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row6_col1\" class=\"data row6 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row6_col2\" class=\"data row6 col2\" >forward</td>\n",
       "      <td id=\"T_9b9f4_row6_col3\" class=\"data row6 col3\" >21.23ms</td>\n",
       "      <td id=\"T_9b9f4_row6_col4\" class=\"data row6 col4\" >19.30ms</td>\n",
       "      <td id=\"T_9b9f4_row6_col5\" class=\"data row6 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row6_col6\" class=\"data row6 col6\" >3,290</td>\n",
       "      <td id=\"T_9b9f4_row6_col7\" class=\"data row6 col7\" >6.242 s</td>\n",
       "      <td id=\"T_9b9f4_row6_col8\" class=\"data row6 col8\" >2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row7_col0\" class=\"data row7 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row7_col1\" class=\"data row7 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row7_col2\" class=\"data row7 col2\" >loss</td>\n",
       "      <td id=\"T_9b9f4_row7_col3\" class=\"data row7 col3\" >974.6µs</td>\n",
       "      <td id=\"T_9b9f4_row7_col4\" class=\"data row7 col4\" >204.6µs</td>\n",
       "      <td id=\"T_9b9f4_row7_col5\" class=\"data row7 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row7_col6\" class=\"data row7 col6\" >68,140</td>\n",
       "      <td id=\"T_9b9f4_row7_col7\" class=\"data row7 col7\" >286.5ms</td>\n",
       "      <td id=\"T_9b9f4_row7_col8\" class=\"data row7 col8\" >0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row8_col0\" class=\"data row8 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row8_col1\" class=\"data row8 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row8_col2\" class=\"data row8 col2\" >backward</td>\n",
       "      <td id=\"T_9b9f4_row8_col3\" class=\"data row8 col3\" >387.2ms</td>\n",
       "      <td id=\"T_9b9f4_row8_col4\" class=\"data row8 col4\" >18.61ms</td>\n",
       "      <td id=\"T_9b9f4_row8_col5\" class=\"data row8 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row8_col6\" class=\"data row8 col6\" >167</td>\n",
       "      <td id=\"T_9b9f4_row8_col7\" class=\"data row8 col7\" >113.8 s</td>\n",
       "      <td id=\"T_9b9f4_row8_col8\" class=\"data row8 col8\" >34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row9_col0\" class=\"data row9 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row9_col1\" class=\"data row9 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row9_col2\" class=\"data row9 col2\" >opt_step</td>\n",
       "      <td id=\"T_9b9f4_row9_col3\" class=\"data row9 col3\" >556.4ms</td>\n",
       "      <td id=\"T_9b9f4_row9_col4\" class=\"data row9 col4\" >6.388ms</td>\n",
       "      <td id=\"T_9b9f4_row9_col5\" class=\"data row9 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row9_col6\" class=\"data row9 col6\" >115</td>\n",
       "      <td id=\"T_9b9f4_row9_col7\" class=\"data row9 col7\" >163.6 s</td>\n",
       "      <td id=\"T_9b9f4_row9_col8\" class=\"data row9 col8\" >50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row10_col0\" class=\"data row10 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row10_col1\" class=\"data row10 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row10_col2\" class=\"data row10 col2\" >zero_grad</td>\n",
       "      <td id=\"T_9b9f4_row10_col3\" class=\"data row10 col3\" >1.968ms</td>\n",
       "      <td id=\"T_9b9f4_row10_col4\" class=\"data row10 col4\" >122.2µs</td>\n",
       "      <td id=\"T_9b9f4_row10_col5\" class=\"data row10 col5\" >294</td>\n",
       "      <td id=\"T_9b9f4_row10_col6\" class=\"data row10 col6\" >-</td>\n",
       "      <td id=\"T_9b9f4_row10_col7\" class=\"data row10 col7\" >578.7ms</td>\n",
       "      <td id=\"T_9b9f4_row10_col8\" class=\"data row10 col8\" >0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row11_col0\" class=\"data row11 col0\" >valid</td>\n",
       "      <td id=\"T_9b9f4_row11_col1\" class=\"data row11 col1\" >draw</td>\n",
       "      <td id=\"T_9b9f4_row11_col2\" class=\"data row11 col2\" ></td>\n",
       "      <td id=\"T_9b9f4_row11_col3\" class=\"data row11 col3\" >13.44ms</td>\n",
       "      <td id=\"T_9b9f4_row11_col4\" class=\"data row11 col4\" >75.85ms</td>\n",
       "      <td id=\"T_9b9f4_row11_col5\" class=\"data row11 col5\" >124</td>\n",
       "      <td id=\"T_9b9f4_row11_col6\" class=\"data row11 col6\" >-680</td>\n",
       "      <td id=\"T_9b9f4_row11_col7\" class=\"data row11 col7\" >1.667 s</td>\n",
       "      <td id=\"T_9b9f4_row11_col8\" class=\"data row11 col8\" >1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row12_col0\" class=\"data row12 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row12_col1\" class=\"data row12 col1\" >batch</td>\n",
       "      <td id=\"T_9b9f4_row12_col2\" class=\"data row12 col2\" ></td>\n",
       "      <td id=\"T_9b9f4_row12_col3\" class=\"data row12 col3\" >18.33ms</td>\n",
       "      <td id=\"T_9b9f4_row12_col4\" class=\"data row12 col4\" >5.751ms</td>\n",
       "      <td id=\"T_9b9f4_row12_col5\" class=\"data row12 col5\" >124</td>\n",
       "      <td id=\"T_9b9f4_row12_col6\" class=\"data row12 col6\" >3,699</td>\n",
       "      <td id=\"T_9b9f4_row12_col7\" class=\"data row12 col7\" >2.273 s</td>\n",
       "      <td id=\"T_9b9f4_row12_col8\" class=\"data row12 col8\" >1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row13_col0\" class=\"data row13 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row13_col1\" class=\"data row13 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row13_col2\" class=\"data row13 col2\" >predict</td>\n",
       "      <td id=\"T_9b9f4_row13_col3\" class=\"data row13 col3\" >17.37ms</td>\n",
       "      <td id=\"T_9b9f4_row13_col4\" class=\"data row13 col4\" >5.533ms</td>\n",
       "      <td id=\"T_9b9f4_row13_col5\" class=\"data row13 col5\" >124</td>\n",
       "      <td id=\"T_9b9f4_row13_col6\" class=\"data row13 col6\" >-</td>\n",
       "      <td id=\"T_9b9f4_row13_col7\" class=\"data row13 col7\" >2.154 s</td>\n",
       "      <td id=\"T_9b9f4_row13_col8\" class=\"data row13 col8\" >1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9b9f4_row14_col0\" class=\"data row14 col0\" ></td>\n",
       "      <td id=\"T_9b9f4_row14_col1\" class=\"data row14 col1\" ></td>\n",
       "      <td id=\"T_9b9f4_row14_col2\" class=\"data row14 col2\" >loss</td>\n",
       "      <td id=\"T_9b9f4_row14_col3\" class=\"data row14 col3\" >836.1µs</td>\n",
       "      <td id=\"T_9b9f4_row14_col4\" class=\"data row14 col4\" >228.3µs</td>\n",
       "      <td id=\"T_9b9f4_row14_col5\" class=\"data row14 col5\" >124</td>\n",
       "      <td id=\"T_9b9f4_row14_col6\" class=\"data row14 col6\" >80,358</td>\n",
       "      <td id=\"T_9b9f4_row14_col7\" class=\"data row14 col7\" >103.7ms</td>\n",
       "      <td id=\"T_9b9f4_row14_col8\" class=\"data row14 col8\" >0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "learn = Learner(dls, xse_resnet50(n_out=dls.c), metrics=Accuracy()).to_fp16().profile()\n",
    "learn.fit_one_cycle(2, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Training Loop\n",
    "The `show_training_loop` output below shows where the new `before_draw` event fits into the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastai.test_utils import synth_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [Recorder, ProgressCallback]\n",
      "    Start Train\n",
      "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - before_draw    : []\n",
      "         - before_batch   : [CastToTensor]\n",
      "         - after_pred     : []\n",
      "         - after_loss     : []\n",
      "         - before_backward: []\n",
      "         - before_step    : []\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder, ProgressCallback]\n",
      "    Start Valid\n",
      "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder, ProgressCallback]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : [ProgressCallback]\n"
     ]
    }
   ],
   "source": [
    "learn = synth_learner()\n",
    "learn.show_training_loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases Logging\n",
    "\n",
    "If Weights & Biases is installed and the [`WandbCallback`](https://docs.fast.ai/callback.wandb.html) is added to `Learner`, the Simple Profiler callback will automatically logs samples/second for draw, batch, forward, loss, backward, and opt_step steps as wandb charts.\n",
    "\n",
    "Also logs two tables to active wandb run:\n",
    "\n",
    "* `simple_profile_report`: formatted report from Simple Profiler\n",
    "* `simple_profile_results`: raw results from Simple Profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to other Loggers\n",
    "\n",
    "To extend to new loggers, follow the Weights & Biases code below and create patches for `SimpleProfilerCallback` to add a `_{Callback.name}_log_after_batch` and `_{Callback.name}_log_after_fit`, where `Callback.name` is the [name of the logger callback](https://docs.fast.ai/callback.core.html#Callback.name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_after_batch(self:SimpleProfilerCallback):\n",
    "        train_vals = {f'samples_per_second/train_{action}': self._train_samples_per_second(action) for action in _train[:-1]}\n",
    "        wandb.log(train_vals, self.learn.wandb._wandb_step+1)\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_after_fit(self:SimpleProfilerCallback):\n",
    "        report = wandb.Table(dataframe=self.learn.simple_profile_report)\n",
    "        results = wandb.Table(dataframe=self.learn.simple_profile_results)\n",
    "\n",
    "        wandb.log({\"simple_profile_report\": report})\n",
    "        wandb.log({\"simple_profile_results\": results})\n",
    "        wandb.log({}) # ensure sync\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to use, pass `logger_callback='{Callback.name}'` to `Learner.profile()`.\n",
    "\n",
    "`SimpleProfilerCallback` sets its `_log_after_batch` method to `f'_{self.logger_callback}_log_after_batch'`, which should match the patched method.\n",
    "\n",
    "```python\n",
    "self._log_after_batch = getattr(self, f'_{self.logger_callback}_log_after_batch', noop)\n",
    "```\n",
    "\n",
    "`SimpleProfilerCallback.log_after_fit` behaves the same way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
