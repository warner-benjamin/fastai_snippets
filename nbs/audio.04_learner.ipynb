{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp audio.learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Learner\n",
    "> Learner which knows to stack `FlattenTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from __future__ import annotations\n",
    "\n",
    "from fastcore.dispatch import retain_type\n",
    "\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.learner import Learner, defaults\n",
    "from fastai.optimizer import Adam\n",
    "\n",
    "from fastxtend.audio.core import TensorSpec, TensorMelSpec\n",
    "from fastxtend.audio.data import MelSpectrogram, Spectrogram\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DetupleCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StackSpecCallback(Callback):\n",
    "    \"Stacks tuples of TensorSpec or TensorMelSpec. ToDo: add resizing\"\n",
    "    order = MixedPrecision.order-1\n",
    "    def before_batch(self):\n",
    "        xb = L(self.xb)\n",
    "        idx = xb.argwhere(lambda x: isinstance(x, (TensorSpec, TensorMelSpec)))\n",
    "        ts = []\n",
    "        for i in idx:\n",
    "            ts.append(xb[i])\n",
    "        stacked = torch.stack(ts, dim=2)\n",
    "        xb = retain_type(torch.flatten(stacked, 1, 2), xb[i])\n",
    "        self.learn.xb = tuple(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## audio_learner -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #export\n",
    "def audio_learner(\n",
    "    dls, \n",
    "    model, \n",
    "    loss_func=None, \n",
    "    opt_func=Adam, \n",
    "    lr=defaults.lr, \n",
    "    splitter=trainable_params, \n",
    "    cbs=None, \n",
    "    metrics=None, \n",
    "    path=None, \n",
    "    model_dir='models', \n",
    "    wd=None, \n",
    "    wd_bn_bias=False, \n",
    "    train_bn=True,\n",
    "    moms=(0.95,0.85,0.95)\n",
    ") -> Learner:\n",
    "    \"An Audio specific Learner that stacks tuples of TensorSpec or TensorMelSpec\"\n",
    "    detuple = False\n",
    "    for i in range(len(dls.train.after_batch.fs)):\n",
    "        if not detuple and isinstance(dls.train.after_batch[i], (Spectrogram, MelSpectrogram)):\n",
    "            detuple = is_listy(dls.train.after_batch[i].n_fft)\n",
    "\n",
    "    if detuple:\n",
    "        if cbs is None: cbs = DetupleSpecCallback()\n",
    "        else: cbs = L(cbs) + L(DetupleSpecCallback())\n",
    "\n",
    "    return Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,\n",
    "                    metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,\n",
    "                    moms=moms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
