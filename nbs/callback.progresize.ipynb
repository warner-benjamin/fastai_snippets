{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.progresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Resizing\n",
    "> A callback to progressively resize images during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ProgressiveResize` is inspired by MosaicML's [Progressive Resizing algorithm for Composer](https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html) which in turn was inspired by [fastai](https://github.com/fastai/fastbook/blob/780b76bef3127ce5b64f8230fce60e915a7e0735/07_sizing_and_tta.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "\n",
    "from fastcore.basics import detuplify\n",
    "from fastcore.transform import Pipeline, Transform\n",
    "\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.vision.augment import AffineCoordTfm, RandomResizedCropGPU\n",
    "\n",
    "from fastxtend.metrics import MetricX\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_resize_augs = (AffineCoordTfm, RandomResizedCropGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _to_size(t:Tensor):\n",
    "    \"Convert Tensor to size compatible values\"\n",
    "    if sum(t.shape)==2: return tuple(t.tolist())\n",
    "    else:               return tuple(t.item(),t.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "class PostProgResize(Callback):\n",
    "    \"Delete batch after resize to assist with PyTorch memory management\"\n",
    "    run_valid, order = True, 100 # Runs last\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.learn._progresize:\n",
    "            del self.learn.xb\n",
    "            del self.learn.yb\n",
    "            del self.learn.pred\n",
    "            self.learn._progresize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressiveResize(Callback):\n",
    "    run_valid, order = True, 5 # Needs to run before MixUp et al\n",
    "    \"Progressively increase the size of input images during training. Final image size is the valid image size.\"\n",
    "    def __init__(self, \n",
    "        initial_size:Number|tuple[int,int]|None=0.5, \n",
    "        increase_by:int|tuple[int,int]=4, \n",
    "        start_at:float=0.5,\n",
    "        finish_at:float=0.75,\n",
    "        resize_mode:str='nearest',\n",
    "        add_resize:bool=False,\n",
    "        input_size:int|tuple[int,int]|None=None, # Final image size. Set if using a non-fastai Dataloaders.\n",
    "        logger_callback='wandb' # Log report and samples/second to `logger_callback` using `Callback.name`\n",
    "    ):\n",
    "        store_attr()\n",
    "        self._log_after_resize = getattr(self, f'_{self.logger_callback}_log_after_resize', noop)\n",
    "\n",
    "    def before_fit(self):\n",
    "        if hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\"): \n",
    "            self.run = False\n",
    "            return\n",
    "\n",
    "        self.learn._progresize = False\n",
    "        if not hasattr(self.learn, 'post_prog_resize'): self.learn.add_cb(PostProgResize)\n",
    "        self.remove_resize, self.null_resize, self.remove_cutmix = True, True, False\n",
    "        self.has_logger = hasattr(self.learn, self.logger_callback)\n",
    "\n",
    "        # Try to automatically determine the input size\n",
    "        try:\n",
    "            n_inp = self.dls.train.n_inp\n",
    "            xb = self.dls.valid.one_batch()[:n_inp]\n",
    "            for n in range(n_inp):\n",
    "                x = detuplify(xb[n])\n",
    "                if isinstance(x, TensorImageBase):\n",
    "                    self.input_size = x.shape[-2:]\n",
    "        finally:\n",
    "            assert self.input_size is not None, \"Could not determine input size. Set `input_size`.\"\n",
    "            self.input_size = tensor(self.input_size)\n",
    "\n",
    "        # Set the initial resize\n",
    "        if isinstance(self.initial_size, float): \n",
    "            self.current_size = (tensor(self.initial_size) * self.input_size).int()\n",
    "        elif isinstance(self.initial_size, tuple): \n",
    "            self.current_size = tensor(self.initial_size)\n",
    "\n",
    "        # Double check that the step size works\n",
    "        self.increase_by = tensor(self.increase_by)\n",
    "        if ((self.input_size-self.current_size) % self.increase_by).sum() != 0:\n",
    "            raise ValueError(f'Resize amount {self.input_size-self.current_size} not evenly divisible by `increase_by` {self.increase_by}')\n",
    "\n",
    "        # Set when the progressive resizing step is applied\n",
    "        n_steps = ((self.input_size-self.current_size) / self.increase_by).int()\n",
    "        if len(n_steps.shape)==2: assert n_steps[0]==n_steps[1]\n",
    "        pct = (self.finish_at - self.start_at) / (n_steps[0].item()-1)\n",
    "        self.step_pcts = [self.start_at + pct*i for i in range(n_steps[0].item())]+[1.1]\n",
    "\n",
    "        self._resize = []\n",
    "        # If `add_resize`, add a seperate resize\n",
    "        if self.add_resize:\n",
    "            self._resize_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size), mode=self.resize_mode))\n",
    "            self._resize.append(self._resize_pipe[0])\n",
    "            self.remove_resize = True\n",
    "        else:\n",
    "            if hasattr(self.learn, 'cutmixupaugment'):\n",
    "                # Modify the `CutMixUpAugment` augmentation pipeline \n",
    "                for i in range(len(self.learn.cutmixupaugment._orig_pipe)):\n",
    "                    if isinstance(self.learn.cutmixupaugment._orig_pipe[i], _resize_augs):\n",
    "                        self._resize.append(self.learn.cutmixupaugment._orig_pipe[i])\n",
    "                        self.null_resize = self.null_resize and self.learn.cutmixupaugment._orig_pipe[i].size is None\n",
    "                        self.remove_resize = False\n",
    "\n",
    "                # If `CutMixUpAugment` has an Affine Transform for Augmentations then use it\n",
    "                if len(self._resize) > 0:\n",
    "                    # Check for pre-mixup augment pipeline and modify it\n",
    "                    if self.learn.cutmixupaugment._docutmixaug:\n",
    "                        for i in range(len(self.learn.cutmixupaugment._cutmixaugs_pipe)):\n",
    "                            if isinstance(self.learn.cutmixupaugment._cutmixaugs_pipe[i], _resize_augs):\n",
    "                                self._resize.append(self.learn.cutmixupaugment._cutmixaugs_pipe[i])\n",
    "                                self.null_resize = self.null_resize and self.learn.cutmixupaugment._cutmixaugs_pipe[i].size is None\n",
    "                                self.remove_resize = False    \n",
    "                    else:\n",
    "                        # There isn't one, then add it a pre-mixup augment pipeline for resizing\n",
    "                        self.learn.cutmixupaugment._cutmixaugs_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size)))\n",
    "                        self.learn.cutmixupaugment._docutmixaug = True\n",
    "                        self._resize.append(self.learn.cutmixupaugment._cutmixaugs_pipe[0])\n",
    "                        self.remove_cutmix, self.remove_resize = True, True\n",
    "\n",
    "            else:\n",
    "                # If no `CutMixUpAugment` check the dataloader pipeline for Affine Transforms\n",
    "                for i in range(len(self.dls.train.after_batch.fs)):\n",
    "                    if isinstance(self.dls.train.after_batch[i], _resize_augs):\n",
    "                        self._resize.append(self.dls.train.after_batch[i])\n",
    "                        self.null_resize = self.null_resize and self.dls.train.after_batch[i].size is None\n",
    "                        self.remove_resize = False\n",
    "\n",
    "            # If no there are no detected resizes add a resize transform pipeline\n",
    "            if len(self._resize) == 0:\n",
    "                self.add_resize = True\n",
    "                self._resize_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size)))\n",
    "                self._resize.append(self._resize_pipe[0])\n",
    "                self.remove_resize = True\n",
    "\n",
    "        # Set created or detected resize to the first size and store original interpolation\n",
    "        self._orig_modes = []\n",
    "        for resize in self._resize:\n",
    "            resize.size = _to_size(self.current_size)\n",
    "            self._orig_modes.append(resize.mode)\n",
    "            resize.mode = self.resize_mode\n",
    "\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.add_resize:\n",
    "            self.learn.xb = self._resize_pipe(self.xb)\n",
    "            # self.learn.yb = self._resize_pipe(self.yb) TODO this wasn't working\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if self.pct_train >= self.step_pcts[0]:\n",
    "            self.learn._progresize = True\n",
    "            self.step_pcts = self.step_pcts[1:]\n",
    "            self.current_size += self.increase_by\n",
    "            for i, resize in enumerate(self._resize):\n",
    "                if (self.current_size < self.input_size).all():\n",
    "                    resize.size = _to_size(self.current_size)\n",
    "                else:\n",
    "                    # Reset everything after progressive resizing is done\n",
    "                    if self.null_resize: \n",
    "                        resize.size = None\n",
    "                    elif self.remove_resize:\n",
    "                        if self.remove_cutmix:\n",
    "                            self.learn.cutmixupaugment._cutmixaugs_pipe = Pipeline([])\n",
    "                            self.learn.cutmixupaugment._docutmixaug = False\n",
    "                        else:\n",
    "                            self._resize_pipe = Pipeline([])\n",
    "                            self.add_resize = False\n",
    "                    else:\n",
    "                        resize.size = _to_size(self.current_size)\n",
    "                        resize.mode = self._orig_modes[i]\n",
    "            if self.has_logger: self._log_after_resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_after_resize(self:ProgressiveResize):\n",
    "        if len(self.current_size.shape)==2:\n",
    "            size = {'progressive_resize_height': self.current_size[0],\n",
    "                    'progressive_resize_width': self.current_size[1] }\n",
    "        else:\n",
    "            size = {'progressive_resize_size': self.current_size}\n",
    "        wandb.log(size, self.learn.wandb._wandb_step+1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.learner import Learner\n",
    "from fastai.vision.augment import Resize, aug_transforms\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models import resnet50\n",
    "from fastxtend.callback.channelslast import *\n",
    "from fastxtend.callback.cutmixup import CutMixUpAugment\n",
    "from fastxtend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @patch\n",
    "# def _set_device(self:Learner, b):\n",
    "#     model_device = next(self.model.parameters()).device\n",
    "#     dls_device = getattr(self.dls, 'device', default_device())\n",
    "#     if model_device == dls_device: return to_device(b, dls_device, non_blocking=True)\n",
    "#     else: return to_device(b, model_device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "class ProgressiveResizeTest(Callback):\n",
    "    run_valid, order = False, ProgressiveResize.order+1\n",
    "    \n",
    "    def before_fit(self):\n",
    "        self.progsize = self.learn.progressive_resize.current_size\n",
    "\n",
    "    def before_batch(self):\n",
    "        assert L(self.x.shape[-2:]) == L(self.progsize.tolist())\n",
    "            \n",
    "    def after_batch(self):\n",
    "        self.progsize = self.learn.progressive_resize.current_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                    splitter=GrandparentSplitter(valid_name='val'),\n",
    "                    get_items=get_image_files, get_y=parent_label,\n",
    "                    item_tfms=Resize(256),\n",
    "                    batch_tfms=[*aug_transforms(),Normalize.from_stats(*imagenet_stats)])\n",
    "dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "learn = Learner(dls, resnet50(num_classes=dls.c)).to_channelslast()\n",
    "learn.fit_one_cycle(20, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                    splitter=GrandparentSplitter(valid_name='val'),\n",
    "                    get_items=get_image_files, get_y=parent_label,\n",
    "                    item_tfms=Resize(256),\n",
    "                    batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "cbs = [ProgressiveResize(0.5, increase_by=8, start_at=0.1, finish_at=0.85)]\n",
    "learn = Learner(dls, resnet50(num_classes=dls.c), cbs=cbs).to_channelslast()\n",
    "learn.fit_one_cycle(20, 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
