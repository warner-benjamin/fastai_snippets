{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastxtend\n",
    "> Train fastai models faster (and other useful tools)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "### Train fastai models faster (and other useful tools)\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "![fastxtend accelerates fastai](nbs/images/imagenette_benchmark.png)\n",
    ":::\n",
    "\n",
    "::: {.content-hidden when-format=\"markdown\"}\n",
    "![fastxtend accelerates fastai](images/imagenette_benchmark.svg)\n",
    ":::\n",
    "\n",
    "Train fastai models faster with fastxtend's [fused optimizers](optimizer.fused.html), [Progressive Resizing](callback.progresize.html) callback, and integrated [FFCV DataLoader](ffcv.tutorial.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature overview\n",
    "\n",
    "**Train Models Faster**\n",
    "\n",
    "* Drop in [fused optimizers](optimizer.fused.html), which are 21 to 293 percent faster then fastai native optimizers.\n",
    "* Up to 75% optimizer memory savings with integrated [bitsandbytes](https://github.com/TimDettmers/bitsandbytes) [8-bit optimizers](optimizer.eightbit.html).\n",
    "* Increase GPU throughput and decrease training time with the [Progressive Resizing](callback.progresize.html) callback.\n",
    "* Use the highly optimized [FFCV DataLoader](ffcv.tutorial.html), fully integrated with fastai.\n",
    "* Integrated support for `torch.compile` via the [Compile](callback.compiler.html) callbacks.\n",
    "\n",
    "**General Features**\n",
    "\n",
    "* Fused implementations of modern optimizers, such as [Adan](optimizer.adan.html), [Lion](optimizer.lion.html), & [StableAdam](optimizer.stableadam.html).\n",
    "* Hugging Face [Transformers compatibility](text.huggingface.html) with fastai\n",
    "* Flexible [metrics](metrics.html) which can log on train, valid, or both. Backwards compatible with fastai metrics.\n",
    "* Easily use [multiple losses](multiloss.html) and log each individual loss on train and valid.\n",
    "* [Multiple profilers](callback.profiler.html) for profiling training and identifying bottlenecks.\n",
    "* A fast [Exponential Moving Average](callback.ema.html) callback for smoother training.\n",
    "\n",
    "**Vision**\n",
    "\n",
    "* Apply `MixUp`, `CutMix`, or Augmentations at once with `CutMixUp` or `CutMixUpAugment`.\n",
    "* Additional [image augmentations](vision.augment.batch.html).\n",
    "* Support for running fastai [batch transforms on CPU](vision.data.html).\n",
    "* More [attention](vision.models.attention_modules.html) and [pooling](vision.models.pooling.html) modules\n",
    "* A flexible implementation of fastai’s `XResNet`.\n",
    "\n",
    "Check out the documentation for additional splitters, callbacks, schedulers, utilities, and more."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "## Documentation\n",
    "<https://fastxtend.benjaminwarner.dev>\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "fastxtend is avalible on pypi:\n",
    "```bash\n",
    "pip install fastxtend\n",
    "```\n",
    "\n",
    "fastxtend can be installed with task-specific dependencies for `vision`, `ffcv`, `text`, `audio`, or `all`:\n",
    "```bash\n",
    "pip install \"fastxtend[all]\"\n",
    "```\n",
    "\n",
    "To easily install most prerequisites for all fastxtend features, use [Conda](https://docs.conda.io/en/latest) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html):\n",
    "\n",
    "```bash\n",
    "conda create -n fastxtend python=3.11 \"pytorch>=2.1\" torchvision torchaudio \\\n",
    "pytorch-cuda=12.1 fastai nbdev pkg-config libjpeg-turbo opencv tqdm psutil \\\n",
    "terminaltables numpy \"numba>=0.57\" librosa timm kornia rich typer wandb \\\n",
    "\"transformers>=4.34\" \"tokenizers>=0.14\" \"datasets>=2.14\" ipykernel ipywidgets \\\n",
    "\"matplotlib<3.8\" -c pytorch -c nvidia -c fastai -c huggingface -c conda-forge\n",
    "\n",
    "conda activate fastxtend\n",
    "\n",
    "pip install \"fastxtend[all]\"\n",
    "```\n",
    "replacing `pytorch-cuda=12.1` with your preferred [supported version of Cuda](https://pytorch.org/get-started/locally).\n",
    "\n",
    "To create an editable development install:\n",
    "```bash\n",
    "git clone https://github.com/warner-benjamin/fastxtend.git\n",
    "cd fastxtend\n",
    "pip install -e \".[dev]\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "Like fastai, fastxtend provides safe wildcard imports using python’s `__all__`. \n",
    "```python\n",
    "from fastai.vision.all import *\n",
    "from fastxtend.vision.all import *\n",
    "from fastxtend.ffcv.all import *\n",
    "```\n",
    "In general, import fastxtend after all fastai imports, as fastxtend modifies fastai. Any method modified by fastxtend is backwards compatible with the original fastai code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Use a fused ForEach optimizer:\n",
    "```python\n",
    "Learner(..., opt_func=adam(foreach=True))\n",
    "```\n",
    "\n",
    "Or a bitsandbytes 8-bit optimizer:\n",
    "```python\n",
    "Learner(..., opt_func=adam(eightbit=True))\n",
    "```\n",
    "\n",
    "Speed up image training using Progressive Resizing:\n",
    "\n",
    "```python\n",
    "Learner(... cbs=ProgressiveResize())\n",
    "```\n",
    "\n",
    "Log an accuracy metric on the training set as a smoothed metric and validation set like normal:\n",
    "```python\n",
    "Learner(..., metrics=[Accuracy(log_metric=LogMetric.Train, metric_type=MetricType.Smooth),\n",
    "                      Accuracy()])\n",
    "```\n",
    "\n",
    "Log multiple losses as individual metrics on train and valid:\n",
    "```python\n",
    "mloss = MultiLoss(loss_funcs=[nn.MSELoss, nn.L1Loss],\n",
    "                  weights=[1, 3.5], loss_names=['mse_loss', 'l1_loss'])\n",
    "\n",
    "Learner(..., loss_func=mloss, metrics=RMSE(), cbs=MultiLossCallback)\n",
    "```\n",
    "\n",
    "Compile a model with `torch.compile`:\n",
    "```python\n",
    "from fastxtend.callback import compiler\n",
    "\n",
    "learn = Learner(...).compile()\n",
    "```\n",
    "\n",
    "Profile a fastai training loop:\n",
    "```python\n",
    "from fastxtend.callback import simpleprofiler\n",
    "\n",
    "learn = Learner(...).profile()\n",
    "learn.fit_one_cycle(2, 3e-3)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "To run the benchmark on your own machine, see the [example scripts](https://github.com/warner-benjamin/fastxtend/tree/main/examples) for details on how to replicate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
