{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "> Adds more basic transform types to fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from __future__ import annotations\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "from fastcore.transform import DisplayedTransform, _is_tuple, retain_type\n",
    "\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchRandTransform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BatchRandTransform(DisplayedTransform):\n",
    "    \"Randomly selects a subset of batch `b` to apply transform with per item probability `p` in `before_call`\"\n",
    "    do,supports,split_idx = True,[],0\n",
    "    def __init__(self, \n",
    "        p:Number=1., # Probability of applying Transform to each batch item\n",
    "        before_call:Callable[[Tensor|tuple[Tensor,...],int],None]|None=None, # Batch preprocessing function\n",
    "        **kwargs\n",
    "    ):\n",
    "        store_attr('p')\n",
    "        super().__init__(**kwargs)\n",
    "        self.before_call = ifnone(before_call,self.before_call)\n",
    "        self.bernoulli = Bernoulli(p)\n",
    "\n",
    "    def before_call(self, \n",
    "        b:Tensor|tuple[Tensor,...], # Batch item(s)\n",
    "        split_idx:int # Train (0) or valid (1) index\n",
    "    ):\n",
    "        \"Randomly select `self.idxs` and set `self.do` based on `self.p` if not valid `split_idx`\"\n",
    "        self.idxs = self.bernoulli.sample((find_bs(b),)).bool() if not split_idx and self.p<1. else torch.ones(find_bs(b)).bool()\n",
    "        self.do = self.p==1. or self.idxs.shape[-1] > 0\n",
    "\n",
    "    def __call__(self, \n",
    "        b:Tensor|tuple[Tensor,...], # Batch item(s)\n",
    "        split_idx:int, # Train (0) or valid (1) index\n",
    "        **kwargs\n",
    "    ) -> Tensor|tuple[Tensor,...]:\n",
    "        \"Call `super().__call__` if `self.do`\"\n",
    "        self.before_call(b, split_idx=split_idx)\n",
    "        return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b\n",
    "\n",
    "    def _do_call(self, \n",
    "        f, # Transform\n",
    "        x:Tensor|tuple[Tensor,...], # Batch item(s)\n",
    "        **kwargs\n",
    "    ) -> Tensor|tuple[Tensor,...]:\n",
    "        \"Override `Transform._do_call` to apply transform `f` to `x[self.idxs]`\"\n",
    "        if not _is_tuple(x):\n",
    "            if f is None: return x\n",
    "            ret = f.returns(x) if hasattr(f,'returns') else None\n",
    "            return retain_type(self._do_f(f, x, **kwargs), x, ret)\n",
    "        res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)\n",
    "        return retain_type(res, x)\n",
    "\n",
    "    def _do_f(self, \n",
    "        f, # Transform\n",
    "        x:Tensor, # Batch item\n",
    "        **kwargs\n",
    "    ) -> Tensor:\n",
    "        \"Apply transform `f` to `x[self.idxs]`\"\n",
    "        x[self.idxs] = f(x[self.idxs], **kwargs)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
