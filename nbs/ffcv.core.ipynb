{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp ffcv.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "# Contains code from:\n",
    "# fastai - Apache License 2.0 - Copyright (c) 2023 fast.ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFCV Core\n",
    "> Core functionality for the fastai+FFCV integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Mapping, Sequence\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ffcvx.fields.base import Field\n",
    "from ffcvx.loader.loader import Loader, OrderOption, ORDER_TYPE, DEFAULT_OS_CACHE, ORDER_MAP\n",
    "from ffcvx.pipeline.operation import Operation\n",
    "from ffcvx.transforms.ops import ToDevice as _ToDevice\n",
    "\n",
    "from fastcore.basics import GetAttr, detuplify, Inf\n",
    "from fastcore.dispatch import retain_types, explode_types\n",
    "from fastcore.meta import funcs_kwargs\n",
    "from fastcore.transform import Pipeline\n",
    "\n",
    "from fastai.data.core import show_batch, show_results, DataLoaders\n",
    "\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@funcs_kwargs\n",
    "class BaseLoader(GetAttr):\n",
    "    \"Provides callbacks for DataLoaders which inherit from `BaseLoader`\"\n",
    "    _methods = 'before_iter after_batch after_iter'.split()\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def before_iter(self, x=None, *args, **kwargs):\n",
    "        \"Called before `BaseLoader` starts to read/iterate over the dataset.\"\n",
    "        return x\n",
    "\n",
    "    def after_batch(self, x=None, *args, **kwargs):\n",
    "        \"After collating mini-batch of items, the mini-batch is passed through this function.\"\n",
    "        return x\n",
    "\n",
    "    def after_iter(self, x=None, *args, **kwargs):\n",
    "        \"Called after `BaseLoader` has fully read/iterated over the dataset.\"\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FFCVDataLoader(BaseLoader, Loader):\n",
    "    \"Hybrid FFCV `Loader` and fastai Transformed DataLoader `TfmdDL`\"\n",
    "    def __init__(self,\n",
    "        fname:str|Path, # Path to the location of the dataset (FFCV beton format)\n",
    "        bs:int=64, # Batch size\n",
    "        num_workers:int=-1, # Number of CPU cores to use in parallel (default: All available up to 16)\n",
    "        os_cache:bool=DEFAULT_OS_CACHE, # Leverage the OS for caching. Beneficial when there is enough memory to cache the dataset\n",
    "        order:ORDER_TYPE=OrderOption.SEQUENTIAL, # Dataset traversal order, one of: SEQEUNTIAL, RANDOM, QUASI_RANDOM\n",
    "        distributed:bool=False, # Emulates the behavior of PyTorch's DistributedSampler for distributed training\n",
    "        seed:int|None=None, # Random seed for batch ordering\n",
    "        indices:Sequence[int]|None=None, # Subset dataset by returning only these indices\n",
    "        pipelines:Mapping[str, Sequence[Operation|nn.Module]]={}, # Dictionary defining for each field the sequence of Decoders and transforms to apply\n",
    "        custom_fields:Mapping[str, Field]={}, # Dictonary informing `Loader` of the types associated to fields that are using a custom type\n",
    "        drop_last:bool|None=None, # Drop non-full batch in each epoch\n",
    "        batches_ahead:int=3, # Number of batches prepared in advance; balances latency and memory\n",
    "        recompile:bool=False, # Recompile at every epoch. Required if FFCV augmentations change during training\n",
    "        device:str|int|torch.device|None=None, # Device to place batch, defaults to fastai's `default_device`\n",
    "        n_inp:int|None=None, # Number of inputs to the model. Defaults to pipelines length minus 1\n",
    "        split_idx:int|None=None, # Apply batch transform(s) to training (0) or validation (1) set\n",
    "        do_setup:bool=True, # Run `setup()` for batch transform(s)\n",
    "        **kwargs\n",
    "    ):\n",
    "        if 'batch_tfms' in kwargs:\n",
    "            if 'after_batch' not in kwargs:\n",
    "                kwargs['after_batch'] = kwargs.pop('batch_tfms')\n",
    "            else:\n",
    "                raise ValueError('Cannot pass both `after_batch` and `batch_tfms` to `FFCVDataLoader`')\n",
    "\n",
    "        kwargs['after_batch'] = Pipeline(kwargs.get('after_batch', None))\n",
    "        if do_setup:\n",
    "            kwargs['after_batch'].setup(self)\n",
    "\n",
    "        if drop_last is None:\n",
    "            drop_last != order==OrderOption.SEQUENTIAL\n",
    "\n",
    "        if device is None:\n",
    "            device = default_device()\n",
    "\n",
    "        Loader.__init__(self,\n",
    "            fname=str(Path(fname)),\n",
    "            batch_size=bs,\n",
    "            num_workers=num_workers,\n",
    "            os_cache=os_cache,\n",
    "            order=order,\n",
    "            distributed=distributed,\n",
    "            seed=seed,\n",
    "            indices=indices,\n",
    "            pipelines=pipelines,\n",
    "            custom_fields=custom_fields,\n",
    "            drop_last=drop_last,\n",
    "            batches_ahead=batches_ahead,\n",
    "            recompile=recompile\n",
    "        )\n",
    "        BaseLoader.__init__(self, **kwargs)\n",
    "        self.split_idx = split_idx\n",
    "        self.device = device\n",
    "        if n_inp is None:\n",
    "            self._n_inp = len(pipelines) - 1\n",
    "        else:\n",
    "            self._n_inp = n_inp\n",
    "\n",
    "        for name in ['item_tfms', 'after_item', 'before_batch']:\n",
    "            if name in kwargs:\n",
    "                if name != 'before_batch':\n",
    "                    msg = f'`FFCVDataLoader` will not call any {name} methods. ' \\\n",
    "                          f'{name} is for use with a fastai DataLoader.\\n' \\\n",
    "                          f'Instead of passing fastai Item Transforms to {name},' \\\n",
    "                          f'initialize the `FFCVDataLoader` pipeline with FFCV transforms.'\n",
    "                else:\n",
    "                    msg = f'`FFCVDataLoader` will not call any {name} methods. ' \\\n",
    "                          f'{name} are for use with a fastai DataLoader.'\n",
    "                warn(msg)\n",
    "\n",
    "\n",
    "    def one_batch(self):\n",
    "        \"Return one processed batch of input(s) and target(s)\"\n",
    "        for b in self._one_batch():\n",
    "            # need to return the yield from _one_batch so `Loader` can reset to iterate the entire epoch\n",
    "            pass\n",
    "        return b\n",
    "\n",
    "    def show_batch(self,\n",
    "        b=None, # Batch to show\n",
    "        max_n:int=9, # Maximum number of items to show\n",
    "        ctxs=None, # List of `ctx` objects to show data. Could be matplotlib axis, DataFrame etc\n",
    "        show:bool=True, # Whether to display data\n",
    "        unique:bool=False, # Whether to show only one\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Show `max_n` input(s) and target(s) from the batch.\"\n",
    "        if unique:\n",
    "            old_get_idxs = self.get_idxs\n",
    "            self.get_idxs = lambda: Inf.zeros\n",
    "        if b is None:\n",
    "            b = self.one_batch()\n",
    "        if not show:\n",
    "            return self._pre_show_batch(b, max_n=max_n)\n",
    "        # Uses Type Dispatch to call the correct `show_batch` for b\n",
    "        show_batch(*self._pre_show_batch(b, max_n=max_n), ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "        if unique:\n",
    "            self.get_idxs = old_get_idxs\n",
    "\n",
    "    def show_results(self,\n",
    "        b, # Batch to show results for\n",
    "        out, # Predicted output from model for the batch\n",
    "        max_n:int=9, # Maximum number of items to show\n",
    "        ctxs=None, # List of `ctx` objects to show data. Could be matplotlib axis, DataFrame etc\n",
    "        show:bool=True, # Whether to display data\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Show `max_n` results with input(s), target(s) and prediction(s).\"\n",
    "        x,y,its = self.show_batch(b, max_n=max_n, show=False)\n",
    "        b_out = type(b)(b[:self.n_inp] + (tuple(out) if is_listy(out) else (out,)))\n",
    "        x1,y1,outs = self.show_batch(b_out, max_n=max_n, show=False)\n",
    "        if its is None:\n",
    "            res = (x, x1, None, None)\n",
    "        else:\n",
    "            res = (x, y, its, outs.itemgot(slice(self.n_inp,None)))\n",
    "        if not show:\n",
    "            return res\n",
    "        # Uses Type Dispatch to call the correct `show_results` for b\n",
    "        show_results(*res, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def n_inp(self) -> int:\n",
    "        \"Number of elements in a batch for model input\"\n",
    "        return self._n_inp\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, device):\n",
    "        self._device = device\n",
    "        # Device setter for Loader\n",
    "        for p in self.pipeline_specs.values():\n",
    "            for t in p.transforms:\n",
    "                if isinstance(t, _ToDevice):\n",
    "                    t.device = device\n",
    "        # Device setter for FFCVDataLoader\n",
    "        if hasattr(self.after_batch, 'fs'):\n",
    "            for tfm in self.after_batch.fs:\n",
    "                for a in L(getattr(tfm, 'parameters', None)):\n",
    "                    setattr(tfm, a, getattr(tfm, a).to(device))\n",
    "                if hasattr(tfm, 'to'):\n",
    "                    tfm.to(device)\n",
    "\n",
    "    def to(self, device):\n",
    "        \"Sets `self.device=device`.\"\n",
    "        self.device = device\n",
    "        return self\n",
    "\n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        f = getattr(self, 'after_batch')\n",
    "        if isinstance(f,Pipeline):\n",
    "            f.split_idx=self.split_idx\n",
    "\n",
    "    def decode(self, b):\n",
    "        \"Decode batch `b`\"\n",
    "        return to_cpu(self.after_batch.decode(self._retain_dl(b)))\n",
    "\n",
    "    def decode_batch(self, b, max_n:int=9):\n",
    "        \"Decode up to `max_n` input(s) from batch `b`\"\n",
    "        return self._decode_batch(self.decode(b), max_n)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.before_iter()\n",
    "        for b in super().__iter__():\n",
    "            yield self.after_batch(b)\n",
    "        self.after_iter()\n",
    "        if hasattr(self, 'it'):\n",
    "            del(self.it)\n",
    "\n",
    "    def _one_pass(self, b=None):\n",
    "        if b is None:\n",
    "            b = self.one_batch()\n",
    "        self._types = explode_types(b)\n",
    "\n",
    "    def _retain_dl(self, b):\n",
    "        if not getattr(self, '_types', None):\n",
    "            self._one_pass(b)\n",
    "        return retain_types(b, typs=self._types)\n",
    "\n",
    "    def _decode_batch(self, b, max_n=9):\n",
    "        return L(batch_to_samples(b, max_n=max_n))\n",
    "\n",
    "    def _pre_show_batch(self, b, max_n=9):\n",
    "        \"Decode `b` to be ready for `show_batch`\"\n",
    "        b = self.decode(b)\n",
    "        if hasattr(b, 'show'):\n",
    "            return b,None,None\n",
    "        its = self._decode_batch(b, max_n)\n",
    "        if not is_listy(b):\n",
    "            b,its = [b],L((o,) for o in its)\n",
    "        return detuplify(b[:self.n_inp]),detuplify(b[self.n_inp:]),its\n",
    "\n",
    "    def _one_batch(self):\n",
    "        orig_traversal_order = self.traversal_order\n",
    "        orig_indices = self.indices\n",
    "        orig_drop_last = self.drop_last\n",
    "\n",
    "        # Set Loader to only return one batch per epoch\n",
    "        if self._args['order'] == OrderOption.SEQUENTIAL:\n",
    "            self.indices = np.arange(0, self.batch_size)\n",
    "        else:\n",
    "            self.indices = np.random.random_integers(0, self.reader.num_samples, self.batch_size)\n",
    "        self.traversal_order = ORDER_MAP[OrderOption.SEQUENTIAL](self)\n",
    "        self.drop_last = False\n",
    "\n",
    "        # yield one batch\n",
    "        yield next(self.__iter__())\n",
    "\n",
    "        # Reset Loader state to its original status\n",
    "        self.next_epoch -= 1\n",
    "        self.indices = orig_indices\n",
    "        self.drop_last = orig_drop_last\n",
    "        self.traversal_order = orig_traversal_order"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FFCVTensorCategory(TensorCategory):\n",
    "    \"fastai's TensorCategory with a show method\"\n",
    "    def show(self, **kwargs):\n",
    "        show_title(self.item(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FFCVTensorMultiCategory(TensorMultiCategory):\n",
    "    \"fastai's TensorMultiCategory with a show method\"\n",
    "    def show(self, **kwargs):\n",
    "        show_title(self.item(), **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patches-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "from packaging.version import parse\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "if parse(fastai.__version__) <= parse('2.7.10'):\n",
    "    @patch\n",
    "    def __init__(self:DataLoaders,\n",
    "        *loaders, # `DataLoader` objects to wrap\n",
    "        path:str|Path='.', # Path to store export objects\n",
    "        device=None # Device to put `DataLoaders`\n",
    "    ):\n",
    "        self.loaders,self.path = list(loaders),Path(path)\n",
    "        if device is not None and hasattr(loaders[0],'to'): self.device = device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
