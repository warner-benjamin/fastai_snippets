---

title: MultiLoss


keywords: fastai
sidebar: home_sidebar

summary: "A loss wrapper and callback to calculate and log individual losses as fastxtend metrics."
description: "A loss wrapper and callback to calculate and log individual losses as fastxtend metrics."
nb_path: "nbs/multiloss.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/multiloss.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MultiLoss" class="doc_header"><code>class</code> <code>MultiLoss</code><a href="https://github.com/warner-benjamin/fastxtend/tree/main/fastxtend/multiloss.py#L26" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MultiLoss</code>(<strong><code>loss_funcs</code></strong>:<code>listy[Callable[..., nn.Module] | FunctionType]</code>, <strong><code>weights</code></strong>:<code>listified[Number] | None</code>=<em><code>None</code></em>, <strong><code>loss_kwargs</code></strong>:<code>listy[dict[str, Any]] | None</code>=<em><code>None</code></em>, <strong><code>loss_names</code></strong>:<code>listy[str] | None</code>=<em><code>None</code></em>, <strong><code>reduction</code></strong>:<code>str | None</code>=<em><code>'mean'</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Combine multiple <code>loss_funcs</code> on one prediction &amp; target via <code>reduction</code>, with optional weighting.</p>
<p>Log <code>loss_funcs</code> as metrics via <a href="/multiloss.html#MultiLossCallback"><code>MultiLossCallback</code></a>, optionally using <code>loss_names</code>.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>loss_funcs</code></strong></td>
<td><code>listy[Callable[..., nn.Module] or FunctionType]</code></td>
<td></td>
<td>Uninitialized loss functions or classes. Must support PyTorch <code>reduction</code> string.</td>
</tr>
<tr>
<td><strong><code>weights</code></strong></td>
<td><code>listified[Number] or None</code></td>
<td><code>None</code></td>
<td>Weight per loss. Defaults to uniform weighting.</td>
</tr>
<tr>
<td><strong><code>loss_kwargs</code></strong></td>
<td><code>listy[dict[str, Any]] or None</code></td>
<td><code>None</code></td>
<td>kwargs to pass to each loss function. Defaults to None.</td>
</tr>
<tr>
<td><strong><code>loss_names</code></strong></td>
<td><code>listy[str] or None</code></td>
<td><code>None</code></td>
<td>Loss names to log using <a href="/multiloss.html#MultiLossCallback"><code>MultiLossCallback</code></a>. Defaults to loss <code>__name__</code>.</td>
</tr>
<tr>
<td><strong><code>reduction</code></strong></td>
<td><code>str or None</code></td>
<td><code>mean</code></td>
<td>PyTorch loss reduction</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/multiloss.html#MultiLoss"><code>MultiLoss</code></a> is a simple multiple loss wrapper which allows logging each individual loss automatically using the <a href="/multiloss.html#MultiLossCallback"><code>MultiLossCallback</code></a>.</p>
<p>Pass uninitialized loss functions to <code>loss_funcs</code>, optional per loss weighting via <code>weights</code>, any loss arguments via a list of dictionaries in <code>loss_kwargs</code>, and optional names for each individual loss via <code>loss_names</code>.</p>
<p>If passed, <code>weights</code>, <code>loss_kwargs</code>, &amp; <code>loss_names</code> must be an iterable of the same length as <code>loss_funcs</code>.</p>
<p>Output from each loss function must be the same shape.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MultiTargetLoss" class="doc_header"><code>class</code> <code>MultiTargetLoss</code><a href="https://github.com/warner-benjamin/fastxtend/tree/main/fastxtend/multiloss.py#L92" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MultiTargetLoss</code>(<strong><code>loss_funcs</code></strong>:<code>listy[Callable[..., nn.Module] | FunctionType]</code>, <strong><code>weights</code></strong>:<code>listified[Number] | None</code>=<em><code>None</code></em>, <strong><code>loss_kwargs</code></strong>:<code>listy[dict[str, Any]] | None</code>=<em><code>None</code></em>, <strong><code>loss_names</code></strong>:<code>listy[str] | None</code>=<em><code>None</code></em>, <strong><code>reduction</code></strong>:<code>str | None</code>=<em><code>'mean'</code></em>) :: <a href="/multiloss.html#MultiLoss"><code>MultiLoss</code></a></p>
</blockquote>
<p>Combine <code>loss_funcs</code> from multiple predictions &amp; targets via <code>reduction</code>, with optional weighting.</p>
<p>Log <code>loss_funcs</code> as metrics via <a href="/multiloss.html#MultiLossCallback"><code>MultiLossCallback</code></a>, optionally using <code>loss_names</code>.</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>loss_funcs</code></strong></td>
<td><code>listy[Callable[..., nn.Module] or FunctionType]</code></td>
<td></td>
<td>Uninitialized loss functions or classes. One per prediction and target. Must support PyTorch <code>reduction</code> string.</td>
</tr>
<tr>
<td><strong><code>weights</code></strong></td>
<td><code>listified[Number] or None</code></td>
<td><code>None</code></td>
<td>Weight per loss. Defaults to uniform weighting.</td>
</tr>
<tr>
<td><strong><code>loss_kwargs</code></strong></td>
<td><code>listy[dict[str, Any]] or None</code></td>
<td><code>None</code></td>
<td>kwargs to pass to each loss function. Defaults to None.</td>
</tr>
<tr>
<td><strong><code>loss_names</code></strong></td>
<td><code>listy[str] or None</code></td>
<td><code>None</code></td>
<td>Loss names to log using <a href="/multiloss.html#MultiLossCallback"><code>MultiLossCallback</code></a>. Defaults to loss <code>__name__</code>.</td>
</tr>
<tr>
<td><strong><code>reduction</code></strong></td>
<td><code>str or None</code></td>
<td><code>mean</code></td>
<td>PyTorch loss reduction</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/multiloss.html#MultiTargetLoss"><code>MultiTargetLoss</code></a> a single loss per multiple target version of <code>Multiloss</code>. It is a simple multiple loss wrapper which allows logging each individual loss automatically using the <a href="/multiloss.html#MultiLossCallback"><code>MultiLossCallback</code></a>.</p>
<p>Pass uninitialized loss functions to <code>loss_funcs</code>, optional per loss weighting via <code>weights</code>, any loss arguments via a list of dictionaries in <code>loss_kwargs</code>, and optional names for each individual loss via <code>loss_names</code>.</p>
<p>If passed, <code>weights</code>, <code>loss_kwargs</code>, &amp; <code>loss_names</code> must be an iterable of the same length as <code>loss_funcs</code>.</p>
<p>Output from each loss function must be the same shape.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MultiLossCallback" class="doc_header"><code>class</code> <code>MultiLossCallback</code><a href="https://github.com/warner-benjamin/fastxtend/tree/main/fastxtend/multiloss.py#L162" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MultiLossCallback</code>(<strong><code>beta</code></strong>:<code>float</code>=<em><code>0.98</code></em>, <strong><code>reduction</code></strong>:<code>str | None</code>=<em><code>'mean'</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Callback to automatically log and name <a href="/multiloss.html#MultiLoss"><code>MultiLoss</code></a> losses as fastxtend metrics</p>
<table>
<thead><tr>
<th></th>
<th>Type</th>
<th>Default</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>beta</code></strong></td>
<td><code>float</code></td>
<td><code>0.98</code></td>
<td>Smoothing beta</td>
</tr>
<tr>
<td><strong><code>reduction</code></strong></td>
<td><code>str or None</code></td>
<td><code>mean</code></td>
<td>Override loss reduction for logging</td>
</tr>
</tbody>
</table>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example">Example<a class="anchor-link" href="#Example"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">no_random</span><span class="p">():</span>
    <span class="n">mloss</span> <span class="o">=</span> <span class="n">MultiLoss</span><span class="p">(</span><span class="n">loss_funcs</span><span class="o">=</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">],</span> 
                      <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">],</span>
                      <span class="n">loss_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mse_loss&#39;</span><span class="p">,</span> <span class="s1">&#39;l1_loss&#39;</span><span class="p">])</span>


    <span class="n">learn</span> <span class="o">=</span> <span class="n">synth_learner</span><span class="p">(</span><span class="n">n_trn</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">mloss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">RMSE</span><span class="p">(),</span> <span class="n">cbs</span><span class="o">=</span><span class="n">MultiLossCallback</span><span class="p">)</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>train_mse_loss</th>
      <th>train_l1_loss</th>
      <th>valid_loss</th>
      <th>valid_mse_loss</th>
      <th>valid_l1_loss</th>
      <th>valid_rmse</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>23.598301</td>
      <td>12.719514</td>
      <td>10.878788</td>
      <td>17.910727</td>
      <td>9.067028</td>
      <td>8.843699</td>
      <td>3.011151</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>22.448792</td>
      <td>11.937573</td>
      <td>10.511218</td>
      <td>15.481797</td>
      <td>7.464430</td>
      <td>8.017367</td>
      <td>2.732111</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>20.827835</td>
      <td>10.837888</td>
      <td>9.989948</td>
      <td>12.756706</td>
      <td>5.756156</td>
      <td>7.000550</td>
      <td>2.399199</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>19.028177</td>
      <td>9.657351</td>
      <td>9.370827</td>
      <td>10.031281</td>
      <td>4.145008</td>
      <td>5.886274</td>
      <td>2.035929</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>17.167393</td>
      <td>8.481768</td>
      <td>8.685625</td>
      <td>7.581020</td>
      <td>2.787561</td>
      <td>4.793459</td>
      <td>1.669599</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>


