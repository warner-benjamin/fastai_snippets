{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastxtend\n",
    "> Train fastai models faster (and other useful tools)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "### Train fastai models faster (and other useful tools)\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "![fastxtend accelerates fastai](nbs/images/imagenette_benchmark.png)\n",
    ":::\n",
    "\n",
    "::: {.content-hidden when-format=\"markdown\"}\n",
    "![fastxtend accelerates fastai](images/imagenette_benchmark.svg)\n",
    ":::\n",
    "\n",
    "Train fastai models faster with fastxtend's [fused optimizers](optimizer.fused.html), [Progressive Resizing](callback.progresize.html) callback, and integrated [FFCV DataLoader](ffcv.tutorial.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature overview\n",
    "\n",
    "**Train Models Faster**\n",
    "\n",
    "* Drop in [fused optimizers](optimizer.fused.html), which are 21 to 293 percent faster then fastai native optimizers.\n",
    "* Increase GPU throughput and decrease training time with the [Progressive Resizing](callback.progresize.html) callback.\n",
    "* Use the highly optimized [FFCV DataLoader](ffcv.tutorial.html), fully integrated with fastai.\n",
    "\n",
    "**General Features**\n",
    "\n",
    "* Fused implementations of modern optimizers, such as [Adan](optimizer.adan.html) and [Lion](optimizer.lion.html).\n",
    "* Flexible [metrics](metrics.html) which can log on train, valid, or both. Backwards compatible with fastai metrics.\n",
    "* Easily use [multiple losses](multiloss.html) and log each individual loss on train and valid.\n",
    "* [Multiple profilers](callback.profiler.html) for profiling training and identifying bottlenecks.\n",
    "* A fast [Exponential Moving Average](callback.ema.html) callback for smoother training.\n",
    "\n",
    "**Vision**\n",
    "\n",
    "* Apply `MixUp`, `CutMix`, or Augmentations at once with `CutMixUp` or `CutMixUpAugment`.\n",
    "* Additional [image augmentations](vision.augment.batch.html).\n",
    "* Support for running fastai [batch transforms on CPU](vision.data.html).\n",
    "* More [attention](vision.models.attention_modules.html) and [pooling](vision.models.pooling.html) modules\n",
    "* A flexible implementation of fastai’s `XResNet`.\n",
    "\n",
    "**Audio**\n",
    "\n",
    "* `TensorAudio`, `TensorSpec`, `TensorMelSpec` objects which maintain metadata and support plotting themselves using librosa.\n",
    "* A selection of performant [audio augmentations](audio.augment.html) inspired by fastaudio and torch-audiomentations.\n",
    "* Uses TorchAudio to quickly convert `TensorAudio` waveforms into `TensorSpec` spectrograms or `TensorMelSpec` mel spectrograms using the GPU.\n",
    "* Out of the box support for converting one `TensorAudio` to one or multiple `TensorSpec` or `TensorMelSpec` objects from the Datablock api.\n",
    "* Audio [MixUp and CutMix](audio.mixup.html) Callbacks.\n",
    "* `audio_learner` which merges multiple `TensorSpec` or `TensorMelSpec` objects before passing to the model.\n",
    "\n",
    "Check out the documentation for additional splitters, callbacks, schedulers, utilities, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "## Documentation\n",
    "<https://fastxtend.benjaminwarner.dev>\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "fastxtend is avalible on pypi:\n",
    "```bash\n",
    "pip install fastxtend\n",
    "```\n",
    "\n",
    "To install with dependencies for vision, FFCV, audio, or all tasks run one of:\n",
    "```bash\n",
    "pip install fastxtend[vision]\n",
    "\n",
    "pip install fastxtend[ffcv]\n",
    "\n",
    "pip install fastxtend[audio]\n",
    "\n",
    "pip install fastxtend[all]\n",
    "```\n",
    "\n",
    "Or to create an editable development install:\n",
    "```bash\n",
    "git clone https://github.com/warner-benjamin/fastxtend.git\n",
    "cd fastxtend\n",
    "pip install -e \".[dev]\"\n",
    "```\n",
    "\n",
    "To easily install prerequisites for all fastxtend features, use [Conda](https://docs.conda.io/en/latest) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html):\n",
    "\n",
    "```bash\n",
    "conda create -n fastxtend python=3.10 pytorch torchvision \\\n",
    "torchaudio pytorch-cuda=11.8 cuda fastai nbdev pkg-config \\\n",
    "libjpeg-turbo opencv tqdm terminaltables psutil numpy=1.23.5 \\\n",
    "numba librosa=0.9.2 timm kornia rich typer wandb -c pytorch \\\n",
    "-c nvidia/label/cuda-11.8.0 -c fastai -c huggingface -c conda-forge\n",
    "\n",
    "conda activate fastxtend\n",
    "```\n",
    "replacing `pytorch-cuda=11.8` and `nvidia/label/cuda-11.8.0` with your preferred [supported version of Cuda](https://pytorch.org/get-started/locally). Then install fastxtend using `pip`:\n",
    "\n",
    "```bash\n",
    "pip install fastxtend[all]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "Like fastai, fastxtend provides safe wildcard imports using python’s `__all__`. \n",
    "```python\n",
    "from fastai.vision.all import *\n",
    "from fastxtend.vision.all import *\n",
    "from fastxtend.ffcv.all import *\n",
    "```\n",
    "In general, import fastxtend after all fastai imports, as fastxtend modifies fastai. Any method modified by fastxtend is backwards compatible with the original fastai code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Use a fused ForEach optimizer:\n",
    "```python\n",
    "Learner(..., opt_func=adam(foreach=True))\n",
    "```\n",
    "\n",
    "Log an accuracy metric on the training set as a smoothed metric and validation set like normal:\n",
    "```python\n",
    "Learner(..., metrics=[Accuracy(log_metric=LogMetric.Train, metric_type=MetricType.Smooth),\n",
    "                      Accuracy()])\n",
    "```\n",
    "\n",
    "Log multiple losses as individual metrics on train and valid:\n",
    "```python\n",
    "mloss = MultiLoss(loss_funcs=[nn.MSELoss, nn.L1Loss],\n",
    "                  weights=[1, 3.5], loss_names=['mse_loss', 'l1_loss'])\n",
    "\n",
    "Learner(..., loss_func=mloss, metrics=RMSE(), cbs=MultiLossCallback)\n",
    "```\n",
    "\n",
    "Apply MixUp, CutMix, or Augmentation while training:\n",
    "```python\n",
    "Learner(..., cbs=CutMixUpAugment)\n",
    "```\n",
    "\n",
    "Profile a fastai training loop:\n",
    "```python\n",
    "from fastxtend.callback import simpleprofiler\n",
    "\n",
    "learn = Learner(...).profile()\n",
    "learn.fit_one_cycle(2, 3e-3)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "To run the benchmark on your own machine, see the [example scripts](https://github.com/warner-benjamin/fastxtend/tree/main/examples) for details on how to replicate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
