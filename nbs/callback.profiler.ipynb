{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "    - callback.simpleprofiler.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "# Contains code from:\n",
    "# fastai - Apache License 2.0 - Copyright (c) 2023 fast.ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiler\n",
    "> Callbacks which add a throughput and simple profiler to fastai. Inspired by PyTorch Lightning's SimpleProfiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import locale\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from packaging.version import parse\n",
    "\n",
    "from fastcore.foundation import docs\n",
    "from fastcore.basics import mk_class, noop, in_notebook\n",
    "\n",
    "import fastai\n",
    "from fastai.learner import Learner, Recorder\n",
    "from fastai.callback.core import *\n",
    "\n",
    "from fastxtend.imports import *\n",
    "from fastxtend.utils import scale_time\n",
    "\n",
    "if in_notebook():\n",
    "    from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastai.test_utils import synth_learner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since fastxtend profilers change the fastai data loading loop, they are not imported by any of the fastxtend all imports and need to be imported seperately:\n",
    "\n",
    "```python\n",
    "from fastxtend.callback import profiler\n",
    "```\n",
    "\n",
    "::: {.callout-warning}\n",
    "Throughput and Simple Profiler are untested on distributed training.\n",
    ":::\n",
    "\n",
    "Jump to usage [examples](#examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "fastai callbacks do not have an event which is called directly before drawing a batch. fastxtend profilers add a new callback event called `before_draw`.\n",
    "\n",
    "With a fastxtend profiler imported, a callback can implement actions on the following events:\n",
    "\n",
    "- `after_create`: called after the `Learner` is created\n",
    "- `before_fit`: called before starting training or inference, ideal for initial setup.\n",
    "- `before_epoch`: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch.\n",
    "- `before_train`: called at the beginning of the training part of an epoch.\n",
    "- **`before_draw`**: called at the beginning of each batch, just before drawing said batch.\n",
    "- `before_batch`: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).\n",
    "- `after_pred`: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.\n",
    "- `after_loss`: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).\n",
    "- `before_backward`: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)\n",
    "- `before_step`: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).\n",
    "- `after_step`: called after the step and before the gradients are zeroed.\n",
    "- `after_batch`: called at the end of a batch, for any clean-up before the next one.\n",
    "- `after_train`: called at the end of the training phase of an epoch.\n",
    "- `before_validate`: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.\n",
    "- `after_validate`: called at the end of the validation part of an epoch.\n",
    "- `after_epoch`: called at the end of an epoch, for any clean-up before the next one.\n",
    "- `after_fit`: called at the end of training, for final clean-up."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement before_draw -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "To add `before_draw` as a callable event, first it needs to be added to both the `_inner_loop` and `_events` lists of fastai events (fastai 2.7.0 adds new backward events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "if parse(fastai.__version__) >= parse('2.7.0'):\n",
    "    _inner_loop = \"before_draw before_batch after_pred after_loss before_backward after_cancel_backward after_backward before_step after_step after_cancel_batch after_batch\".split()\n",
    "else:\n",
    "    _inner_loop = \"before_draw before_batch after_pred after_loss before_backward before_step after_step after_cancel_batch after_batch\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "if parse(fastai.__version__) >= parse('2.7.0'):\n",
    "    _events = L.split('after_create before_fit before_epoch before_train before_draw before_batch after_pred after_loss \\\n",
    "        before_backward after_cancel_backward after_backward before_step after_cancel_step after_step \\\n",
    "        after_cancel_batch after_batch after_cancel_train after_train before_validate after_cancel_validate \\\n",
    "        after_validate after_cancel_epoch after_epoch after_cancel_fit after_fit')\n",
    "else:\n",
    "    _events = L.split('after_create before_fit before_epoch before_train before_draw before_batch after_pred after_loss \\\n",
    "        before_backward before_step after_cancel_step after_step after_cancel_batch after_batch after_cancel_train \\\n",
    "        after_train before_validate after_cancel_validate after_validate after_cancel_epoch \\\n",
    "        after_epoch after_cancel_fit after_fit')\n",
    "\n",
    "mk_class('event', **_events.map_dict(),\n",
    "         doc=\"All possible events as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "Next, `Callback` needs to be modified to be aware of the new event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@patch\n",
    "def __call__(self:Callback, event_name):\n",
    "    \"Call `self.{event_name}` if it's defined\"\n",
    "    _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n",
    "            (self.run_valid and not getattr(self, 'training', False)))\n",
    "    res = None\n",
    "    if self.run and _run:\n",
    "        try: res = getattr(self, event_name, noop)()\n",
    "        except (CancelBatchException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): raise\n",
    "        except Exception as e:\n",
    "            e.args = [f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\\n\\t{e.args[0]}']\n",
    "            raise\n",
    "    if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "Then `Learner._call_one` needs to be aware of the `before_draw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@patch\n",
    "def _call_one(self:Learner, event_name):\n",
    "    if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n",
    "    for cb in self.cbs.sorted('order'): cb(event_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "Finally, `Learner.all_batches` can be modified to call `before_draw` when iterating through a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@patch\n",
    "def all_batches(self:Learner):\n",
    "    self.n_iter = len(self.dl)\n",
    "    self.it = iter(self.dl)\n",
    "    for i in range(self.n_iter):\n",
    "        self(\"before_draw\")\n",
    "        self.one_batch(i, next(self.it))\n",
    "    del(self.it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_loop = ['Start Fit', 'before_fit', 'Start Epoch Loop', 'before_epoch', 'Start Train', 'before_train',\n",
    "         'Start Batch Loop', 'before_draw', 'before_batch', 'after_pred', 'after_loss', 'before_backward',\n",
    "         'before_step', 'after_step', 'after_cancel_batch', 'after_batch','End Batch Loop', 'End Train',\n",
    "         'after_cancel_train', 'after_train', 'Start Valid', 'before_validate', 'Start Batch Loop',\n",
    "         '**CBs same as train batch**', 'End Batch Loop', 'End Valid', 'after_cancel_validate',\n",
    "         'after_validate', 'End Epoch Loop', 'after_cancel_epoch', 'after_epoch', 'End Fit',\n",
    "         'after_cancel_fit', 'after_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@patch\n",
    "def show_training_loop(self:Learner):\n",
    "    indent = 0\n",
    "    for s in _loop:\n",
    "        if s.startswith('Start'): print(f'{\" \"*indent}{s}'); indent += 2\n",
    "        elif s.startswith('End'): indent -= 2; print(f'{\" \"*indent}{s}')\n",
    "        else: print(f'{\" \"*indent} - {s:15}:', self.ordered_cbs(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput\n",
    "The Throughput profiler only measures the `step`, `draw`, and `batch`. To use, both `ThroughputCallback` and `ThroughputPostCallback` must be added to the `Learner`. The recommended way to use is via `Learner.profile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_phase = ['fit', 'epoch', 'train', 'valid']\n",
    "_epoch = ['train', 'valid']\n",
    "_train_full  = ['step', 'draw', 'batch', 'forward', 'loss', 'backward', 'opt_step', 'zero_grad']\n",
    "_valid_full  = ['step', 'draw', 'batch', 'predict', 'loss']\n",
    "_train_short = ['step', 'draw', 'batch']\n",
    "_valid_short = _train_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ThroughputCallback(Callback):\n",
    "    \"\"\"\n",
    "    Adds a throughput profiler to the fastai `Learner`. Optionally showing formatted report or saving unformatted results as csv.\n",
    "\n",
    "    Pair with ThroughputPostCallback to profile training performance.\n",
    "\n",
    "    Post fit, access report & results via `Learner.profile_report` & `Learner.profile_results`.\n",
    "    \"\"\"\n",
    "    order,remove_on_fetch = TrainEvalCallback.order+1,True\n",
    "    def __init__(self,\n",
    "        show_report:bool=True, # Display formatted report post profile\n",
    "        plain:bool=False, # For Jupyter Notebooks, display plain report\n",
    "        markdown:bool=False, # Display markdown formatted report\n",
    "        save_csv:bool=False,  # Save raw results to csv\n",
    "        csv_name:str='throughput.csv', # CSV save location\n",
    "        rolling_average:int=10, # Number of batches to average throughput over\n",
    "        drop_first_batch:bool=True, # Drop the first batch from profiling\n",
    "        logger_callback='wandb' # Log report and samples/second to `logger_callback` using `Callback.name`\n",
    "    ):\n",
    "        store_attr(but='csv_name,average,drop_first_batch')\n",
    "        self.csv_name = Path(csv_name)\n",
    "        self._drop = int(drop_first_batch)\n",
    "        self._rolling_average = rolling_average\n",
    "        self._log_after_batch = getattr(self, f'_{logger_callback}_log_after_batch', noop)\n",
    "        self._log_after_fit   = getattr(self, f'_{logger_callback}_log_after_fit', noop)\n",
    "        self._phase, self._train, self._valid = _phase, _train_short, _valid_short\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.has_logger = hasattr(self.learn, self.logger_callback) and not hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\")\n",
    "        self._raw_values, self._processed_samples = {}, {}\n",
    "        for p in _phase:\n",
    "            self._raw_values[p] = []\n",
    "        for p in _epoch:\n",
    "            for a in getattr(self, f'_{p}'):\n",
    "                if a!='samples':\n",
    "                    self._raw_values[f'{p}_{a}'] = []\n",
    "            self._raw_values[f'{p}_bs'] = []\n",
    "        self._fit_start = time.perf_counter()\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self._epoch_start = time.perf_counter()\n",
    "\n",
    "    def before_train(self):\n",
    "        self._train_start = time.perf_counter()\n",
    "\n",
    "    def before_validate(self):\n",
    "        self._validate_start = time.perf_counter()\n",
    "\n",
    "    def before_draw(self):\n",
    "        if self.training:\n",
    "            self._train_draw_start = time.perf_counter()\n",
    "        else:\n",
    "            self._valid_draw_start = time.perf_counter()\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.training:\n",
    "            self._raw_values['train_draw'].append(time.perf_counter() - self._train_draw_start)\n",
    "            self._train_batch_start = time.perf_counter()\n",
    "        else:\n",
    "            self._raw_values['valid_draw'].append(time.perf_counter() - self._valid_draw_start)\n",
    "            self._valid_batch_start = time.perf_counter()\n",
    "\n",
    "    def _samples_per_second(self, bs, action, epoch='train'):\n",
    "        if action in ['step', 'draw']:\n",
    "            batch = np.mean(self._raw_values[f'{epoch}_batch'][-self._rolling_average:])\n",
    "            draw = np.mean(self._raw_values[f'{epoch}_draw'][-self._rolling_average:])\n",
    "            return -((bs/batch if action=='draw' else 0) - bs/(draw+batch))\n",
    "        else:\n",
    "            return bs/np.mean(self._raw_values[f'{epoch}_{action}'][-self._rolling_average:])\n",
    "\n",
    "    def _generate_report(self):\n",
    "        total_time = self._raw_values['fit'][0]\n",
    "        self.report = pd.DataFrame(columns=['Phase', 'Action', 'Mean Duration', 'Duration Std Dev',\n",
    "                                            'Number of Calls', 'Samples/Second', 'Total Time', 'Percent of Total'])\n",
    "        for p in _phase:\n",
    "            if p == 'fit':\n",
    "                self._append_to_df(['fit', p, 0, 0, 1, '-', total_time, f'{self._calc_percent(total_time):.0%}'])\n",
    "            elif p == 'epoch':\n",
    "                self._append_to_df(self._create_overview_row('fit', p, self._raw_values[p], None))\n",
    "            else:\n",
    "                self._append_to_df(self._create_overview_row('fit', p, self._raw_values[p], np.array(self._raw_values[f'{p}_bs'])))\n",
    "\n",
    "        for p in _epoch:\n",
    "            bs = np.array(self._raw_values[f'{p}_bs'])\n",
    "            for a in getattr(self, f'_{p}'):\n",
    "                if a == 'step':\n",
    "                    values = np.array(self._raw_values[f'{p}_draw']) + np.array(self._raw_values[f'{p}_batch'])\n",
    "                else:\n",
    "                    values = np.array(self._raw_values[f'{p}_{a}'])\n",
    "                self._append_to_df(self._create_detail_row(p, a, values, bs))\n",
    "\n",
    "        self.learn.profile_results = self.report.copy()\n",
    "        for c in ['Mean Duration', 'Duration Std Dev', 'Total Time']:\n",
    "            self.report[c] = self.report[c].apply(scale_time)\n",
    "        self.report[['Phase', 'Action']] = self.report[['Phase', 'Action']].where(~self.report[['Phase', 'Action']].duplicated(), '')\n",
    "        self.report['Phase']  = self.report['Phase'].where(~self.report['Phase'].duplicated(), '')\n",
    "        self.report['Action'] = self.report['Action'].where(self.report['Phase'] != self.report['Action']).fillna('')\n",
    "        self.learn.profile_report = self.report\n",
    "\n",
    "    def _display_report(self):\n",
    "        if self.show_report:\n",
    "            if self.markdown:\n",
    "                print(self.report.to_markdown(index=False))\n",
    "            else:\n",
    "                if in_notebook() and not self.plain:\n",
    "                    with pd.option_context('display.max_rows', len(self.report.index)):\n",
    "                        s = self.report.style.set_caption(\"Profiling Results\").hide(axis='index')\n",
    "                        display(s)\n",
    "                else:\n",
    "                    print('Profiling Results')\n",
    "                    print(self.report.to_string(index=False))\n",
    "            if self._drop > 0:\n",
    "                print(f'Batch dropped. train and valid phases show {self._drop} less batch than fit.')\n",
    "        if self.save_csv:\n",
    "            self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            self.learn.profile_results.to_csv(self.path/self.csv_name, index=False)\n",
    "\n",
    "    def _append_to_df(self, row):\n",
    "        self.report.loc[len(self.report.index)] = row\n",
    "\n",
    "    def _calc_percent(self, time):\n",
    "        return time / self._raw_values['fit'][0]\n",
    "\n",
    "    def _create_overview_row(self, phase, action, input, bs=None):\n",
    "        if bs is not None:\n",
    "            draw = np.array(self._raw_values[f'{action}_draw'])\n",
    "            batch = np.array(self._raw_values[f'{action}_batch'])\n",
    "            self._processed_samples[f'{phase}_{action}'] = bs/(draw+batch)\n",
    "            sam_per_sec = f'{int(np.around(self._processed_samples[f\"{phase}_{action}\"].mean())):,d}'\n",
    "        else:\n",
    "            sam_per_sec = '-'\n",
    "        return [phase, action, np.mean(input), np.std(input), len(input), sam_per_sec,\n",
    "                np.sum(input), f'{self._calc_percent(np.sum(input)):.0%}']\n",
    "\n",
    "    def _create_detail_row(self, phase, action, input, bs=None):\n",
    "        input = input[self._drop:]\n",
    "        if bs is None or action=='zero_grad':\n",
    "            sam_per_sec = '-'\n",
    "        elif action == 'draw':\n",
    "            bs = np.array(bs[self._drop:])\n",
    "            batch = np.array(self._raw_values[f'{phase}_batch'][self._drop:])\n",
    "            self._processed_samples[f'{phase}_{action}'] = -(bs/batch - bs/(input+batch))\n",
    "            sam_per_sec = f'{int(np.around(self._processed_samples[f\"{phase}_{action}\"].mean())):,d}'\n",
    "        else:\n",
    "            bs = np.array(bs[self._drop:])\n",
    "            self._processed_samples[f'{phase}_{action}'] = bs/input\n",
    "            sam_per_sec = f'{int(np.around(self._processed_samples[f\"{phase}_{action}\"].mean())):,d}'\n",
    "        return [phase, action, np.mean(input), np.std(input), len(input), sam_per_sec,\n",
    "                np.sum(input), f'{self._calc_percent(np.sum(input)):.0%}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ThroughputPostCallback(Callback):\n",
    "    \"Required pair with `ThroughputCallback` to profile training performance. Removes itself after training is over.\"\n",
    "    order,remove_on_fetch = Recorder.order-1,True\n",
    "    def __init__(self):\n",
    "        self._log_full = False\n",
    "        self._phase, self._train, self._valid = _phase, _train_short, _train_short\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.profiler = self.learn.throughput\n",
    "        self.has_logger = self.profiler.has_logger\n",
    "        self._start_train_logging, self._start_valid_logging = False, False\n",
    "        self.n_train_batches = len(self.dls.train)\n",
    "        self.n_valid_batches = len(self.dls.valid)\n",
    "        self._rolling_average = self.profiler._rolling_average\n",
    "        self._iter = -self.profiler._drop\n",
    "\n",
    "    def after_train(self):\n",
    "        self.profiler._raw_values['train'].append(time.perf_counter() - self.profiler._train_start)\n",
    "\n",
    "    def after_validate(self):\n",
    "        self.profiler._raw_values['valid'].append(time.perf_counter() - self.profiler._validate_start)\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training:\n",
    "            self.profiler._raw_values['train_batch'].append(time.perf_counter() - self.profiler._train_batch_start)\n",
    "            self.profiler._raw_values['train_bs'].append(find_bs(self.learn.yb))\n",
    "            if self.has_logger and self._iter >= self._rolling_average and self._iter % self._rolling_average == 0:\n",
    "                self.profiler._log_after_batch(self._train)\n",
    "            self._iter += 1\n",
    "        else:\n",
    "            self.profiler._raw_values['valid_batch'].append(time.perf_counter() - self.profiler._valid_batch_start)\n",
    "            self.profiler._raw_values['valid_bs'].append(find_bs(self.learn.yb))\n",
    "\n",
    "    def after_epoch(self):\n",
    "        self.profiler._raw_values['epoch'].append(time.perf_counter() - self.profiler._epoch_start)\n",
    "\n",
    "    def _after_fit(self, callbacks):\n",
    "        self.profiler._raw_values['fit'].append(time.perf_counter() - self.profiler._fit_start)\n",
    "        self.profiler._generate_report()\n",
    "        if self.has_logger: self.profiler._log_after_fit()\n",
    "        if not hasattr(self.learn, 'lr_finder'):\n",
    "            self.profiler._display_report()\n",
    "            self.learn.remove_cbs(callbacks)\n",
    "\n",
    "    def after_fit(self):\n",
    "        self._after_fit([ThroughputCallback, ThroughputPostCallback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Profiler\n",
    "To use, both `SimpleProfilerCallback` and `SimpleProfilerPostCallback` must be added to the `Learner`. The recommended way to use is via `Learner.profile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleProfilerCallback(ThroughputCallback):\n",
    "    \"\"\"\n",
    "    Adds a simple profiler to the fastai `Learner`. Optionally showing formatted report or saving unformatted results as csv.\n",
    "\n",
    "    Pair with SimpleProfilerPostCallback to profile training performance.\n",
    "\n",
    "    Post fit, access report & results via `Learner.profile_report` & `Learner.profile_results`.\n",
    "    \"\"\"\n",
    "    order,remove_on_fetch = TrainEvalCallback.order+1,True\n",
    "    def __init__(self,\n",
    "        show_report:bool=True, # Display formatted report post profile\n",
    "        plain:bool=False, # For Jupyter Notebooks, display plain report\n",
    "        markdown:bool=False, # Display markdown formatted report\n",
    "        save_csv:bool=False,  # Save raw results to csv\n",
    "        csv_name:str='simpleprofiler.csv', # CSV save location\n",
    "        rolling_average:int=10, # Number of batches to average throughput over\n",
    "        drop_first_batch:bool=True, # Drop the first batch from profiling\n",
    "        logger_callback='wandb' # Log report and samples/second to `logger_callback` using `Callback.name`\n",
    "    ):\n",
    "        super().__init__(show_report=show_report, plain=plain, markdown=markdown, save_csv=save_csv,\n",
    "                         csv_name=csv_name, rolling_average=rolling_average, drop_first_batch=drop_first_batch,\n",
    "                         logger_callback=logger_callback)\n",
    "        self._phase, self._train, self._valid = _phase, _train_full, _valid_full\n",
    "\n",
    "    def before_backward(self):\n",
    "        self._backward_start = time.perf_counter()\n",
    "\n",
    "    def before_step(self):\n",
    "        self._raw_values['train_backward'].append(time.perf_counter() - self._backward_start)\n",
    "        self._step_start = time.perf_counter()\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training:\n",
    "            self._raw_values['train_zero_grad'].append(time.perf_counter() - self._zero_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleProfilerPostCallback(ThroughputPostCallback):\n",
    "    \"Required pair with `SimpleProfilerCallback` to profile training performance. Removes itself after training is over.\"\n",
    "    order,remove_on_fetch = Recorder.order-1,True\n",
    "    def __init__(self):\n",
    "        self._log_full = True\n",
    "        self._phase, self._train, self._valid = _phase, _train_full, _valid_full\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.profiler = self.learn.simple_profiler\n",
    "        self._start_logging = self.profiler._rolling_average + self.profiler._drop\n",
    "        self.has_logger = self.profiler.has_logger\n",
    "        self._start_train_logging, self._start_valid_logging = False, False\n",
    "        self.n_train_batches = len(self.dls.train)\n",
    "        self.n_valid_batches = len(self.dls.valid)\n",
    "\n",
    "    def after_pred(self):\n",
    "        if self.training:\n",
    "            self.profiler._raw_values['train_forward'].append(time.perf_counter() - self.profiler._train_batch_start)\n",
    "            self.profiler._train_loss_start = time.perf_counter()\n",
    "        else:\n",
    "            self.profiler._raw_values['valid_predict'].append(time.perf_counter() - self.profiler._valid_batch_start)\n",
    "            self.profiler._valid_loss_start = time.perf_counter()\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.training:\n",
    "            self.profiler._raw_values['train_loss'].append(time.perf_counter() - self.profiler._train_loss_start)\n",
    "        else:\n",
    "            self.profiler._raw_values['valid_loss'].append(time.perf_counter() - self.profiler._valid_loss_start)\n",
    "\n",
    "    def after_step(self):\n",
    "        self.profiler._raw_values['train_opt_step'].append(time.perf_counter() - self.profiler._step_start)\n",
    "        self.profiler._zero_start = time.perf_counter()\n",
    "\n",
    "    def after_fit(self):\n",
    "        self._after_fit([SimpleProfilerCallback, SimpleProfilerPostCallback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Method\n",
    "`Learner.profile` is the easy and recommended way to use a fastxtend profiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProfileMode(Enum):\n",
    "    \"Profile enum for `Learner.profile`\"\n",
    "    Throughput = 'throughput'\n",
    "    Simple     = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def profile(self:Learner,\n",
    "        mode:ProfileMode=ProfileMode.Throughput, # Which profiler to use. Throughput or Simple.\n",
    "        show_report:bool=True, # Display formatted report post profile\n",
    "        plain:bool=False, # For Jupyter Notebooks, display plain report\n",
    "        markdown:bool=False, # Display markdown formatted report\n",
    "        save_csv:bool=False,  # Save raw results to csv\n",
    "        csv_name:str='simpleprofiler.csv', # CSV save location\n",
    "        rolling_average:int=10, # Number of batches to average throughput over\n",
    "        drop_first_batch:bool=True, # Drop the first batch from profiling\n",
    "        logger_callback='wandb' # Log report and samples/second to `logger_callback` using `Callback.name`\n",
    "    ):\n",
    "    \"Run a fastxtend profiler which removes itself when finished training.\"\n",
    "    if mode == ProfileMode.Throughput:\n",
    "        self.add_cbs([ThroughputCallback(show_report=show_report, plain=plain, markdown=markdown, \n",
    "                                         save_csv=save_csv, csv_name=csv_name, rolling_average=rolling_average, \n",
    "                                         drop_first_batch=drop_first_batch, logger_callback=logger_callback),\n",
    "                      ThroughputPostCallback()\n",
    "                ])\n",
    "    if mode == ProfileMode.Simple:\n",
    "        self.add_cbs([SimpleProfilerCallback(show_report=show_report, plain=plain, markdown=markdown, \n",
    "                                             save_csv=save_csv, csv_name=csv_name, rolling_average=rolling_average, \n",
    "                                             drop_first_batch=drop_first_batch, logger_callback=logger_callback),\n",
    "                      SimpleProfilerPostCallback()\n",
    "                ])\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Simple Profiler report contains the following items divided in three Phases (Fit, Train, & Valid)\n",
    "\n",
    "Fit:\n",
    "\n",
    "- `fit`:  total time fitting the model takes.\n",
    "- `epoch`: duration of both training and validation epochs. Often epoch total time is the same amount of elapsed time as fit.\n",
    "- `train`: duration of each training epoch.\n",
    "- `valid`: duration of each validation epoch.\n",
    "\n",
    "Train:\n",
    "\n",
    "- `step`: total duration of all batch steps including drawing the batch. Measured from `before_draw` to `after_batch`.\n",
    "- `draw`: time spent waiting for a batch to be drawn. Measured from `before_draw` to `before_batch`. Ideally this value should be as close to zero as possible. \n",
    "- `batch`: total duration of all batch steps except drawing the batch. Measured from `before_batch` to `after_batch`.\n",
    "- `forward`: duration of the forward pass and any additional batch modifications. Measured from `before_batch` to `after_pred`.\n",
    "- `loss`: duration of calculating loss. Measured from `after_pred` to `after_loss`.\n",
    "- `backward`: duration of the backward pass. Measured from `before_backward` to `before_step`.\n",
    "- `opt_step`: duration of the optimizer step. Measured from `before_step` to `after_step`.\n",
    "- `zero_grad`: duration of the zero_grad step. Measured from `after_step` to `after_batch`.\n",
    "\n",
    "Valid:\n",
    "\n",
    "- `step`: total duration of all batch steps including drawing the batch. Measured from `before_draw` to `after_batch`.\n",
    "- `draw`: time spent waiting for a batch to be drawn. Measured from `before_draw` to `before_batch`. Ideally this value should be as close to zero as possible. \n",
    "- `batch`: total duration of all batch steps except drawing the batch. Measured from `before_batch` to `after_batch`.\n",
    "- `predict`: duration of the prediction pass and any additional batch modifications. Measured from `before_batch` to `after_pred`.\n",
    "- `loss`: duration of calculating loss. Measured from `after_pred` to `after_loss`.\n",
    "\n",
    "The Throughput profiler only contains `step`, `draw`, and `batch`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "These examples are trained on Imagenette with an image size of 224 and batch size of 64 on a 3080 Ti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.vision.augment import Resize\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models.xresnet import xresnext50\n",
    "from fastxtend.optimizer.fused import adam\n",
    "from fastxtend.metrics import *\n",
    "from fastxtend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                    splitter=GrandparentSplitter(valid_name='val'),\n",
    "                    get_items=get_image_files, get_y=parent_label,\n",
    "                    item_tfms=Resize(224),\n",
    "                    batch_tfms=[Normalize.from_stats(*imagenet_stats)])\n",
    "dls = dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.501953</td>\n",
       "      <td>1.734705</td>\n",
       "      <td>0.472357</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.040516</td>\n",
       "      <td>0.913281</td>\n",
       "      <td>0.712866</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6d54b\">\n",
       "  <caption>Profiling Results</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_6d54b_level0_col0\" class=\"col_heading level0 col0\" >Phase</th>\n",
       "      <th id=\"T_6d54b_level0_col1\" class=\"col_heading level0 col1\" >Action</th>\n",
       "      <th id=\"T_6d54b_level0_col2\" class=\"col_heading level0 col2\" >Mean Duration</th>\n",
       "      <th id=\"T_6d54b_level0_col3\" class=\"col_heading level0 col3\" >Duration Std Dev</th>\n",
       "      <th id=\"T_6d54b_level0_col4\" class=\"col_heading level0 col4\" >Number of Calls</th>\n",
       "      <th id=\"T_6d54b_level0_col5\" class=\"col_heading level0 col5\" >Samples/Second</th>\n",
       "      <th id=\"T_6d54b_level0_col6\" class=\"col_heading level0 col6\" >Total Time</th>\n",
       "      <th id=\"T_6d54b_level0_col7\" class=\"col_heading level0 col7\" >Percent of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row0_col0\" class=\"data row0 col0\" >fit</td>\n",
       "      <td id=\"T_6d54b_row0_col1\" class=\"data row0 col1\" ></td>\n",
       "      <td id=\"T_6d54b_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_6d54b_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_6d54b_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "      <td id=\"T_6d54b_row0_col5\" class=\"data row0 col5\" >-</td>\n",
       "      <td id=\"T_6d54b_row0_col6\" class=\"data row0 col6\" >35.63 s</td>\n",
       "      <td id=\"T_6d54b_row0_col7\" class=\"data row0 col7\" >100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row1_col0\" class=\"data row1 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row1_col1\" class=\"data row1 col1\" >epoch</td>\n",
       "      <td id=\"T_6d54b_row1_col2\" class=\"data row1 col2\" >17.81 s</td>\n",
       "      <td id=\"T_6d54b_row1_col3\" class=\"data row1 col3\" >838.2ms</td>\n",
       "      <td id=\"T_6d54b_row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "      <td id=\"T_6d54b_row1_col5\" class=\"data row1 col5\" >-</td>\n",
       "      <td id=\"T_6d54b_row1_col6\" class=\"data row1 col6\" >35.63 s</td>\n",
       "      <td id=\"T_6d54b_row1_col7\" class=\"data row1 col7\" >100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row2_col1\" class=\"data row2 col1\" >train</td>\n",
       "      <td id=\"T_6d54b_row2_col2\" class=\"data row2 col2\" >14.24 s</td>\n",
       "      <td id=\"T_6d54b_row2_col3\" class=\"data row2 col3\" >797.1ms</td>\n",
       "      <td id=\"T_6d54b_row2_col4\" class=\"data row2 col4\" >2</td>\n",
       "      <td id=\"T_6d54b_row2_col5\" class=\"data row2 col5\" >678</td>\n",
       "      <td id=\"T_6d54b_row2_col6\" class=\"data row2 col6\" >28.49 s</td>\n",
       "      <td id=\"T_6d54b_row2_col7\" class=\"data row2 col7\" >80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row3_col0\" class=\"data row3 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row3_col1\" class=\"data row3 col1\" >valid</td>\n",
       "      <td id=\"T_6d54b_row3_col2\" class=\"data row3 col2\" >3.565 s</td>\n",
       "      <td id=\"T_6d54b_row3_col3\" class=\"data row3 col3\" >39.48ms</td>\n",
       "      <td id=\"T_6d54b_row3_col4\" class=\"data row3 col4\" >2</td>\n",
       "      <td id=\"T_6d54b_row3_col5\" class=\"data row3 col5\" >1,311</td>\n",
       "      <td id=\"T_6d54b_row3_col6\" class=\"data row3 col6\" >7.130 s</td>\n",
       "      <td id=\"T_6d54b_row3_col7\" class=\"data row3 col7\" >20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row4_col0\" class=\"data row4 col0\" >train</td>\n",
       "      <td id=\"T_6d54b_row4_col1\" class=\"data row4 col1\" >step</td>\n",
       "      <td id=\"T_6d54b_row4_col2\" class=\"data row4 col2\" >86.62ms</td>\n",
       "      <td id=\"T_6d54b_row4_col3\" class=\"data row4 col3\" >41.67ms</td>\n",
       "      <td id=\"T_6d54b_row4_col4\" class=\"data row4 col4\" >293</td>\n",
       "      <td id=\"T_6d54b_row4_col5\" class=\"data row4 col5\" >739</td>\n",
       "      <td id=\"T_6d54b_row4_col6\" class=\"data row4 col6\" >25.38 s</td>\n",
       "      <td id=\"T_6d54b_row4_col7\" class=\"data row4 col7\" >71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row5_col0\" class=\"data row5 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row5_col1\" class=\"data row5 col1\" >draw</td>\n",
       "      <td id=\"T_6d54b_row5_col2\" class=\"data row5 col2\" >4.269ms</td>\n",
       "      <td id=\"T_6d54b_row5_col3\" class=\"data row5 col3\" >37.39ms</td>\n",
       "      <td id=\"T_6d54b_row5_col4\" class=\"data row5 col4\" >293</td>\n",
       "      <td id=\"T_6d54b_row5_col5\" class=\"data row5 col5\" >-38</td>\n",
       "      <td id=\"T_6d54b_row5_col6\" class=\"data row5 col6\" >1.251 s</td>\n",
       "      <td id=\"T_6d54b_row5_col7\" class=\"data row5 col7\" >4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row6_col0\" class=\"data row6 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row6_col1\" class=\"data row6 col1\" >batch</td>\n",
       "      <td id=\"T_6d54b_row6_col2\" class=\"data row6 col2\" >82.35ms</td>\n",
       "      <td id=\"T_6d54b_row6_col3\" class=\"data row6 col3\" >4.472ms</td>\n",
       "      <td id=\"T_6d54b_row6_col4\" class=\"data row6 col4\" >293</td>\n",
       "      <td id=\"T_6d54b_row6_col5\" class=\"data row6 col5\" >777</td>\n",
       "      <td id=\"T_6d54b_row6_col6\" class=\"data row6 col6\" >24.13 s</td>\n",
       "      <td id=\"T_6d54b_row6_col7\" class=\"data row6 col7\" >68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row7_col0\" class=\"data row7 col0\" >valid</td>\n",
       "      <td id=\"T_6d54b_row7_col1\" class=\"data row7 col1\" >step</td>\n",
       "      <td id=\"T_6d54b_row7_col2\" class=\"data row7 col2\" >43.05ms</td>\n",
       "      <td id=\"T_6d54b_row7_col3\" class=\"data row7 col3\" >63.38ms</td>\n",
       "      <td id=\"T_6d54b_row7_col4\" class=\"data row7 col4\" >123</td>\n",
       "      <td id=\"T_6d54b_row7_col5\" class=\"data row7 col5\" >1,470</td>\n",
       "      <td id=\"T_6d54b_row7_col6\" class=\"data row7 col6\" >5.295 s</td>\n",
       "      <td id=\"T_6d54b_row7_col7\" class=\"data row7 col7\" >15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row8_col0\" class=\"data row8 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row8_col1\" class=\"data row8 col1\" >draw</td>\n",
       "      <td id=\"T_6d54b_row8_col2\" class=\"data row8 col2\" >14.46ms</td>\n",
       "      <td id=\"T_6d54b_row8_col3\" class=\"data row8 col3\" >60.89ms</td>\n",
       "      <td id=\"T_6d54b_row8_col4\" class=\"data row8 col4\" >123</td>\n",
       "      <td id=\"T_6d54b_row8_col5\" class=\"data row8 col5\" >-744</td>\n",
       "      <td id=\"T_6d54b_row8_col6\" class=\"data row8 col6\" >1.779 s</td>\n",
       "      <td id=\"T_6d54b_row8_col7\" class=\"data row8 col7\" >5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6d54b_row9_col0\" class=\"data row9 col0\" ></td>\n",
       "      <td id=\"T_6d54b_row9_col1\" class=\"data row9 col1\" >batch</td>\n",
       "      <td id=\"T_6d54b_row9_col2\" class=\"data row9 col2\" >28.59ms</td>\n",
       "      <td id=\"T_6d54b_row9_col3\" class=\"data row9 col3\" >11.42ms</td>\n",
       "      <td id=\"T_6d54b_row9_col4\" class=\"data row9 col4\" >123</td>\n",
       "      <td id=\"T_6d54b_row9_col5\" class=\"data row9 col5\" >2,214</td>\n",
       "      <td id=\"T_6d54b_row9_col6\" class=\"data row9 col6\" >3.516 s</td>\n",
       "      <td id=\"T_6d54b_row9_col7\" class=\"data row9 col7\" >10%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5df581de40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch dropped. train and valid phases show 1 less batch than fit.\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "learn = Learner(dls, xresnext50(n_out=dls.c), opt_func=adam(foreach=True),\n",
    "                metrics=Accuracy()).to_channelslast().profile()\n",
    "learn.fit_one_cycle(2, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.497550</td>\n",
       "      <td>2.453694</td>\n",
       "      <td>0.428535</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.997146</td>\n",
       "      <td>0.888791</td>\n",
       "      <td>0.723057</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_dc0b2\">\n",
       "  <caption>Profiling Results</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_dc0b2_level0_col0\" class=\"col_heading level0 col0\" >Phase</th>\n",
       "      <th id=\"T_dc0b2_level0_col1\" class=\"col_heading level0 col1\" >Action</th>\n",
       "      <th id=\"T_dc0b2_level0_col2\" class=\"col_heading level0 col2\" >Mean Duration</th>\n",
       "      <th id=\"T_dc0b2_level0_col3\" class=\"col_heading level0 col3\" >Duration Std Dev</th>\n",
       "      <th id=\"T_dc0b2_level0_col4\" class=\"col_heading level0 col4\" >Number of Calls</th>\n",
       "      <th id=\"T_dc0b2_level0_col5\" class=\"col_heading level0 col5\" >Samples/Second</th>\n",
       "      <th id=\"T_dc0b2_level0_col6\" class=\"col_heading level0 col6\" >Total Time</th>\n",
       "      <th id=\"T_dc0b2_level0_col7\" class=\"col_heading level0 col7\" >Percent of Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row0_col0\" class=\"data row0 col0\" >fit</td>\n",
       "      <td id=\"T_dc0b2_row0_col1\" class=\"data row0 col1\" ></td>\n",
       "      <td id=\"T_dc0b2_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_dc0b2_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_dc0b2_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "      <td id=\"T_dc0b2_row0_col5\" class=\"data row0 col5\" >-</td>\n",
       "      <td id=\"T_dc0b2_row0_col6\" class=\"data row0 col6\" >34.55 s</td>\n",
       "      <td id=\"T_dc0b2_row0_col7\" class=\"data row0 col7\" >100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row1_col0\" class=\"data row1 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row1_col1\" class=\"data row1 col1\" >epoch</td>\n",
       "      <td id=\"T_dc0b2_row1_col2\" class=\"data row1 col2\" >17.27 s</td>\n",
       "      <td id=\"T_dc0b2_row1_col3\" class=\"data row1 col3\" >44.73ms</td>\n",
       "      <td id=\"T_dc0b2_row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "      <td id=\"T_dc0b2_row1_col5\" class=\"data row1 col5\" >-</td>\n",
       "      <td id=\"T_dc0b2_row1_col6\" class=\"data row1 col6\" >34.54 s</td>\n",
       "      <td id=\"T_dc0b2_row1_col7\" class=\"data row1 col7\" >100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row2_col1\" class=\"data row2 col1\" >train</td>\n",
       "      <td id=\"T_dc0b2_row2_col2\" class=\"data row2 col2\" >13.64 s</td>\n",
       "      <td id=\"T_dc0b2_row2_col3\" class=\"data row2 col3\" >4.756ms</td>\n",
       "      <td id=\"T_dc0b2_row2_col4\" class=\"data row2 col4\" >2</td>\n",
       "      <td id=\"T_dc0b2_row2_col5\" class=\"data row2 col5\" >709</td>\n",
       "      <td id=\"T_dc0b2_row2_col6\" class=\"data row2 col6\" >27.28 s</td>\n",
       "      <td id=\"T_dc0b2_row2_col7\" class=\"data row2 col7\" >79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row3_col0\" class=\"data row3 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row3_col1\" class=\"data row3 col1\" >valid</td>\n",
       "      <td id=\"T_dc0b2_row3_col2\" class=\"data row3 col2\" >3.629 s</td>\n",
       "      <td id=\"T_dc0b2_row3_col3\" class=\"data row3 col3\" >48.68ms</td>\n",
       "      <td id=\"T_dc0b2_row3_col4\" class=\"data row3 col4\" >2</td>\n",
       "      <td id=\"T_dc0b2_row3_col5\" class=\"data row3 col5\" >1,291</td>\n",
       "      <td id=\"T_dc0b2_row3_col6\" class=\"data row3 col6\" >7.259 s</td>\n",
       "      <td id=\"T_dc0b2_row3_col7\" class=\"data row3 col7\" >21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row4_col0\" class=\"data row4 col0\" >train</td>\n",
       "      <td id=\"T_dc0b2_row4_col1\" class=\"data row4 col1\" >step</td>\n",
       "      <td id=\"T_dc0b2_row4_col2\" class=\"data row4 col2\" >87.64ms</td>\n",
       "      <td id=\"T_dc0b2_row4_col3\" class=\"data row4 col3\" >44.58ms</td>\n",
       "      <td id=\"T_dc0b2_row4_col4\" class=\"data row4 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row4_col5\" class=\"data row4 col5\" >730</td>\n",
       "      <td id=\"T_dc0b2_row4_col6\" class=\"data row4 col6\" >25.68 s</td>\n",
       "      <td id=\"T_dc0b2_row4_col7\" class=\"data row4 col7\" >74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row5_col0\" class=\"data row5 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row5_col1\" class=\"data row5 col1\" >draw</td>\n",
       "      <td id=\"T_dc0b2_row5_col2\" class=\"data row5 col2\" >4.428ms</td>\n",
       "      <td id=\"T_dc0b2_row5_col3\" class=\"data row5 col3\" >39.70ms</td>\n",
       "      <td id=\"T_dc0b2_row5_col4\" class=\"data row5 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row5_col5\" class=\"data row5 col5\" >-39</td>\n",
       "      <td id=\"T_dc0b2_row5_col6\" class=\"data row5 col6\" >1.297 s</td>\n",
       "      <td id=\"T_dc0b2_row5_col7\" class=\"data row5 col7\" >4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row6_col0\" class=\"data row6 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row6_col1\" class=\"data row6 col1\" >batch</td>\n",
       "      <td id=\"T_dc0b2_row6_col2\" class=\"data row6 col2\" >83.22ms</td>\n",
       "      <td id=\"T_dc0b2_row6_col3\" class=\"data row6 col3\" >6.353ms</td>\n",
       "      <td id=\"T_dc0b2_row6_col4\" class=\"data row6 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row6_col5\" class=\"data row6 col5\" >769</td>\n",
       "      <td id=\"T_dc0b2_row6_col6\" class=\"data row6 col6\" >24.38 s</td>\n",
       "      <td id=\"T_dc0b2_row6_col7\" class=\"data row6 col7\" >71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row7_col0\" class=\"data row7 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row7_col1\" class=\"data row7 col1\" >forward</td>\n",
       "      <td id=\"T_dc0b2_row7_col2\" class=\"data row7 col2\" >16.65ms</td>\n",
       "      <td id=\"T_dc0b2_row7_col3\" class=\"data row7 col3\" >5.732ms</td>\n",
       "      <td id=\"T_dc0b2_row7_col4\" class=\"data row7 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row7_col5\" class=\"data row7 col5\" >3,843</td>\n",
       "      <td id=\"T_dc0b2_row7_col6\" class=\"data row7 col6\" >4.880 s</td>\n",
       "      <td id=\"T_dc0b2_row7_col7\" class=\"data row7 col7\" >14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row8_col0\" class=\"data row8 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row8_col1\" class=\"data row8 col1\" >loss</td>\n",
       "      <td id=\"T_dc0b2_row8_col2\" class=\"data row8 col2\" >771.3µs</td>\n",
       "      <td id=\"T_dc0b2_row8_col3\" class=\"data row8 col3\" >196.1µs</td>\n",
       "      <td id=\"T_dc0b2_row8_col4\" class=\"data row8 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row8_col5\" class=\"data row8 col5\" >82,977</td>\n",
       "      <td id=\"T_dc0b2_row8_col6\" class=\"data row8 col6\" >226.0ms</td>\n",
       "      <td id=\"T_dc0b2_row8_col7\" class=\"data row8 col7\" >1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row9_col0\" class=\"data row9 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row9_col1\" class=\"data row9 col1\" >backward</td>\n",
       "      <td id=\"T_dc0b2_row9_col2\" class=\"data row9 col2\" >19.10ms</td>\n",
       "      <td id=\"T_dc0b2_row9_col3\" class=\"data row9 col3\" >5.501ms</td>\n",
       "      <td id=\"T_dc0b2_row9_col4\" class=\"data row9 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row9_col5\" class=\"data row9 col5\" >3,351</td>\n",
       "      <td id=\"T_dc0b2_row9_col6\" class=\"data row9 col6\" >5.597 s</td>\n",
       "      <td id=\"T_dc0b2_row9_col7\" class=\"data row9 col7\" >16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row10_col0\" class=\"data row10 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row10_col1\" class=\"data row10 col1\" >opt_step</td>\n",
       "      <td id=\"T_dc0b2_row10_col2\" class=\"data row10 col2\" >45.46ms</td>\n",
       "      <td id=\"T_dc0b2_row10_col3\" class=\"data row10 col3\" >5.934ms</td>\n",
       "      <td id=\"T_dc0b2_row10_col4\" class=\"data row10 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row10_col5\" class=\"data row10 col5\" >1,408</td>\n",
       "      <td id=\"T_dc0b2_row10_col6\" class=\"data row10 col6\" >13.32 s</td>\n",
       "      <td id=\"T_dc0b2_row10_col7\" class=\"data row10 col7\" >39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row11_col0\" class=\"data row11 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row11_col1\" class=\"data row11 col1\" >zero_grad</td>\n",
       "      <td id=\"T_dc0b2_row11_col2\" class=\"data row11 col2\" >1.106ms</td>\n",
       "      <td id=\"T_dc0b2_row11_col3\" class=\"data row11 col3\" >298.9µs</td>\n",
       "      <td id=\"T_dc0b2_row11_col4\" class=\"data row11 col4\" >293</td>\n",
       "      <td id=\"T_dc0b2_row11_col5\" class=\"data row11 col5\" >-</td>\n",
       "      <td id=\"T_dc0b2_row11_col6\" class=\"data row11 col6\" >324.1ms</td>\n",
       "      <td id=\"T_dc0b2_row11_col7\" class=\"data row11 col7\" >1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row12_col0\" class=\"data row12 col0\" >valid</td>\n",
       "      <td id=\"T_dc0b2_row12_col1\" class=\"data row12 col1\" >step</td>\n",
       "      <td id=\"T_dc0b2_row12_col2\" class=\"data row12 col2\" >43.94ms</td>\n",
       "      <td id=\"T_dc0b2_row12_col3\" class=\"data row12 col3\" >67.12ms</td>\n",
       "      <td id=\"T_dc0b2_row12_col4\" class=\"data row12 col4\" >123</td>\n",
       "      <td id=\"T_dc0b2_row12_col5\" class=\"data row12 col5\" >1,441</td>\n",
       "      <td id=\"T_dc0b2_row12_col6\" class=\"data row12 col6\" >5.404 s</td>\n",
       "      <td id=\"T_dc0b2_row12_col7\" class=\"data row12 col7\" >16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row13_col0\" class=\"data row13 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row13_col1\" class=\"data row13 col1\" >draw</td>\n",
       "      <td id=\"T_dc0b2_row13_col2\" class=\"data row13 col2\" >15.77ms</td>\n",
       "      <td id=\"T_dc0b2_row13_col3\" class=\"data row13 col3\" >63.35ms</td>\n",
       "      <td id=\"T_dc0b2_row13_col4\" class=\"data row13 col4\" >123</td>\n",
       "      <td id=\"T_dc0b2_row13_col5\" class=\"data row13 col5\" >-807</td>\n",
       "      <td id=\"T_dc0b2_row13_col6\" class=\"data row13 col6\" >1.940 s</td>\n",
       "      <td id=\"T_dc0b2_row13_col7\" class=\"data row13 col7\" >6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row14_col0\" class=\"data row14 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row14_col1\" class=\"data row14 col1\" >batch</td>\n",
       "      <td id=\"T_dc0b2_row14_col2\" class=\"data row14 col2\" >28.16ms</td>\n",
       "      <td id=\"T_dc0b2_row14_col3\" class=\"data row14 col3\" >11.90ms</td>\n",
       "      <td id=\"T_dc0b2_row14_col4\" class=\"data row14 col4\" >123</td>\n",
       "      <td id=\"T_dc0b2_row14_col5\" class=\"data row14 col5\" >2,248</td>\n",
       "      <td id=\"T_dc0b2_row14_col6\" class=\"data row14 col6\" >3.464 s</td>\n",
       "      <td id=\"T_dc0b2_row14_col7\" class=\"data row14 col7\" >10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row15_col0\" class=\"data row15 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row15_col1\" class=\"data row15 col1\" >predict</td>\n",
       "      <td id=\"T_dc0b2_row15_col2\" class=\"data row15 col2\" >26.60ms</td>\n",
       "      <td id=\"T_dc0b2_row15_col3\" class=\"data row15 col3\" >11.17ms</td>\n",
       "      <td id=\"T_dc0b2_row15_col4\" class=\"data row15 col4\" >123</td>\n",
       "      <td id=\"T_dc0b2_row15_col5\" class=\"data row15 col5\" >2,379</td>\n",
       "      <td id=\"T_dc0b2_row15_col6\" class=\"data row15 col6\" >3.272 s</td>\n",
       "      <td id=\"T_dc0b2_row15_col7\" class=\"data row15 col7\" >9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_dc0b2_row16_col0\" class=\"data row16 col0\" ></td>\n",
       "      <td id=\"T_dc0b2_row16_col1\" class=\"data row16 col1\" >loss</td>\n",
       "      <td id=\"T_dc0b2_row16_col2\" class=\"data row16 col2\" >1.353ms</td>\n",
       "      <td id=\"T_dc0b2_row16_col3\" class=\"data row16 col3\" >1.795ms</td>\n",
       "      <td id=\"T_dc0b2_row16_col4\" class=\"data row16 col4\" >123</td>\n",
       "      <td id=\"T_dc0b2_row16_col5\" class=\"data row16 col5\" >46,800</td>\n",
       "      <td id=\"T_dc0b2_row16_col6\" class=\"data row16 col6\" >166.4ms</td>\n",
       "      <td id=\"T_dc0b2_row16_col7\" class=\"data row16 col7\" >0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5df5894e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch dropped. train and valid phases show 1 less batch than fit.\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "learn = Learner(dls, xresnext50(n_out=dls.c), opt_func=adam(foreach=True),\n",
    "                metrics=Accuracy()).to_channelslast().profile(ProfileMode.Simple)\n",
    "learn.fit_one_cycle(2, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Training Loop\n",
    "The `show_training_loop` output below shows where the new `before_draw` event fits into the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [Recorder, ProgressCallback]\n",
      "    Start Train\n",
      "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - before_draw    : []\n",
      "         - before_batch   : [CastToTensor]\n",
      "         - after_pred     : []\n",
      "         - after_loss     : []\n",
      "         - before_backward: []\n",
      "         - before_step    : []\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder, ProgressCallback]\n",
      "    Start Valid\n",
      "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder, ProgressCallback]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : [ProgressCallback]\n"
     ]
    }
   ],
   "source": [
    "learn = synth_learner()\n",
    "learn.show_training_loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases Logging\n",
    "\n",
    "If Weights & Biases is installed and the [`WandbCallback`](https://docs.fast.ai/callback.wandb.html) is added to `Learner`, the Simple Profiler callback will automatically logs samples/second for draw, batch, forward, loss, backward, and opt_step steps as wandb charts.\n",
    "\n",
    "Also logs two tables to active wandb run:\n",
    "\n",
    "* `profile_report`: formatted report from Simple Profiler\n",
    "* `profile_results`: raw results from Simple Profiler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to other Loggers\n",
    "\n",
    "To extend to new loggers, follow the Weights & Biases code below and create patches for `ThroughputCallback` to add a `_{Callback.name}_log_after_batch` and `_{Callback.name}_log_after_fit`, where `Callback.name` is the [name of the logger callback](https://docs.fast.ai/callback.core.html#Callback.name).\n",
    "\n",
    "`SimpleProfilerCallback` inherits from `ThroughputCallback` so only one patch is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def convert_to_int(s):\n",
    "    try:\n",
    "        return int(s.replace(\",\", \"\"))\n",
    "    except ValueError:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_after_batch(self:ThroughputCallback, actions:list[str]):\n",
    "        bs = np.mean(self._raw_values[f'train_bs'][-self._rolling_average:])\n",
    "        logs = {f'throughput/{action}': self._samples_per_second(bs, action) for action in actions}\n",
    "        wandb.log(logs, self.learn.wandb._wandb_step+1)\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_after_fit(self:ThroughputCallback):\n",
    "        for t in self.learn.profile_results.itertuples():\n",
    "            if isinstance(convert_to_int(t._6), int):\n",
    "                wandb.summary[f'{t.Phase}/{t.Action}_throughput'] = self._processed_samples[f'{t.Phase}_{t.Action}']\n",
    "\n",
    "            values = self._raw_values[f'{t.Phase}_{t.Action}']\n",
    "            if t.Phase in ['train', 'valid']:\n",
    "                # Optionaly drop first batch if train/valid phase\n",
    "                values = values[self._drop:]\n",
    "            wandb.summary[f'{t.Phase}/{t.Action}_duration'] = values\n",
    "\n",
    "        report = wandb.Table(dataframe=self.learn.profile_report)\n",
    "        results = wandb.Table(dataframe=self.learn.profile_results)\n",
    "\n",
    "        wandb.log({\"profile_report\": report})\n",
    "        wandb.log({\"profile_results\": results})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to use, pass `logger_callback='{Callback.name}'` to `Learner.profile()`.\n",
    "\n",
    "`ThroughputCallback` sets its `_log_after_batch` method to `f'_{self.logger_callback}_log_after_batch'`, which should match the patched method.\n",
    "\n",
    "```python\n",
    "self._log_after_batch = getattr(self, f'_{self.logger_callback}_log_after_batch', noop)\n",
    "```\n",
    "\n",
    "`ThroughputCallback.log_after_fit` behaves the same way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
