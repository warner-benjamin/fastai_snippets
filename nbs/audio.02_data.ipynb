{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp audio.data\n",
    "#|default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Contains code from:\n",
    "# fastai - Apache License 2.0 - Copyright (c) 2023 fast.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Data\n",
    "> Audio DataBlocks and show_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "\n",
    "from torch.nn.functional import interpolate\n",
    "import torchaudio.transforms as tatfms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastcore.dispatch import typedispatch, explode_types\n",
    "from fastcore.transform import DisplayedTransform\n",
    "\n",
    "from fastai.basics import defaults\n",
    "from fastai.torch_core import default_device\n",
    "from fastai.vision.data import get_grid\n",
    "from fastai.data.block import TransformBlock\n",
    "\n",
    "from fastxtend.audio.core import TensorAudio, TensorSpec, TensorMelSpec\n",
    "from fastxtend.imports import *\n",
    "from fastxtend.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show methods -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@typedispatch\n",
    "def show_batch(x:TensorAudio, y, samples, ctxs=None, max_n=9, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, hear=False, **kwargs)\n",
    "    plt.tight_layout()\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@typedispatch\n",
    "def show_batch(x:TensorSpec|TensorMelSpec, y, samples, ctxs=None, max_n=9, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    plt.tight_layout()\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Spectrogram(DisplayedTransform):\n",
    "    \"Convert a `TensorAudio` into one or more `TensorSpec`\"\n",
    "    order = 75\n",
    "    def __init__(self,\n",
    "        n_fft:Listified[int]=1024,\n",
    "        win_length:Listified[int]|None=None,\n",
    "        hop_length:Listified[int]|None=None,\n",
    "        pad:Listified[int]=0,\n",
    "        window_fn:Listified[Callable[..., Tensor]]=torch.hann_window,\n",
    "        power:Listified[float]=2.,\n",
    "        normalized:Listified[bool]=False,\n",
    "        wkwargs:Listified[dict]|None=None,\n",
    "        center:Listified[bool]=True,\n",
    "        pad_mode:Listified[str]=\"reflect\",\n",
    "        onesided:Listified[bool]=True,\n",
    "        norm:Listified[str]|None=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        listify_store_attr()\n",
    "        attrs = {k:v for k,v in getattr(self,'__stored_args__',{}).items() if k not in ['size', 'mode']}\n",
    "        # self.resize = size is not None\n",
    "        if is_listy(self.n_fft):\n",
    "            self.specs, self._attrs = nn.ModuleList(), []\n",
    "            self.len, self.multiple = len(self.n_fft), True\n",
    "            for i in range(self.len):\n",
    "                self.specs.append(tatfms.Spectrogram(n_fft=self.n_fft[i], win_length=self.win_length[i],\n",
    "                                                     hop_length=self.hop_length[i], pad=self.pad[i],\n",
    "                                                     window_fn=self.window_fn[i], power=self.power[i],\n",
    "                                                     normalized=self.normalized[i], wkwargs=self.wkwargs[i],\n",
    "                                                     center=self.center[i], pad_mode=self.pad_mode[i],\n",
    "                                                     onesided=self.onesided[i], norm=self.norm[i]))\n",
    "\n",
    "                self._attrs.append({k:v[i] for k,v in self._get_attrs().items()})\n",
    "        else:\n",
    "            self.multiple = False\n",
    "            self.spec = tatfms.Spectrogram(n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length,\n",
    "                                           pad=self.pad, window_fn=self.window_fn, power=self.power,\n",
    "                                           normalized=self.normalized, wkwargs=self.wkwargs, center=self.center,\n",
    "                                           pad_mode=self.pad_mode, onesided=self.onesided, norm=self.norm)\n",
    "\n",
    "            self._attrs = {k:v for k,v in self._get_attrs().items()}\n",
    "\n",
    "    def encodes(self, x:TensorAudio):\n",
    "        if self.multiple:\n",
    "            specs = []\n",
    "            for i in range(self.len):\n",
    "                specs.append(TensorSpec.create(self.specs[i](x), settings=self._attrs[i]))\n",
    "            return tuple(specs)\n",
    "        else:\n",
    "            return TensorSpec.create(self.spec(x), settings=self._attrs)\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        device, *_ = torch._C._nn._parse_to(*args, **kwargs)\n",
    "        if self.multiple:\n",
    "            self.specs.to(device)\n",
    "        else:\n",
    "            self.spec.to(device)\n",
    "\n",
    "    def _get_attrs(self):\n",
    "        return {k:v for k,v in getattr(self,'__dict__',{}).items() if k in getattr(self,'__stored_args__',{}).keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MelSpectrogram(DisplayedTransform):\n",
    "    \"Convert a `TensorAudio` into one or more `TensorMelSpec`\"\n",
    "    order = 75\n",
    "    def __init__(self,\n",
    "        sample_rate:Listified[int]=16000,\n",
    "        n_fft:Listified[int]=1024,\n",
    "        win_length:Listified[int]|None=None,\n",
    "        hop_length:Listified[int]|None=None,\n",
    "        f_min:Listified[float]=0.,\n",
    "        f_max:Listified[float]|None=None,\n",
    "        pad:Listified[int]=0,\n",
    "        n_mels:Listified[int]=128,\n",
    "        window_fn:Listified[Callable[..., Tensor]]=torch.hann_window,\n",
    "        power:Listified[float]=2.,\n",
    "        normalized:Listified[bool]=False,\n",
    "        wkwargs:Listified[dict]|None=None,\n",
    "        center:Listified[bool]=True,\n",
    "        pad_mode:Listified[str]=\"reflect\",\n",
    "        norm:Listified[str]|None=None,\n",
    "        mel_scale:Listified[str]=\"htk\",\n",
    "        # size:tuple[int,int]|None=None, # If set, resize MelSpectrogram to `size`\n",
    "        # mode='bilinear'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        listify_store_attr()\n",
    "        # self.resize = size is not None\n",
    "        if is_listy(self.n_fft):\n",
    "            self.mels, self._attrs = nn.ModuleList(), []\n",
    "            self.len, self.multiple = len(self.n_fft), True\n",
    "            for i in range(self.len):\n",
    "                self.win_length[i] = self.win_length[i] if self.win_length[i] is not None else self.n_fft[i]\n",
    "                self.hop_length[i] = self.hop_length[i] if self.hop_length[i] is not None else self.win_length[i] // 2\n",
    "                self.mels.append(tatfms.MelSpectrogram(sample_rate=self.sample_rate[i], n_fft=self.n_fft[i],\n",
    "                                                       win_length=self.win_length[i], hop_length=self.hop_length[i],\n",
    "                                                       f_min=self.f_min[i], f_max=self.f_max[i], pad=self.pad[i],\n",
    "                                                       n_mels=self.n_mels[i], window_fn=self.window_fn[i], power=self.power[i],\n",
    "                                                       normalized=self.normalized[i], wkwargs=self.wkwargs[i],\n",
    "                                                       center=self.center[i], pad_mode=self.pad_mode[i],\n",
    "                                                       norm=self.norm[i], mel_scale=self.mel_scale[i]))\n",
    "\n",
    "                self._attrs.append({**{k:v[i] for k,v in self._get_attrs().items()},**{'sr':self.sample_rate[i]}})\n",
    "        else:\n",
    "            self.multiple = False\n",
    "            self.win_length = self.win_length if self.win_length is not None else self.n_fft\n",
    "            self.hop_length = self.hop_length if self.hop_length is not None else self.win_length // 2\n",
    "            self.mel = tatfms.MelSpectrogram(sample_rate=self.sample_rate, n_fft=self.n_fft, win_length=self.win_length,\n",
    "                                             hop_length=self.hop_length, f_min=self.f_min, f_max=self.f_max, pad=self.pad,\n",
    "                                             n_mels=self.n_mels, window_fn=self.window_fn, power=self.power,\n",
    "                                             normalized=self.normalized, wkwargs=self.wkwargs, center=self.center,\n",
    "                                             pad_mode=self.pad_mode, norm=self.norm, mel_scale=self.mel_scale)\n",
    "\n",
    "            self._attrs = {**{k:v for k,v in self._get_attrs().items()},**{'sr':self.sample_rate}}\n",
    "\n",
    "    def encodes(self, x:TensorAudio):\n",
    "        if self.multiple:\n",
    "            mels = []\n",
    "            for i in range(self.len):\n",
    "                mels.append(TensorMelSpec.create(self.mels[i](x), settings=self._attrs[i]))\n",
    "            return tuple(mels)\n",
    "        else:\n",
    "            return TensorMelSpec.create(self.mel(x), settings=self._attrs)\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        device, *_ = torch._C._nn._parse_to(*args, **kwargs)\n",
    "        if self.multiple:\n",
    "            self.mels.to(device)\n",
    "        else:\n",
    "            self.mel.to(device)\n",
    "\n",
    "    def _get_attrs(self):\n",
    "        return {k:v for k,v in getattr(self,'__dict__',{}).items() if k in getattr(self,'__stored_args__',{}).keys() and k not in ['size', 'mode']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformBlocks for audio\n",
    "Audio data blocks for using with the fastai [data block API](https://docs.fast.ai/data.block.html#general-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def AudioBlock(cls=TensorAudio):\n",
    "    \"A `TransformBlock` for audio of `cls`\"\n",
    "    return TransformBlock(type_tfms=cls.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def SpecBlock(cls=TensorAudio,\n",
    "    # Spectrogram args\n",
    "    n_fft:Listified[int]=1024,\n",
    "    win_length:Listified[int]|None=None,\n",
    "    hop_length:Listified[int]|None=None,\n",
    "    pad:Listified[int]=0,\n",
    "    window_fn:Listified[Callable[..., Tensor]]=torch.hann_window,\n",
    "    power:Listified[float]=2.,\n",
    "    normalized:Listified[bool]=False,\n",
    "    wkwargs:Listified[dict]|None=None,\n",
    "    center:Listified[bool]=True,\n",
    "    pad_mode:Listified[str]=\"reflect\",\n",
    "    norm:Listified[str]|None=None\n",
    "):\n",
    "    \"A `TransformBlock` to read `TensorAudio` and then use the GPU to turn audio into one or more `Spectrogram`s\"\n",
    "    return TransformBlock(type_tfms=cls.create,\n",
    "                          batch_tfms=[Spectrogram(n_fft=n_fft, win_length=win_length, hop_length=hop_length,\n",
    "                                                  pad=pad, window_fn=window_fn, power=power, normalized=normalized,\n",
    "                                                  wkwargs=wkwargs, center=center, pad_mode=pad_mode, norm=norm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def MelSpecBlock(cls=TensorAudio,\n",
    "    # MelSpectrogram args\n",
    "    sr:Listified[int]=16000,\n",
    "    n_fft:Listified[int]=1024,\n",
    "    win_length:Listified[int]|None=None,\n",
    "    hop_length:Listified[int]|None=None,\n",
    "    f_min:Listified[float]=0.,\n",
    "    f_max:Listified[float]|None=None,\n",
    "    pad:Listified[int]=0,\n",
    "    n_mels:Listified[int]=128,\n",
    "    window_fn:Listified[Callable[..., Tensor]]=torch.hann_window,\n",
    "    power:Listified[float]=2.,\n",
    "    normalized:Listified[bool]=False,\n",
    "    wkwargs:Listified[dict]|None=None,\n",
    "    center:Listified[bool]=True,\n",
    "    pad_mode:Listified[str]=\"reflect\",\n",
    "    norm:Listified[str]|None=None,\n",
    "    mel_scale:Listified[str]=\"htk\"\n",
    "):\n",
    "    \"A `TransformBlock` to read `TensorAudio` and then use the GPU to turn audio into one or more `MelSpectrogram`s\"\n",
    "    return TransformBlock(type_tfms=cls.create,\n",
    "                          batch_tfms=[MelSpectrogram(sample_rate=sr, n_fft=n_fft, win_length=win_length,\n",
    "                                                     hop_length=hop_length, f_min=f_min, f_max=f_max, pad=pad,\n",
    "                                                     n_mels=n_mels, window_fn=window_fn, power=power,\n",
    "                                                     normalized=normalized, wkwargs=wkwargs, center=center,\n",
    "                                                     pad_mode=pad_mode, norm=norm, mel_scale=mel_scale)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
