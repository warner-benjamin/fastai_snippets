{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.simpleprofiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from fastcore.foundation import L, patch, docs\n",
    "from fastcore.basics import mk_class, noop, store_attr, in_notebook\n",
    "from fastai.learner import Learner, Recorder\n",
    "from fastai.test_utils import synth_learner\n",
    "from fastai.callback.core import *\n",
    "\n",
    "\n",
    "if in_notebook():\n",
    "    from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Profiler\n",
    "> Callbacks which add a simple profiler to fastai. Inspired by PyTorch Lightning's SimpleProfiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since simple profiler changes the fastai data loading loop, it is not imported by any of the fastxtend all imports. It needs to be imported seperately:\n",
    "\n",
    "```python\n",
    "from fastxtend.callback import simpleprofiler\n",
    "```\n",
    "\n",
    "> Note: Simple Profiler is currently untested on distributed training.\n",
    "\n",
    "Jump [here](#Examples) for usage examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "Fastai callbacks do not have an event which is called directly before drawing a batch. Simple Profiler adds a new callback event called `before_draw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Simple Profiler imported, a callback can implement actions on the following events:\n",
    "\n",
    "- `after_create`: called after the `Learner` is created\n",
    "- `before_fit`: called before starting training or inference, ideal for initial setup.\n",
    "- `before_epoch`: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch.\n",
    "- `before_train`: called at the beginning of the training part of an epoch.\n",
    "- `before_draw`: called at the beginning of each batch, just before drawing said batch. \n",
    "- `before_batch`: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).\n",
    "- `after_pred`: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.\n",
    "- `after_loss`: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).\n",
    "- `before_backward`: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)\n",
    "- `before_step`: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).\n",
    "- `after_step`: called after the step and before the gradients are zeroed.\n",
    "- `after_batch`: called at the end of a batch, for any clean-up before the next one.\n",
    "- `after_train`: called at the end of the training phase of an epoch.\n",
    "- `before_validate`: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.\n",
    "- `after_validate`: called at the end of the validation part of an epoch.\n",
    "- `after_epoch`: called at the end of an epoch, for any clean-up before the next one.\n",
    "- `after_fit`: called at the end of training, for final clean-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement before_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add `before_draw` as a callable event, first it needs to be added to both lists of fastai events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "_inner_loop = \"before_draw before_batch after_pred after_loss before_backward before_step after_step after_cancel_batch after_batch\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "_events = L.split('after_create before_fit before_epoch before_train before_draw before_batch after_pred after_loss \\\n",
    "    before_backward before_step after_cancel_step after_step after_cancel_batch after_batch after_cancel_train \\\n",
    "    after_train before_validate after_cancel_validate after_validate after_cancel_epoch \\\n",
    "    after_epoch after_cancel_fit after_fit')\n",
    "\n",
    "mk_class('event', **_events.map_dict(),\n",
    "         doc=\"All possible events as attributes to get tab-completion and typo-proofing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, `Callback` needs to be modified to be aware of the new event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "@patch\n",
    "def __call__(self:Callback, event_name):\n",
    "    \"Call `self.{event_name}` if it's defined\"\n",
    "    _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n",
    "            (self.run_valid and not getattr(self, 'training', False)))\n",
    "    res = None\n",
    "    if self.run and _run: res = getattr(self, event_name, noop)()\n",
    "    if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then `Learner._call_one` needs to patch to be aware of the `before_draw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "@patch\n",
    "def _call_one(self:Learner, event_name):\n",
    "    if not hasattr(event, event_name): raise Exception(f'missing {event_name}')\n",
    "    for cb in self.cbs.sorted('order'): cb(event_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `Learner.all_batches` can be modified to call `before_draw` when iterating through a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "@patch\n",
    "def all_batches(self:Learner):\n",
    "    self.n_iter = len(self.dl)\n",
    "    if hasattr(self, 'simple_profiler'):\n",
    "        self.it = iter(self.dl)\n",
    "        for i in range(self.n_iter):\n",
    "            self(\"before_draw\")\n",
    "            self.one_batch(i, next(self.it))\n",
    "        del(self.it)\n",
    "    else:\n",
    "        for o in enumerate(self.dl): self.one_batch(*o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While testing hasn't shown any negative side effects of this approach, `all_batches` only uses the new batch drawing implementation if `SimpleProfilerCallback` is in the list of callbacks, and reverts back to the original method if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_loop = ['Start Fit', 'before_fit', 'Start Epoch Loop', 'before_epoch', 'Start Train', 'before_train',\n",
    "         'Start Batch Loop', 'before_draw', 'before_batch', 'after_pred', 'after_loss', 'before_backward', \n",
    "         'before_step', 'after_step', 'after_cancel_batch', 'after_batch','End Batch Loop', 'End Train',\n",
    "         'after_cancel_train', 'after_train', 'Start Valid', 'before_validate', 'Start Batch Loop',\n",
    "         '**CBs same as train batch**', 'End Batch Loop', 'End Valid', 'after_cancel_validate',\n",
    "         'after_validate', 'End Epoch Loop', 'after_cancel_epoch', 'after_epoch', 'End Fit',\n",
    "         'after_cancel_fit', 'after_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "@patch\n",
    "def show_training_loop(self:Learner):\n",
    "    indent = 0\n",
    "    for s in _loop:\n",
    "        if s.startswith('Start'): print(f'{\" \"*indent}{s}'); indent += 2\n",
    "        elif s.startswith('End'): indent -= 2; print(f'{\" \"*indent}{s}')\n",
    "        else: print(f'{\" \"*indent} - {s:15}:', self.ordered_cbs(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Profiler Callbacks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_all = ['fit', 'epoch', 'train', 'validate']\n",
    "_train = ['backward', 'step', 'zero_grad']\n",
    "_multiple = ['draw', 'batch', 'pred', 'loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleProfilerPostCallback(Callback):\n",
    "    \"Pair with `SimpleProfilerCallback` to profile training performance. Removes itself after training is over.\"\n",
    "    order,remove_on_fetch = Recorder.order-1,True\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.profiler = self.learn.simple_profiler\n",
    "\n",
    "    def after_train(self):\n",
    "        self.profiler._raw_time['train'].append(time.monotonic() - self.profiler._train_start)\n",
    "\n",
    "    def after_validate(self):\n",
    "        self.profiler._raw_time['validate'].append(time.monotonic() - self.profiler._validate_start)\n",
    "\n",
    "    def after_pred(self):\n",
    "        if self.training: self.profiler._raw_time['train_pred'].append(time.monotonic() - self.profiler._train_batch_start)\n",
    "        else: self.profiler._raw_time['valid_pred'].append(time.monotonic() - self.profiler._valid_batch_start)\n",
    "        \n",
    "        if self.training: self.profiler._train_loss_start = time.monotonic()\n",
    "        else: self.profiler._valid_loss_start = time.monotonic()\n",
    "\n",
    "    def after_loss(self):\n",
    "        if self.training: self.profiler._raw_time['train_loss'].append(time.monotonic() - self.profiler._train_loss_start)\n",
    "        else: self.profiler._raw_time['valid_loss'].append(time.monotonic() - self.profiler._valid_loss_start)\n",
    "\n",
    "    def after_step(self):\n",
    "        self.profiler._raw_time['step'].append(time.monotonic() - self.profiler._step_start)\n",
    "        self.profiler._zero_start = time.monotonic()\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training: self.profiler._raw_time['train_batch'].append(time.monotonic() - self.profiler._train_draw_start)\n",
    "        else: self.profiler._raw_time['valid_batch'].append(time.monotonic() - self.profiler._valid_draw_start)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        self.profiler._raw_time['epoch'].append(time.monotonic() - self.profiler._epoch_start)\n",
    "\n",
    "    def after_fit(self):\n",
    "        self.profiler._raw_time['fit'].append(time.monotonic() - self.profiler._fit_start)\n",
    "        self.profiler._generate_report()\n",
    "        if not hasattr(self.learn, 'lr_finder'):\n",
    "            self.profiler._display_report()\n",
    "            self.learn.remove_cbs([SimpleProfilerCallback, SimpleProfilerPostCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SimpleProfilerCallback(Callback):\n",
    "    \"\"\"\n",
    "    Adds a simple profiler to the fastai `Learner`. Optionally showing formatted report or saving unformatted results as csv.\n",
    "    \n",
    "    Pair with SimpleProfilerPostCallback to profile training performance.\n",
    "\n",
    "    Post fit, access report & results via `Learner.simple_profile_report` & `Learner.simple_profile_results`.\n",
    "    \"\"\"\n",
    "    order,remove_on_fetch = TrainEvalCallback.order+1,True\n",
    "    def __init__(self, show_report=True, plain=False, markdown=False, \n",
    "                 save_csv=False, csv_name='simple_profile.csv'): \n",
    "        store_attr()\n",
    "        self.csv_name = Path(csv_name)\n",
    "\n",
    "    def before_fit(self):\n",
    "        self._raw_time = dict()\n",
    "        for c in _all + _train:\n",
    "            self._raw_time[c] = []\n",
    "        for p in ['train', 'valid']:\n",
    "            for c in _multiple:\n",
    "                self._raw_time[f'{p}_{c}'] = []\n",
    "\n",
    "        self._fit_start = time.monotonic()\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self._epoch_start = time.monotonic()\n",
    "\n",
    "    def before_train(self):\n",
    "        self._train_start = time.monotonic()\n",
    "\n",
    "    def before_validate(self):\n",
    "        self._validate_start = time.monotonic()\n",
    "\n",
    "    def before_draw(self):\n",
    "        if self.training: self._train_draw_start = time.monotonic()\n",
    "        else: self._valid_draw_start = time.monotonic()\n",
    "\n",
    "    def before_batch(self):\n",
    "        if self.training: self._raw_time['train_draw'].append(time.monotonic() - self._train_draw_start)\n",
    "        else: self._raw_time['valid_draw'].append(time.monotonic() - self._valid_draw_start)\n",
    "\n",
    "        if self.training: self._train_batch_start = time.monotonic()\n",
    "        else: self._valid_batch_start = time.monotonic()\n",
    "\n",
    "    def before_backward(self):\n",
    "        self._backward_start = time.monotonic()\n",
    "\n",
    "    def before_step(self):\n",
    "        self._raw_time['backward'].append(time.monotonic() - self._backward_start)\n",
    "        self._step_start = time.monotonic()\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if self.training: self._raw_time['zero_grad'].append(time.monotonic() - self._zero_start)\n",
    "\n",
    "    def _generate_report(self):\n",
    "        total_time = self._raw_time['fit'][0]\n",
    "        self.report = pd.DataFrame(columns=['Phase', 'Action', 'Mean Duration', 'Duration Std Dev', \n",
    "                                               'Number of Calls', 'Total Time', 'Percent of Total'])\n",
    "\n",
    "        for c in _all:\n",
    "            if c == 'fit':\n",
    "                self._append_to_df(['fit', c, 0, 0, 1, total_time, f'{self._calc_percent(total_time):.0%}'])\n",
    "            else: self._append_to_df(self._create_row('fit', c, self._raw_time[c]))\n",
    "        \n",
    "        for c in _train: self._append_to_df(self._create_row('train', f'{c}', self._raw_time[c]))\n",
    "\n",
    "        for p in ['train', 'valid']:\n",
    "            for c in _multiple: self._append_to_df(self._create_row(p, f'{c}', self._raw_time[f'{p}_{c}']))\n",
    "\n",
    "        self.report = self.report.sort_values(['Phase','Total Time'], ascending=[True,False])\n",
    "        self.learn.simple_profile_results = self.report.copy()\n",
    "        for c in ['Mean Duration', 'Duration Std Dev', 'Total Time']:\n",
    "            self.report[c] = self.report[c].apply(self._scale)\n",
    "        self.report['Phase'] = self.report['Phase'].where(~self.report['Phase'].duplicated(), '')\n",
    "\n",
    "        self.learn.simple_profile_report = self.report\n",
    "\n",
    "    def _display_report(self):   \n",
    "        if self.show_report:\n",
    "            if self.markdown: print(self.report.to_markdown(index=False))\n",
    "            else:\n",
    "                if in_notebook() and not self.plain:\n",
    "                    with pd.option_context('display.max_rows', len(self.report.index)):\n",
    "                        s = self.report.style.set_caption(\"Simple Profiler Results\").hide_index()\n",
    "                        display(s)\n",
    "                else:\n",
    "                    print('Simple Profiler Results')\n",
    "                    print(self.report.to_string(index=False))\n",
    "\n",
    "        if self.save_csv:\n",
    "            self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            self.learn.simple_profile_results.to_csv(self.path/self.csv_name, index=False)\n",
    "\n",
    "    def _append_to_df(self, row):\n",
    "        self.report.loc[len(self.report.index)] = row\n",
    "\n",
    "    def _calc_percent(self, time):\n",
    "        return time / self._raw_time['fit'][0]\n",
    "\n",
    "    def _create_row(self, phase, name, input):\n",
    "        return [phase, name, np.mean(input), np.std(input), len(input), \n",
    "                np.sum(input), f'{self._calc_percent(np.sum(input)):.0%}']\n",
    "\n",
    "    # modified from https://github.com/thomasbrandon/mish-cuda/blob/master/test/perftest.py\n",
    "    def _scale(self, val, spec=\"#0.4G\"):\n",
    "        if val == 0: return '-'\n",
    "        PREFIXES = np.array([c for c in u\"yzafpnµm kMGTPEZY\"])\n",
    "        exp = np.int8(np.log10(np.abs(val)) // 3 * 3 * np.sign(val))\n",
    "        val /= 10.**exp\n",
    "        prefix = PREFIXES[exp//3 + len(PREFIXES)//2]\n",
    "        return f\"{val:{spec}}{prefix}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def profile(self:Learner, show_report=True, plain=False, markdown=False, \n",
    "            save_csv=False, csv_name='simple_profile.csv'):\n",
    "    \"Run Simple Profiler when training. Simple Profiler removes itself when finished.\"\n",
    "    self.add_cbs([SimpleProfilerCallback(show_report, plain, markdown, save_csv, csv_name),\n",
    "                  SimpleProfilerPostCallback()])\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Simple Profiler report contains the following items divided in three Phases (Fit, Train, & Valid)\n",
    "\n",
    "Fit:\n",
    "- `fit`:  total time fitting the model takes.\n",
    "- `epoch`: duration of both training and validation epochs. Often epoch total time is the same amount of elapsed time as fit.\n",
    "- `train`: duration of each training epoch.\n",
    "- `validate`: duration of each validation epoch.\n",
    "\n",
    "Train:\n",
    "- `draw`: time spent waiting for a batch to be drawn. Measured from `before_draw` to `before_batch`. With default prefetching settings, ideally this is as close to instantly as possible. \n",
    "- `batch`: total duration of all batch steps sans drawing the batch. Measured from `before_batch` to `after_batch`.\n",
    "- `pred`: duration of the forward pass and any additional batch modifications. Measured from `before_batch` to `after_pred`.\n",
    "- `loss`: duration of caculating loss. Measured from `after_pred` to `after_loss`.\n",
    "- `backward`: duration of the backward pass. Measured from `before_backward` to `before_step`.\n",
    "- `step`: duration of the optimizer step. Measured from `before_step` to `after_step`.\n",
    "- `zero_grad`: duration of the zero_grad step. Measured from `after_step` to `after_batch`.\n",
    "\n",
    "Valid:\n",
    "- `draw`: time spent waiting for a batch to be drawn. Measured from `before_draw` to `before_batch`. With default prefetching settings, ideally this is as close to instantly as possible. \n",
    "- `batch`: total duration of all batch steps sans drawing the batch. Measured from `before_batch` to `after_batch`.\n",
    "- `pred`: duration of the forward pass and any additional batch modifications. Measured from `before_batch` to `after_pred`.\n",
    "- `loss`: duration of caculating loss. Measured from `after_pred` to `after_loss`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "Both examples are trained on Imagenette with an image size of 256 and batch size of 64 on a Colab P100 4CPU instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.624050</td>\n",
       "      <td>2.352882</td>\n",
       "      <td>0.376051</td>\n",
       "      <td>03:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.184010</td>\n",
       "      <td>1.147916</td>\n",
       "      <td>0.643567</td>\n",
       "      <td>03:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002\" class=\"dataframe\"><caption>Simple Profiler Results</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Phase</th>        <th class=\"col_heading level0 col1\" >Action</th>        <th class=\"col_heading level0 col2\" >Mean Duration</th>        <th class=\"col_heading level0 col3\" >Duration Std Dev</th>        <th class=\"col_heading level0 col4\" >Number of Calls</th>        <th class=\"col_heading level0 col5\" >Total Time</th>        <th class=\"col_heading level0 col6\" >Percent of Total</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col0\" class=\"data row0 col0\" >fit</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col1\" class=\"data row0 col1\" >fit</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col5\" class=\"data row0 col5\" >404.7 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row0_col6\" class=\"data row0 col6\" >100%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col0\" class=\"data row1 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col1\" class=\"data row1 col1\" >epoch</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col2\" class=\"data row1 col2\" >202.4 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col3\" class=\"data row1 col3\" >2.721 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col5\" class=\"data row1 col5\" >404.7 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row1_col6\" class=\"data row1 col6\" >100%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col0\" class=\"data row2 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col1\" class=\"data row2 col1\" >train</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col2\" class=\"data row2 col2\" >178.4 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col3\" class=\"data row2 col3\" >2.020 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col4\" class=\"data row2 col4\" >2</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col5\" class=\"data row2 col5\" >356.7 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row2_col6\" class=\"data row2 col6\" >88%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col0\" class=\"data row3 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col1\" class=\"data row3 col1\" >validate</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col2\" class=\"data row3 col2\" >23.99 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col3\" class=\"data row3 col3\" >699.9ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col4\" class=\"data row3 col4\" >2</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col5\" class=\"data row3 col5\" >47.98 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row3_col6\" class=\"data row3 col6\" >12%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col0\" class=\"data row4 col0\" >train</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col1\" class=\"data row4 col1\" >batch</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col2\" class=\"data row4 col2\" >1.203 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col3\" class=\"data row4 col3\" >293.3ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col4\" class=\"data row4 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col5\" class=\"data row4 col5\" >353.7 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row4_col6\" class=\"data row4 col6\" >87%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col0\" class=\"data row5 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col1\" class=\"data row5 col1\" >step</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col2\" class=\"data row5 col2\" >726.8ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col3\" class=\"data row5 col3\" >35.05ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col4\" class=\"data row5 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col5\" class=\"data row5 col5\" >213.7 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row5_col6\" class=\"data row5 col6\" >53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col0\" class=\"data row6 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col1\" class=\"data row6 col1\" >backward</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col2\" class=\"data row6 col2\" >411.3ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col3\" class=\"data row6 col3\" >159.6ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col4\" class=\"data row6 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col5\" class=\"data row6 col5\" >120.9 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row6_col6\" class=\"data row6 col6\" >30%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col0\" class=\"data row7 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col1\" class=\"data row7 col1\" >pred</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col2\" class=\"data row7 col2\" >32.90ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col3\" class=\"data row7 col3\" >107.5ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col4\" class=\"data row7 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col5\" class=\"data row7 col5\" >9.673 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row7_col6\" class=\"data row7 col6\" >2%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col0\" class=\"data row8 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col1\" class=\"data row8 col1\" >draw</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col2\" class=\"data row8 col2\" >28.49ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col3\" class=\"data row8 col3\" >78.12ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col4\" class=\"data row8 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col5\" class=\"data row8 col5\" >8.375 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row8_col6\" class=\"data row8 col6\" >2%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col0\" class=\"data row9 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col1\" class=\"data row9 col1\" >zero_grad</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col2\" class=\"data row9 col2\" >2.437ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col3\" class=\"data row9 col3\" >324.4µs</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col4\" class=\"data row9 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col5\" class=\"data row9 col5\" >716.4ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row9_col6\" class=\"data row9 col6\" >0%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col0\" class=\"data row10 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col1\" class=\"data row10 col1\" >loss</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col2\" class=\"data row10 col2\" >958.6µs</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col3\" class=\"data row10 col3\" >107.4µs</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col4\" class=\"data row10 col4\" >294</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col5\" class=\"data row10 col5\" >281.8ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row10_col6\" class=\"data row10 col6\" >0%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col0\" class=\"data row11 col0\" >valid</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col1\" class=\"data row11 col1\" >batch</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col2\" class=\"data row11 col2\" >72.83ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col3\" class=\"data row11 col3\" >176.0ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col4\" class=\"data row11 col4\" >124</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col5\" class=\"data row11 col5\" >9.031 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row11_col6\" class=\"data row11 col6\" >2%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col0\" class=\"data row12 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col1\" class=\"data row12 col1\" >pred</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col2\" class=\"data row12 col2\" >40.13ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col3\" class=\"data row12 col3\" >126.7ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col4\" class=\"data row12 col4\" >124</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col5\" class=\"data row12 col5\" >4.976 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row12_col6\" class=\"data row12 col6\" >1%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col0\" class=\"data row13 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col1\" class=\"data row13 col1\" >draw</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col2\" class=\"data row13 col2\" >31.58ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col3\" class=\"data row13 col3\" >121.3ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col4\" class=\"data row13 col4\" >124</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col5\" class=\"data row13 col5\" >3.916 s</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row13_col6\" class=\"data row13 col6\" >1%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col0\" class=\"data row14 col0\" ></td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col1\" class=\"data row14 col1\" >loss</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col2\" class=\"data row14 col2\" >967.8µs</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col3\" class=\"data row14 col3\" >1.034ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col4\" class=\"data row14 col4\" >124</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col5\" class=\"data row14 col5\" >120.0ms</td>\n",
       "                        <td id=\"T_a0525fb0_3831_11ec_a814_0242ac1c0002row14_col6\" class=\"data row14 col6\" >0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe6c5578850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|slow\n",
    "learn = Learner(dls, xse_resnet50(n_out=dls.c), metrics=accuracy).to_fp16().profile()\n",
    "learn.fit_one_cycle(2, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a XResNet18, the total time spent drawing while training increases to 20 seconds, twenty percent of total fit time. This is due to Colab's four core CPU and slow disk not being able to prefetch quickly enough, causing the training process to wait on drawing a batch. In contrast in the XSEResNet50 training above, total training draw time was only 8 seconds, two percent of the total fit time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.552181</td>\n",
       "      <td>1.569250</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.148098</td>\n",
       "      <td>1.137456</td>\n",
       "      <td>0.638217</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002\" class=\"dataframe\"><caption>Simple Profiler Results</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Phase</th>        <th class=\"col_heading level0 col1\" >Action</th>        <th class=\"col_heading level0 col2\" >Mean Duration</th>        <th class=\"col_heading level0 col3\" >Duration Std Dev</th>        <th class=\"col_heading level0 col4\" >Number of Calls</th>        <th class=\"col_heading level0 col5\" >Total Time</th>        <th class=\"col_heading level0 col6\" >Percent of Total</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col0\" class=\"data row0 col0\" >fit</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col1\" class=\"data row0 col1\" >fit</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col5\" class=\"data row0 col5\" >99.46 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row0_col6\" class=\"data row0 col6\" >100%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col0\" class=\"data row1 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col1\" class=\"data row1 col1\" >epoch</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col2\" class=\"data row1 col2\" >49.73 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col3\" class=\"data row1 col3\" >91.12ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col5\" class=\"data row1 col5\" >99.46 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row1_col6\" class=\"data row1 col6\" >100%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col0\" class=\"data row2 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col1\" class=\"data row2 col1\" >train</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col2\" class=\"data row2 col2\" >34.84 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col3\" class=\"data row2 col3\" >7.996ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col4\" class=\"data row2 col4\" >2</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col5\" class=\"data row2 col5\" >69.68 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row2_col6\" class=\"data row2 col6\" >70%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col0\" class=\"data row3 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col1\" class=\"data row3 col1\" >validate</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col2\" class=\"data row3 col2\" >14.89 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col3\" class=\"data row3 col3\" >82.42ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col4\" class=\"data row3 col4\" >2</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col5\" class=\"data row3 col5\" >29.78 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row3_col6\" class=\"data row3 col6\" >30%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col0\" class=\"data row4 col0\" >train</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col1\" class=\"data row4 col1\" >batch</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col2\" class=\"data row4 col2\" >228.9ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col3\" class=\"data row4 col3\" >102.6ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col4\" class=\"data row4 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col5\" class=\"data row4 col5\" >67.30 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row4_col6\" class=\"data row4 col6\" >68%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col0\" class=\"data row5 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col1\" class=\"data row5 col1\" >step</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col2\" class=\"data row5 col2\" >130.7ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col3\" class=\"data row5 col3\" >9.819ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col4\" class=\"data row5 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col5\" class=\"data row5 col5\" >38.43 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row5_col6\" class=\"data row5 col6\" >39%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col0\" class=\"data row6 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col1\" class=\"data row6 col1\" >draw</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col2\" class=\"data row6 col2\" >68.27ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col3\" class=\"data row6 col3\" >102.4ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col4\" class=\"data row6 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col5\" class=\"data row6 col5\" >20.07 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row6_col6\" class=\"data row6 col6\" >20%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col0\" class=\"data row7 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col1\" class=\"data row7 col1\" >pred</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col2\" class=\"data row7 col2\" >16.81ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col3\" class=\"data row7 col3\" >6.889ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col4\" class=\"data row7 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col5\" class=\"data row7 col5\" >4.942 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row7_col6\" class=\"data row7 col6\" >5%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col0\" class=\"data row8 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col1\" class=\"data row8 col1\" >backward</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col2\" class=\"data row8 col2\" >9.573ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col3\" class=\"data row8 col3\" >2.601ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col4\" class=\"data row8 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col5\" class=\"data row8 col5\" >2.815 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row8_col6\" class=\"data row8 col6\" >3%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col0\" class=\"data row9 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col1\" class=\"data row9 col1\" >zero_grad</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col2\" class=\"data row9 col2\" >1.990ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col3\" class=\"data row9 col3\" >2.550ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col4\" class=\"data row9 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col5\" class=\"data row9 col5\" >585.0ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row9_col6\" class=\"data row9 col6\" >1%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col0\" class=\"data row10 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col1\" class=\"data row10 col1\" >loss</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col2\" class=\"data row10 col2\" >1.378ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col3\" class=\"data row10 col3\" >2.065ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col4\" class=\"data row10 col4\" >294</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col5\" class=\"data row10 col5\" >405.0ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row10_col6\" class=\"data row10 col6\" >0%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col0\" class=\"data row11 col0\" >valid</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col1\" class=\"data row11 col1\" >batch</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col2\" class=\"data row11 col2\" >209.4ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col3\" class=\"data row11 col3\" >282.0ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col4\" class=\"data row11 col4\" >124</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col5\" class=\"data row11 col5\" >25.96 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row11_col6\" class=\"data row11 col6\" >26%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col0\" class=\"data row12 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col1\" class=\"data row12 col1\" >draw</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col2\" class=\"data row12 col2\" >192.7ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col3\" class=\"data row12 col3\" >282.0ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col4\" class=\"data row12 col4\" >124</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col5\" class=\"data row12 col5\" >23.89 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row12_col6\" class=\"data row12 col6\" >24%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col0\" class=\"data row13 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col1\" class=\"data row13 col1\" >pred</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col2\" class=\"data row13 col2\" >15.27ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col3\" class=\"data row13 col3\" >12.77ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col4\" class=\"data row13 col4\" >124</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col5\" class=\"data row13 col5\" >1.893 s</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row13_col6\" class=\"data row13 col6\" >2%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col0\" class=\"data row14 col0\" ></td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col1\" class=\"data row14 col1\" >loss</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col2\" class=\"data row14 col2\" >1.269ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col3\" class=\"data row14 col3\" >2.028ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col4\" class=\"data row14 col4\" >124</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col5\" class=\"data row14 col5\" >157.4ms</td>\n",
       "                        <td id=\"T_dbc85f9a_3831_11ec_a814_0242ac1c0002row14_col6\" class=\"data row14 col6\" >0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe6c4a966d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|slow\n",
    "learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy).to_fp16().profile()\n",
    "learn.fit_one_cycle(2, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Training Loop\n",
    "The `show_training_loop` output below shows where the new `before_draw` event fits into the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fit\n",
      "   - before_fit     : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "  Start Epoch Loop\n",
      "     - before_epoch   : [Recorder, ProgressCallback]\n",
      "    Start Train\n",
      "       - before_train   : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - before_draw    : []\n",
      "         - before_batch   : []\n",
      "         - after_pred     : []\n",
      "         - after_loss     : []\n",
      "         - before_backward: []\n",
      "         - before_step    : []\n",
      "         - after_step     : []\n",
      "         - after_cancel_batch: []\n",
      "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      End Batch Loop\n",
      "    End Train\n",
      "     - after_cancel_train: [Recorder]\n",
      "     - after_train    : [Recorder, ProgressCallback]\n",
      "    Start Valid\n",
      "       - before_validate: [TrainEvalCallback, Recorder, ProgressCallback]\n",
      "      Start Batch Loop\n",
      "         - **CBs same as train batch**: []\n",
      "      End Batch Loop\n",
      "    End Valid\n",
      "     - after_cancel_validate: [Recorder]\n",
      "     - after_validate : [Recorder, ProgressCallback]\n",
      "  End Epoch Loop\n",
      "   - after_cancel_epoch: []\n",
      "   - after_epoch    : [Recorder]\n",
      "End Fit\n",
      " - after_cancel_fit: []\n",
      " - after_fit      : [ProgressCallback]\n"
     ]
    }
   ],
   "source": [
    "learn = synth_learner()\n",
    "learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Profiler Wandb Logging\n",
    "> Automatically logs Simple Profiler Callback to wandb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs two tables to active wandb run: \n",
    "- `simple_profile_report`: formatted report from Simple Profiler Callback\n",
    "- `simple_profile_results`: raw results from Simple Profiler Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "try:\n",
    "    import wandb\n",
    "    from fastai.callback.wandb import WandbCallback\n",
    "\n",
    "    if not hasattr(WandbCallback,'_orig_before_fit'): WandbCallback._orig_before_fit = WandbCallback.before_fit\n",
    "    if not hasattr(WandbCallback,'_orig_after_fit'): WandbCallback._orig_after_fit = WandbCallback.after_fit\n",
    "\n",
    "    @patch\n",
    "    def before_fit(self:WandbCallback):\n",
    "        if not hasattr(self.learn, 'lr_finder') and hasattr(self.learn, 'simple_profiler'):\n",
    "            self.log_simple_profiler = True\n",
    "        else:\n",
    "            self.log_simple_profiler = False\n",
    "        \n",
    "        self._orig_before_fit()\n",
    "\n",
    "    @patch\n",
    "    def after_fit(self:WandbCallback):\n",
    "        self._orig_after_fit()\n",
    "\n",
    "        if self.log_simple_profiler:\n",
    "            report = wandb.Table(dataframe=self.learn.simple_profile_report)\n",
    "            results = wandb.Table(dataframe=self.learn.simple_profile_results)\n",
    "\n",
    "            wandb.log({\"simple_profile_report\": report})\n",
    "            wandb.log({\"simple_profile_results\": results})\n",
    "            wandb.log({}) # ensure sync \n",
    "            \n",
    "            self.log_simple_profiler = False\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted augment.tensor_item_tfm.ipynb.\n",
      "Converted callback.cutmixup.ipynb.\n",
      "Converted callback.lr_finder.ipynb.\n",
      "Converted callback.simpleprofiler.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted schedulers.fit_flat_varied.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
