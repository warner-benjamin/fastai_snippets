{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from types import FunctionType\n",
    "\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    raise ImportError(\"timm is required to use MESACallback. Install via `pip install timm`.\")\n",
    "\n",
    "from timm.utils.model_ema import ModelEmaV2\n",
    "\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.mixup import reduce_loss\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.layers import NoneReduce\n",
    "\n",
    "from fastxtend.multiloss import MultiLoss, MultiLossCallback, MixHandlerX\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastxtend.test_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-Efficient Sharpness-Aware Callback\n",
    "> First pass at a callback to add [Memory-Efficient Sharpness-Aware](https://arxiv.org/abs/2205.14083) training to fastai. EMA implementation from [timm](https://github.com/rwightman/pytorch-image-models/blob/master/timm/utils/model_ema.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MESALoss(MultiLoss):\n",
    "    def __init__(self,\n",
    "        orig_loss:nn.Module|FunctionType,\n",
    "        temp:Number=3, # Soften MESA targets by this temperature. τ in paper\n",
    "        weight:float=0.8, # Weight of MESA loss. λ in paper\n",
    "        reduction:str='mean' # PyTorch loss reduction\n",
    "    ):\n",
    "        store_attr(but='reduction')\n",
    "        self.temp = 1/temp\n",
    "        if hasattr(self.orig_loss, 'reduction'): self.orig_loss.reduction = reduction\n",
    "        else: self.orig_loss = partial(self.orig_loss, reduction=reduction)\n",
    "        self._mesa_loss = nn.KLDivLoss(log_target=True, reduction='batchmean' if reduction=='mean' else reduction)\n",
    "        self.mesa_loss = False\n",
    "        self.loss_names = L('orig_loss', 'mesa_loss')\n",
    "        self.loss_funcs = self.loss_names # compatibility with MultiLossCallback\n",
    "        self._zero, self._loss = torch.tensor(0., requires_grad=False), {}\n",
    "        if getattr(self.orig_loss, 'y_int', False): self.y_int = True\n",
    "\n",
    "    def forward(self, pred, *targs):\n",
    "        targ, mesa_targ = targs\n",
    "        self._loss[0] = self.orig_loss(pred, targ)\n",
    "        if self.mesa_loss:\n",
    "            self._loss[1] = self.weight*self._mesa_loss(F.log_softmax(self.temp*pred, dim=1), F.log_softmax(self.temp*mesa_targ, dim=1))\n",
    "        else:\n",
    "            self._loss[1] = self._zero\n",
    "        return self._loss[0] + self._loss[1]\n",
    "\n",
    "    def forward_mixup(self, pred, *targs):\n",
    "        targ1, targ2, mesa_targ, lam = targs\n",
    "        with NoneReduce(self.orig_loss) as ol:\n",
    "            loss = torch.lerp(ol(pred, targ1), ol(pred, targ2), lam)\n",
    "        self._loss[0] = reduce_loss(loss, getattr(self.orig_loss, 'reduction', 'mean'))\n",
    "        if self.mesa_loss:\n",
    "            self._loss[1] = self.weight*self._mesa_loss(F.log_softmax(self.temp*pred, dim=1), F.log_softmax(self.temp*mesa_targ, dim=1))\n",
    "        else:\n",
    "            self._loss[1] = self._zero\n",
    "        return self._loss[0] + self._loss[1]\n",
    "\n",
    "    @property\n",
    "    def reduction(self): return self._reduction\n",
    "\n",
    "    @reduction.setter\n",
    "    def reduction(self, r):\n",
    "        if hasattr(self.orig_loss, 'reduction'): self.orig_loss.reduction = r\n",
    "        else: self.orig_loss = partial(self.orig_loss, reduction=r)\n",
    "        self._mesa_loss.reduction = 'batchmean' if r=='mean' else r\n",
    "        self._reduction = r\n",
    "\n",
    "    @delegates(Module.to)\n",
    "    def to(self, *args, **kwargs):\n",
    "        device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)\n",
    "        self._zero.to(device)\n",
    "        super(Module, self).to(*args, **kwargs)\n",
    "\n",
    "    def activation(self, pred):\n",
    "        \"Returns `orig_loss` `activation`\"\n",
    "        return getattr(self.orig_loss, 'activation', noop)(pred)\n",
    "\n",
    "    def decodes(self, pred):\n",
    "        \"Returns `orig_loss` `decodes`\"\n",
    "        return getattr(self.orig_loss, 'decodes', noop)(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MESACallback(Callback):\n",
    "    order = MixedPrecision.order+1\n",
    "    \"Callback to implment Memory-Efficient Sharpness-Aware training from https://arxiv.org/abs/2205.14083\"\n",
    "    def __init__(self,\n",
    "        start_epoch:int=5, # Epoch to start MESA. Defaults to `start_pct` if None (index 1)\n",
    "        temp:Number=3, # Soften MESA targets by this temperature. τ in paper\n",
    "        weight:float=0.8, # Weight of MESA loss. λ in paper\n",
    "        decay:float=0.9998, # EMA decay. β in paper\n",
    "        reduction:str='mean', # PyTorch loss reduction\n",
    "        cleanup:bool=True\n",
    "    ):\n",
    "        store_attr()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def before_fit(self):\n",
    "        if hasattr(self.learn, 'lr_finder') or hasattr(self, \"gather_preds\"): return\n",
    "        self.start_epoch=self.start_epoch-1\n",
    "        self._ema_pred = lambda x: 0\n",
    "        self.orig_loss = self.learn.loss_func\n",
    "        self.orig_loss_reduction = self.orig_loss.reduction if hasattr(self.orig_loss, 'reduction') else None\n",
    "        self.learn.loss_func = MESALoss(self.orig_loss, self.temp, self.weight, self.reduction)\n",
    "        self.learn.loss_func.to(getattr(self.dls, 'device', default_device()))\n",
    "        self.ema_model = ModelEmaV2(self.learn.model, self.decay)\n",
    "        self._mixup = len(self.learn._grab_cbs(MixHandlerX)) > 0 and getattr(self.orig_loss, 'y_int', False)\n",
    "\n",
    "    def before_train(self):\n",
    "        if self.start_epoch == self.epoch:\n",
    "            if self._mixup: self.learn.loss_func_mixup.mesa_loss = True\n",
    "            else:           self.learn.loss_func.mesa_loss = True\n",
    "            self._ema_pred = self.ema_model.module\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def after_pred(self):\n",
    "        self.learn.yb = tuple([self.y, self._ema_pred(*self.xb)])\n",
    "\n",
    "    def after_loss(self):\n",
    "        y, _ = self.yb\n",
    "        self.learn.yb = tuple([y])\n",
    "\n",
    "    def after_batch(self):\n",
    "        self.ema_model.update(self.learn.model)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def after_fit(self):\n",
    "        if self.cleanup:\n",
    "            if hasattr(self.orig_loss, 'reduction'):\n",
    "                self.orig_loss.reduction = self.orig_loss_reduction\n",
    "            self.learn.loss_func = self.orig_loss\n",
    "            self.ema_model = None\n",
    "            self.remove_cb(MESACallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.learner import Learner, Recorder\n",
    "from fastai.vision.augment import Resize\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models.xresnet import xresnet18\n",
    "\n",
    "from fastxtend.callback.cutmixup import MixUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_orig_loss</th>\n",
       "      <th>train_mesa_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_orig_loss</th>\n",
       "      <th>valid_mesa_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.764903</td>\n",
       "      <td>1.764903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.589739</td>\n",
       "      <td>1.589739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.248024</td>\n",
       "      <td>1.248024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.415202</td>\n",
       "      <td>1.415202</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.036043</td>\n",
       "      <td>1.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.170383</td>\n",
       "      <td>1.170383</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.853409</td>\n",
       "      <td>0.853409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.038804</td>\n",
       "      <td>1.038804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.897851</td>\n",
       "      <td>0.743198</td>\n",
       "      <td>0.154654</td>\n",
       "      <td>1.098253</td>\n",
       "      <td>0.927330</td>\n",
       "      <td>0.170922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.788958</td>\n",
       "      <td>0.628259</td>\n",
       "      <td>0.160699</td>\n",
       "      <td>0.966897</td>\n",
       "      <td>0.799375</td>\n",
       "      <td>0.167522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.677702</td>\n",
       "      <td>0.511786</td>\n",
       "      <td>0.165916</td>\n",
       "      <td>0.941499</td>\n",
       "      <td>0.786114</td>\n",
       "      <td>0.155385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.563589</td>\n",
       "      <td>0.397229</td>\n",
       "      <td>0.166360</td>\n",
       "      <td>0.881339</td>\n",
       "      <td>0.713294</td>\n",
       "      <td>0.168045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.492636</td>\n",
       "      <td>0.325024</td>\n",
       "      <td>0.167612</td>\n",
       "      <td>0.865666</td>\n",
       "      <td>0.704752</td>\n",
       "      <td>0.160914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.460393</td>\n",
       "      <td>0.293331</td>\n",
       "      <td>0.167062</td>\n",
       "      <td>0.860304</td>\n",
       "      <td>0.702629</td>\n",
       "      <td>0.157675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "with no_random():\n",
    "    imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(64),\n",
    "                        batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
    "    dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus())\n",
    "\n",
    "    learn = Learner(dls, xresnet18(n_out=dls.c), cbs=[MESACallback, MultiLossCallback])\n",
    "    learn.remove_cb(Recorder)\n",
    "    learn.add_cb(Recorder(add_time=False))\n",
    "    learn.fit_one_cycle(10, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_orig_loss</th>\n",
       "      <th>train_mesa_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_orig_loss</th>\n",
       "      <th>valid_mesa_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.936363</td>\n",
       "      <td>1.936363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.637596</td>\n",
       "      <td>1.637596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.596632</td>\n",
       "      <td>1.596632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.494622</td>\n",
       "      <td>1.494622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.423184</td>\n",
       "      <td>1.423184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.211276</td>\n",
       "      <td>1.211276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.326761</td>\n",
       "      <td>1.326761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.170963</td>\n",
       "      <td>1.170963</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.352496</td>\n",
       "      <td>1.263226</td>\n",
       "      <td>0.089270</td>\n",
       "      <td>1.062338</td>\n",
       "      <td>0.940975</td>\n",
       "      <td>0.121363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.273435</td>\n",
       "      <td>1.180923</td>\n",
       "      <td>0.092512</td>\n",
       "      <td>1.022477</td>\n",
       "      <td>0.905502</td>\n",
       "      <td>0.116975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.196219</td>\n",
       "      <td>1.102559</td>\n",
       "      <td>0.093661</td>\n",
       "      <td>0.944279</td>\n",
       "      <td>0.825535</td>\n",
       "      <td>0.118744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.125571</td>\n",
       "      <td>1.030896</td>\n",
       "      <td>0.094675</td>\n",
       "      <td>0.877916</td>\n",
       "      <td>0.752801</td>\n",
       "      <td>0.125115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.067545</td>\n",
       "      <td>0.972960</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>0.858698</td>\n",
       "      <td>0.745409</td>\n",
       "      <td>0.113289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.062083</td>\n",
       "      <td>0.969335</td>\n",
       "      <td>0.092748</td>\n",
       "      <td>0.853712</td>\n",
       "      <td>0.740154</td>\n",
       "      <td>0.113558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "\n",
    "# mixup test\n",
    "with no_random():\n",
    "    imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(64),\n",
    "                        batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
    "    dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus())\n",
    "\n",
    "    learn = Learner(dls, xresnet18(n_out=dls.c), cbs=[MESACallback, MultiLossCallback, MixUp])\n",
    "    learn.remove_cb(Recorder)\n",
    "    learn.add_cb(Recorder(add_time=False))\n",
    "    learn.fit_one_cycle(10, 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
