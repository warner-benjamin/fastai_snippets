{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "# Contains code from:\n",
    "# fastai - Apache License 2.0 - Copyright (c) 2023 fast.ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Compile [beta]\n",
    "> Experimental callbacks and patches to integrate `torch.compile` into fastai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CompilerCallback` and `DynamoExplainCallback` are experiments to provide an easy to use `torch.compile` integration for fastai.\n",
    "\n",
    "`torch.compile` with the default inductor backend [allows 30% to 2x speedups and 10% memory compression](https://github.com/pytorch/pytorch/issues/93794) for both training and inference.\n",
    "\n",
    "For more information on `torch.compile` please read *[PyTorch's getting started](https://pytorch.org/docs/master/compile/get-started.html)* guide. For troubleshooting `torch.compile` refer to this [PyTorch Nightly guide](https://pytorch.org/docs/master/compile/index.html#troubleshooting-and-gotchas).\n",
    "\n",
    "This module is not imported via any fastxtend all imports. You must import it separately after importing fastai and fastxtend:\n",
    "\n",
    "```python\n",
    "from fastxtend.callback import compiler\n",
    "# or\n",
    "from fastxtend.callback.compiler import *\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "from typing import Dict\n",
    "\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from packaging.version import parse\n",
    "\n",
    "import torch._dynamo as dynamo\n",
    "from torch.serialization import FILE_LIKE\n",
    "\n",
    "from fastai.learner import Learner, save_model, join_path_file, _cast_tensor\n",
    "from fastai.callback import schedule\n",
    "from fastai.callback.core import Callback, TrainEvalCallback, CancelFitException\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "\n",
    "try:\n",
    "    from fastxtend.ffcv.loader import Loader\n",
    "    FFCV = True\n",
    "except ImportError:\n",
    "    FFCV = False\n",
    "\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastai.vision.learner import vision_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_torch_version = parse(torch.__version__)\n",
    "_torch_20 = parse('2.0')\n",
    "_torch_21 = parse('2.1')\n",
    "\n",
    "if _torch_version < _torch_20:\n",
    "    warn('Imported `fastxtend.callback.compiler`, which requires a minimum of PyTorch 2.0 to work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CompileMode(str, Enum):\n",
    "    \"All valid `torch.compile` modes for tab-completion and typo-proofing\"\n",
    "    default        = 'default'\n",
    "    reduceoverhead = 'reduce-overhead'\n",
    "    maxautotune    = 'max-autotune'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the 'reduce-overhead' mode doesn't appear to train, instead the loss stagnates, and 'max-autotune' shouldn't be used per *[Compile troubleshooting and gotchas](https://pytorch.org/docs/master/compile/index.html#troubleshooting-and-gotchas)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MatMulPrecision(str, Enum):\n",
    "    \"All valid `matmul_precision` modes for tab-completion and typo-proofing\"\n",
    "    highest = 'highest'\n",
    "    high    = 'high'\n",
    "    medium  = 'medium'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CompilerCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CompilerCallback(Callback):\n",
    "    \"An experimental callback for `torch.compile` (beta) and fastai\"\n",
    "    order = TrainEvalCallback.order + 1 # Compiling needs to occur on the GPU, but before distributed training starts\n",
    "\n",
    "    def __init__(self,\n",
    "        fullgraph:bool=False, # Prevent breaking model into subgraphs\n",
    "        dynamic:bool=False, # Use dynamic shape tracing\n",
    "        backend:str|Callable='inductor', # `torch.compile` backend to use\n",
    "        mode:str|CompileMode|None=None, # `torch.compile` mode to use\n",
    "        options:Dict[str, Union[str,int,bool]]|None=None, # Extra options to pass to compile backend\n",
    "        matmul_precision:str|MatMulPrecision='high', # Set Ampere and newer TF32 matmul precision\n",
    "        recompile:bool=False, # Force a compiled model to recompile. Use when freezing/unfreezing a compiled model.\n",
    "        verbose:bool=True, # Verbose output\n",
    "    ):\n",
    "        if isinstance(mode, CompileMode):\n",
    "            mode = mode.value\n",
    "        if isinstance(mode, MatMulPrecision):\n",
    "            matmul_precision = matmul_precision.value\n",
    "        if mode is not None and options is not None:\n",
    "            raise ValueError(f\"Both {mode=} or {options=} cannot be set at the same time.\")\n",
    "        store_attr(but='recompile')\n",
    "        self._recompile = recompile\n",
    "\n",
    "    def before_fit(self):\n",
    "        if _torch_version < _torch_20:\n",
    "            self.run = False\n",
    "            warn(\"Attempting to use `CompilerCallback` without PyTorch 2.0 or greater. Disabling.\")\n",
    "            return\n",
    "\n",
    "        if torch.cuda.get_device_capability() >= (8, 0) and torch.get_float32_matmul_precision() != self.matmul_precision:\n",
    "            if self.verbose and self.matmul_precision!='highest':\n",
    "                print(f\"Your GPU has modern tensor cores, automatically enabling by setting `torch.set_float32_matmul_precision('{self.matmul_precision}')`\")\n",
    "            torch.set_float32_matmul_precision(self.matmul_precision)\n",
    "\n",
    "        if hasattr(self.learn, 'progressive_resize') and _torch_version < _torch_21:\n",
    "            warn(\"Using `ProgressiveResize` and `torch.compile` at the same time will result in a new compile every size change.\")\n",
    "        msg = \"\"\n",
    "        if self.dynamic:\n",
    "            msg += \"Using `torch.compile` with dynamic shapes is under active development and might fail\\n\"\n",
    "        if self.mode == 'max-autotune':\n",
    "            msg += \"Using `torch.compile` with `mode='max-autotune'` is under active development and might fail\\n\"\n",
    "        if msg != \"\":\n",
    "            msg += \"See https://pytorch.org/docs/master/compile/index.html#troubleshooting-and-gotchas for more details\"\n",
    "            warn(msg)\n",
    "        if self.mode == 'reduce-overhead':\n",
    "            warn(\"Using `torch.compile` & fastai with `mode='reduce-overhead'` currently doesn't appear to train.\")\n",
    "\n",
    "        if self._recompile and isinstance(self.learn.model, dynamo.OptimizedModule):\n",
    "            if self.verbose:\n",
    "                print(\"Recompiling model\")\n",
    "            dynamo.reset()\n",
    "            self.learn.model = self.learn.model._orig_mod\n",
    "        self._recompile = False\n",
    "\n",
    "        if not isinstance(self.learn.model, dynamo.OptimizedModule):\n",
    "            self.learn.model = torch.compile(self.learn.model, fullgraph=self.fullgraph,\n",
    "                                             dynamic=self.dynamic, backend=self.backend,\n",
    "                                             mode=self.mode, options=self.options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `torch.compile` with dynamic shapes and `mode='max-autotune'` is under active development and might fail. See *[Compile troubleshooting and gotchas](https://pytorch.org/docs/master/compile/index.html#troubleshooting-and-gotchas)* for more details.\n",
    "\n",
    "By default, <code>CompilerCallback</code> will set matmul ops to use TensorFloat32 for supported GPUs, which is the recommended setting for `torch.compile`. Set `matmul_precision='highest'` to turn off or `matmul_precision='medium'` to enable `bfloat16` mode.\n",
    "\n",
    "fastxtend provides the [compile](#learner.compile) convenience method for easily enabling `torch.compile`. Or you can pass <code>CompilerCallback</code> to the `cbs` argument of the `fastai.learner.Learner` or a fit method.\n",
    "\n",
    "```python\n",
    "learn = Learner(..., cbs=CompilerCallback())\n",
    "learn.fine_tune(1)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DynamoExplainCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DynamoExplainCallback(Callback):\n",
    "    \"An experimental callback to find graph breaks with `torch.compile` (beta)\"\n",
    "    order = MixedPrecision.order+1 # DynamoExplain occurs on the GPU before any training starts\n",
    "\n",
    "    def __init__(self,\n",
    "        print_results:bool=True, # Print enabled `torch._dynamo.explain` output(s)\n",
    "        explanation:bool=True, # Print the `explanation` output\n",
    "        out_guards:bool=False, # Print the `out_guards` output\n",
    "        graphs:bool=False, # Print the `graphs` output\n",
    "        ops_per_graph:bool=False, # Print the `ops_per_graph` output\n",
    "        break_reasons:bool=False, # Print the `break_reasons` output\n",
    "        explanation_verbose:bool=False, # Print the `explanation_verbose` output\n",
    "    ):\n",
    "        self.print_results = print_results\n",
    "        self.print_explanation = explanation\n",
    "        self.print_out_guards = out_guards\n",
    "        self.print_graphs = graphs\n",
    "        self.print_ops_per_graph = ops_per_graph\n",
    "        self.print_break_reasons = break_reasons\n",
    "        self.print_explanation_verbose = explanation_verbose\n",
    "\n",
    "    def before_fit(self):\n",
    "        if _torch_version < _torch_20:\n",
    "            self.run = False\n",
    "            warn(\"Attempting to use `DynamoExplainCallback` without PyTorch 2.0 or greater. Canceling training.\")\n",
    "            raise CancelFitException()\n",
    "\n",
    "        self.explanation, self.out_guards, self.graphs, self.ops_per_graph, self.break_reasons, self.explanation_verbose = '','','','','',''\n",
    "        states = get_random_states()\n",
    "        try:\n",
    "            if FFCV and isinstance(self.dls.train, Loader) and self.dls.train.async_tfms:\n",
    "                # With `async_tfms`, `Loader` needs to initialize all `Loader.batches_ahead` Cuda streams\n",
    "                # for the training dataloader. Since FFCV doesn't support seeded transforms and the reset\n",
    "                # random state only seeds the dataset order, this shouldn't effect training outcome.\n",
    "                b = self.dls.train.one_batch(batches_ahead=True)\n",
    "            else:\n",
    "                b = self.dls.valid.one_batch()\n",
    "            i = getattr(self.dls, 'n_inp', 1 if len(b)==1 else len(b)-1)\n",
    "            self.learn.xb, self.learn.yb = b[:i], b[i:]\n",
    "\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                self.learn.mixed_precision.autocast.__enter__()\n",
    "\n",
    "            self.explanation, self.out_guards, self.graphs, self.ops_per_graph, self.break_reasons, self.explanation_verbose \\\n",
    "                = dynamo.explain(self.learn.model, *_cast_tensor(self.learn.xb))\n",
    "\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                self.learn.mixed_precision.autocast.__exit__(None, None, None)\n",
    "\n",
    "            self.learn.opt.zero_grad()\n",
    "        finally:\n",
    "            set_random_states(**states)\n",
    "\n",
    "        if self.print_results:\n",
    "            print('\\nDynamo Explain Report')\n",
    "            if self.print_explanation:\n",
    "                print('\\nExplanation:\\n')\n",
    "                print(self.explanation)\n",
    "            if self.print_out_guards:\n",
    "                print('\\nOut Guards:\\n')\n",
    "                print(self.out_guards)\n",
    "            if self.print_graphs:\n",
    "                print('\\nGraphs:\\n')\n",
    "                print(self.graphs)\n",
    "            if self.print_ops_per_graph:\n",
    "                print('\\nOperations per Graph:\\n')\n",
    "                print(self.ops_per_graph)\n",
    "            if self.print_break_reasons:\n",
    "                print('\\nBreak Reasons:\\n')\n",
    "                print(self.break_reasons)\n",
    "            if self.print_explanation_verbose:\n",
    "                print('\\nVerbose Explanation:\\n')\n",
    "                print(self.explanation_verbose)\n",
    "            print('\\n')\n",
    "\n",
    "        raise CancelFitException()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DynamoExplainCallback` automates finding graph breaks using `torch._dynamo.explain` per the *[Identifying the cause of a graph break](https://pytorch.org/docs/stable/dynamo/faq.html#identifying-the-cause-of-a-graph-break)* section in the *[PyTorch Compile FAQ](https://pytorch.org/docs/stable/dynamo/faq.html)*. <code>DynamoExplainCallback</code> uses one batch from the validation dataloader[^Loader] to generate the `_dynamo.explain` report(s) and then cancels training.\n",
    "\n",
    "To use, pass <code>DynamoExplainCallback</code> to the `cbs` argument of the `fastai.learner.Learner` or fit method.\n",
    "\n",
    "```python\n",
    "learn = Learner(..., cbs=DynamoExplainCallback())\n",
    "learn.fit(1)\n",
    "```\n",
    "\n",
    "By default, <code>DynamoExplainCallback</code> prints the `explanation` output from `_dynamo.explain`, with arguments to enable printing `out_guards`, `graphs`, `ops_per_graph`, `break_reasons`, and/or `explanation_verbose`.\n",
    "\n",
    "All `_dynamo.explain` outputs are stored as attributes in the callback for later reference. For example, to view the verbose explanation after running `Learner` with <code>DynamoExplainCallback</code>:\n",
    "\n",
    "```python\n",
    "print(learn.dynamo_explain.explanation_verbose)\n",
    "```\n",
    "\n",
    "[^Loader]: Unless using the FFCV `Loader`, then it uses the training dataloader. This doesn't effect seeded training as FFCV dataloaders do not seed transforms, only dataset order."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Method\n",
    "\n",
    "fastxtend adds a convenience method to `Learner` to easily enable `torch.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def compile(self:Learner,\n",
    "    fullgraph:bool=False, # Prevent breaking model into subgraphs\n",
    "    backend:str|Callable='inductor', # `torch.compile` backend to use\n",
    "    mode:str|CompileMode|None=None, # `torch.compile` mode to use\n",
    "    options:Dict[str, Union[str,int,bool]]|None=None, # Extra options to pass to compile backend\n",
    "    matmul_precision:str|MatMulPrecision='high', # Set Ampere and newer TF32 matmul precision\n",
    "    recompile:bool=False, # Force a compiled model to recompile. Use when freezing/unfreezing a compiled model.\n",
    "    verbose:bool=True, # Verbose output\n",
    "):\n",
    "    \"Set `Learner` to compile model using `torch.compile`.\"\n",
    "    return self.add_cb(CompilerCallback(fullgraph=fullgraph, backend=backend,\n",
    "                                        mode=mode, options=options,\n",
    "                                        matmul_precision=matmul_precision,\n",
    "                                        recompile=recompile, verbose=verbose))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compile` does not expose `dynamic` since it's recommended not to be used with PyTorch 2.0. You can set it directly via `CompilerCallback`.\n",
    "\n",
    "To use, call the `compile` method after initalizing a `fastai.learner.Learner`.\n",
    "\n",
    "```python\n",
    "learn = Learner(...).compile()\n",
    "learn.fine_tune(1)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compatability Patches\n",
    "\n",
    "These patches integrate `torch.compile` with fastai saving, loading, freezing, unfreezing, and fine tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "@delegates(save_model)\n",
    "def save(self:Learner,\n",
    "    file:FILE_LIKE, # Save file name, path, bytes, or IO\n",
    "    save_compiled:bool=False, # Save compiled model\n",
    "    **kwargs\n",
    "):\n",
    "    \"Save model and optimizer state (if `with_opt`) to `self.path/self.model_dir/file`\"\n",
    "    file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "    if _torch_version >= _torch_20 and isinstance(self.model, dynamo.OptimizedModule) and not save_compiled:\n",
    "        save_model(file, self.model._orig_mod, getattr(self,'opt',None), **kwargs)\n",
    "    else:\n",
    "        save_model(file, self.model, getattr(self,'opt',None), **kwargs)\n",
    "    return file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a compiled model is supported, but for maximum compatiblity is turned off by default. Set `save_compiled=True` to save a compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def export(self:Learner,\n",
    "    fname:FILE_LIKE='export.pkl', # Learner export file name, path, bytes, or IO\n",
    "    pickle_module:Any=pickle, # Module used for pickling metadata and objects\n",
    "    pickle_protocol:int=2 # Pickle protocol used\n",
    "):\n",
    "    \"Export the content of `self` without the items and the optimizer state for inference\"\n",
    "    if rank_distrib(): return # don't export if child proc\n",
    "    self._end_cleanup()\n",
    "    old_dbunch = self.dls\n",
    "    self.dls = self.dls.new_empty()\n",
    "    state = self.opt.state_dict() if self.opt is not None else None\n",
    "    self.opt = None\n",
    "    # torch.compiled models currently cannot be pickled.\n",
    "    if _torch_version >= _torch_20 and isinstance(self.model, dynamo.OptimizedModule):\n",
    "        self.model = self.model._orig_mod\n",
    "    with warnings.catch_warnings():\n",
    "        # To avoid the warning that come from PyTorch about model not being checked\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        torch.save(self, self.path/fname, pickle_module=pickle_module, pickle_protocol=pickle_protocol)\n",
    "    self.create_opt()\n",
    "    if state is not None: self.opt.load_state_dict(state)\n",
    "    self.dls = old_dbunch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of PyTorch 2.0 and 2.1 Nightly, compiled models cannot be pickled, so `export` sets `Learner.model` as the non-compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def load_learner(\n",
    "    fname:FILE_LIKE, # File name, path, bytes, or IO\n",
    "    cpu:bool=True, # Load model to CPU\n",
    "    pickle_module=pickle # Module used for unpickling metadata and objects\n",
    "):\n",
    "    \"Load a `Learner` object in `fname`, by default putting it on the `cpu`\"\n",
    "    distrib_barrier()\n",
    "    map_loc = 'cpu' if cpu else default_device()\n",
    "    try: res = torch.load(fname, map_location=map_loc, pickle_module=pickle_module)\n",
    "    except AttributeError as e:\n",
    "        e.args = [f\"Custom classes or functions exported with your `Learner` not available in namespace.\\Re-declare/import before loading:\\n\\t{e.args[0]}\"]\n",
    "        raise\n",
    "    if cpu:\n",
    "        res.dls.cpu()\n",
    "        if hasattr(res, 'channels_last'): res = res.to_contiguous(to_fp32=True)\n",
    "        elif hasattr(res, 'mixed_precision'): res = res.to_fp32()\n",
    "        elif hasattr(res, 'non_native_mixed_precision'): res = res.to_non_native_fp32()\n",
    "        if hasattr(res, 'compiler'): res = res.remove_cb(CompilerCallback)\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `load_learner` will remove the `CompilerCallback`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing and Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def freeze_to(self:Learner, n:int):\n",
    "    \"Freeze parameter groups up to `n`\"\n",
    "    if self.opt is None:\n",
    "        self.create_opt()\n",
    "    self.opt.freeze_to(n)\n",
    "    self.opt.clear_state()\n",
    "    if _torch_version >= _torch_20 and isinstance(self.model, dynamo.OptimizedModule):\n",
    "        if hasattr(self, 'compiler'):\n",
    "            self.compiler._recompile = True\n",
    "        else:\n",
    "            warn(\"Freezing or unfreezing a compiled model isn't supported.\"\\\n",
    "                 \"\\nThe model must be recompiled to take effect.\"\\\n",
    "                 \"\\nPass `CompilerCallback(..., recompile=True)` to `Learner.cbs`\"\\\n",
    "                 \"\\nor call `torch._dynamo.reset() and recompile model.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freezing and unfreezing models works, but they need to be recompiled after. `freeze_to` will set `CompilerCallback` to recompile the model or warn users they need to manually recompile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "@delegates(Learner.fit_one_cycle)\n",
    "def fine_tune(self:Learner,\n",
    "    epochs:int, # Number of unfrozen epochs to train\n",
    "    base_lr:float=2e-3, # Base learning rate, model head unfrozen learning rate\n",
    "    freeze_epochs:int=1, # Number of frozen epochs to train\n",
    "    lr_mult:Numeric=100, # Model stem unfrozen learning rate: `base_lr/lr_mult`\n",
    "    pct_start:float=0.3, # Start unfrozen learning rate cosine annealing\n",
    "    div:Numeric=5.0, # Initial unfrozen learning rate: `base_lr/div`\n",
    "    freeze_compile:bool=False, # pct_start for unfrozen fit_one_cycle\n",
    "    **kwargs\n",
    "):\n",
    "    \"Fine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\"\n",
    "    self.freeze()\n",
    "    if _torch_version >= _torch_20 and hasattr(self, 'compiler') and not freeze_compile:\n",
    "        self.compiler.run = isinstance(self.model, dynamo.OptimizedModule)\n",
    "    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)\n",
    "    base_lr /= 2\n",
    "    self.unfreeze()\n",
    "    self.fit_one_cycle(epochs, slice(base_lr/lr_mult, base_lr), pct_start=pct_start, div=div, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `fine_tune` will not compile the `freeze_epochs`, but this can be overridden by passing `freeze_compile=True`. If the model is already compiled, this will have no effect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "from packaging.version import parse\n",
    "import fastai\n",
    "\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "if parse(fastai.__version__) < parse('2.7.11'):\n",
    "    from fastxtend.callback.channelslast import *\n",
    "else:\n",
    "    from fastai.callback.channelslast import *\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.vision.augment import Resize, aug_transforms\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models import resnet34\n",
    "\n",
    "from fastxtend.metrics import Accuracy\n",
    "from fastxtend.optimizer.fused import adam\n",
    "from fastxtend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPU has modern tensor cores, automatically enabling by setting `torch.set_float32_matmul_precision('high')`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.880623</td>\n",
       "      <td>2.615195</td>\n",
       "      <td>0.249427</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.511329</td>\n",
       "      <td>1.463864</td>\n",
       "      <td>0.526369</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.208427</td>\n",
       "      <td>1.337830</td>\n",
       "      <td>0.569427</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.993035</td>\n",
       "      <td>0.886476</td>\n",
       "      <td>0.717197</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.818099</td>\n",
       "      <td>0.817872</td>\n",
       "      <td>0.735032</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = Learner(dls, resnet34(num_classes=dls.c), opt_func=adam(foreach=True),\n",
    "                    metrics=Accuracy()).to_channelslast().compile()\n",
    "    learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.174962</td>\n",
       "      <td>0.945987</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.245339</td>\n",
       "      <td>0.129721</td>\n",
       "      <td>0.962293</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.183843</td>\n",
       "      <td>0.153452</td>\n",
       "      <td>0.951847</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127661</td>\n",
       "      <td>0.117478</td>\n",
       "      <td>0.960509</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083120</td>\n",
       "      <td>0.106381</td>\n",
       "      <td>0.965860</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055219</td>\n",
       "      <td>0.101295</td>\n",
       "      <td>0.969936</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = vision_learner(dls, resnet34, opt_func=adam(foreach=True),\n",
    "                           metrics=Accuracy()).to_channelslast()\n",
    "    learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.174962</td>\n",
       "      <td>0.945987</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.241853</td>\n",
       "      <td>0.124922</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.190665</td>\n",
       "      <td>0.142393</td>\n",
       "      <td>0.954140</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127720</td>\n",
       "      <td>0.114811</td>\n",
       "      <td>0.963567</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.082946</td>\n",
       "      <td>0.100213</td>\n",
       "      <td>0.967643</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.098956</td>\n",
       "      <td>0.967389</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = vision_learner(dls, resnet34, opt_func=adam(foreach=True),\n",
    "                    metrics=Accuracy()).to_channelslast().compile()\n",
    "    learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.09895562380552292,0.9673885107040405]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/test.pth')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "learn.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.09896746277809143,0.9673885107040405]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "saved = vision_learner(dls, resnet34, opt_func=adam(foreach=True),\n",
    "                       metrics=Accuracy()).to_channelslast() \n",
    "saved.load('test')\n",
    "saved.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "exported = load_learner('export.pkl')\n",
    "exported.dls = learn.dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.098935067653656,0.9673885107040405]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "exported.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benja/miniconda3/envs/fastxtend/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/benja/miniconda3/envs/fastxtend/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dynamo Explain Report\n",
      "\n",
      "\n",
      "Explanation:\n",
      "\n",
      "\n",
      "Dynamo produced 1 graphs with 0 graph break and 17 ops\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = vision_learner(dls, resnet34, opt_func=adam(foreach=True), metrics=Accuracy(),\n",
    "                           cbs=DynamoExplainCallback()).to_channelslast()\n",
    "    learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in function iadd>, <built-in method cat of type object at 0x7fb991162540>]]\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "print(learn.dynamo_explain.ops_per_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
