{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp ffcv.operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "# Contains code from:\n",
    "# FFCV - Apache License 2.0 - Copyright (c) 2022 FFCV Team"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFCV Operations\n",
    "> Operations for the fastxtend `Loader`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastxtend provides multiple FFCV operations, including existing FFCV operations as [a reference](#ffcv-operation-reference), a fastai compatible `ToDevice`, and fastai compatible [Tensor conversions](#convert-to-fastai-tensors).\n",
    "\n",
    "By default, these operations are imported under `ft` if using `from fastxtend.ffcv.all import *`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "\n",
    "from abc import ABCMeta\n",
    "from typing import Callable, Optional, Tuple\n",
    "from dataclasses import replace\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from fastcore.dispatch import retain_meta\n",
    "from fastcore.transform import _TfmMeta\n",
    "\n",
    "from fastai.data.transforms import IntToFloatTensor as _IntToFloatTensor\n",
    "\n",
    "from ffcv.pipeline.allocation_query import AllocationQuery\n",
    "from ffcv.pipeline.operation import Operation\n",
    "from ffcv.pipeline.state import State\n",
    "from ffcv.transforms.ops import ToDevice as _ToDevice\n",
    "from ffcv.transforms.ops import Convert, View\n",
    "\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_all_ = ['Convert', 'View']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFCV Operations Reference\n",
    "\n",
    "These operations are from FFCV. You can find the original documentation at the [FFCV API Reference](https://docs.ffcv.io/api/transforms.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Convert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(View)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDevice\n",
    "\n",
    "While FFCV has a [<code>ToDevice</code>](https://docs.ffcv.io/api/transforms.html#ffcv.transforms.ToTensor) operation, it is recommended to use the fastxtend `ToDevice` operation for compatability with fastai features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToDevice(_ToDevice):\n",
    "    \"Move tensor to device and retains metadata\"\n",
    "    def __init__(self,\n",
    "        device:int|str|torch.device='cuda', # Device to move Tensor to\n",
    "        non_blocking:bool=True # Asynchronous if copying from CPU to GPU\n",
    "    ):\n",
    "        device, *_ = torch._C._nn._parse_to(device=device)\n",
    "        super().__init__(device, non_blocking)\n",
    "\n",
    "    def generate_code(self) -> Callable:\n",
    "        def to_device(inp, dst):\n",
    "            if len(inp.shape) == 4:\n",
    "                if inp.is_contiguous(memory_format=torch.channels_last):\n",
    "                    dst = dst.reshape(inp.shape[0], inp.shape[2], inp.shape[3], inp.shape[1])\n",
    "                    dst = dst.permute(0,3,1,2)\n",
    "            if not isinstance(dst, type(inp)):\n",
    "                dst = retain_meta(dst, torch.as_subclass(dst, type(inp)))\n",
    "            dst = dst[:inp.shape[0]]\n",
    "            dst.copy_(inp, non_blocking=self.non_blocking)\n",
    "            return dst\n",
    "        return to_device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to fastai Tensors\n",
    "\n",
    "While FFCV has [`ToTensor`](https://docs.ffcv.io/api/transforms.html#ffcv.transforms.ToTensor) and [`ToTorchImage`](https://docs.ffcv.io/api/transforms.html#ffcv.transforms.ToTorchImage) operations for converting NumPy arrays to PyTorch Tensors, it is recommended to use these fastxtend operations for compatability with fastai features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorBase -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorBase(Operation):\n",
    "    \"Convert from Numpy array to fastai TensorBase or `tensor_cls`.\"\n",
    "    def __init__(self, tensor_cls:TensorBase=TensorBase):\n",
    "        super().__init__()\n",
    "        self.tensor_cls = tensor_cls\n",
    "\n",
    "    def generate_code(self) -> Callable:\n",
    "        tensor_cls = self.tensor_cls\n",
    "        def to_tensor(inp, dst):\n",
    "            return tensor_cls(torch.from_numpy(inp))\n",
    "        return to_tensor\n",
    "\n",
    "    def declare_state_and_memory(self, previous_state: State) -> Tuple[State, Optional[AllocationQuery]]:\n",
    "        new_dtype = torch.from_numpy(np.empty((), dtype=previous_state.dtype)).dtype\n",
    "        return replace(previous_state, jit_mode=False, dtype=new_dtype), None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorImage -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorImage(ToTensorBase):\n",
    "    \"Convenience operation to convert from Numpy array to fastai TensorImage or `tensor_cls`.\"\n",
    "    def __init__(self, tensor_cls:TensorImageBase=TensorImage):\n",
    "        super().__init__()\n",
    "        self.tensor_cls = tensor_cls\n",
    "\n",
    "    def generate_code(self) -> Callable:\n",
    "        tensor_cls = self.tensor_cls\n",
    "        def to_tensor(inp, dst):\n",
    "            return tensor_cls(torch.from_numpy(inp).permute(0,3,1,2))\n",
    "        return to_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorImageBW -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorImageBW(ToTensorImage):\n",
    "    \"Convenience operation to convert from Numpy array to fastai TensorImageBW.\"\n",
    "    def __init__(self):\n",
    "        super().__init__(TensorImageBW)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorMask -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorMask(ToTensorImage):\n",
    "    \"Convenience operation to convert from Numpy array to fastai TensorMask.\"\n",
    "    def __init__(self):\n",
    "        super().__init__(TensorMask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorCategory -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorCategory(ToTensorBase):\n",
    "    \"Convenience operation to convert from Numpy array to fastxtend TensorCategory.\"\n",
    "    def __init__(self):\n",
    "        super().__init__(TensorCategory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorMultiCategory -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorMultiCategory(ToTensorBase):\n",
    "    \"Convenience operation convert from Numpy array to fastxtend TensorMultiCategory.\"\n",
    "    def __init__(self):\n",
    "        super().__init__(TensorMultiCategory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToTensorTitledTensorScalar -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ToTensorTitledTensorScalar(ToTensorBase):\n",
    "    \"Convenience operation convert from Numpy array to fastai TitledTensorScalar.\"\n",
    "    def __init__(self):\n",
    "        super().__init__(TitledTensorScalar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
