{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.progresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Resizing\n",
    "> Automatic progressive resizing of images during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ProgressiveResize` is inspired by MosaicML’s [Progressive Resizing algorithm for Composer](https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html) which in turn was inspired by [fastai’s](https://github.com/fastai/fastbook/blob/780b76bef3127ce5b64f8230fce60e915a7e0735/07_sizing_and_tta.ipynb) manual progressive resizing.\n",
    "\n",
    "![progressive resizing illustrated](images/progressive_resizing.png)\n",
    "\n",
    "Progressive Resizing decreases model training time by training on smaller images then gradually increasing to the full image size. This allows training on more samples for the same compute budget, often leading to higher performance then training on full sized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from fastcore.basics import detuplify, in_notebook\n",
    "from fastcore.transform import Pipeline\n",
    "\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.learner import _cast_tensor\n",
    "from fastai.vision.augment import AffineCoordTfm, RandomResizedCropGPU\n",
    "\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_resize_augs = (AffineCoordTfm, RandomResizedCropGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _to_size(t:Tensor):\n",
    "    \"Convert Tensor to size compatible values\"\n",
    "    if sum(t.shape)==2:\n",
    "        return tuple(t.tolist())\n",
    "    else:\n",
    "        return tuple(t.item(),t.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _num_steps(final_size, current_size, increase_by):\n",
    "    \"Convert Tensor to size compatible values\"\n",
    "    steps = (final_size - current_size) / increase_by\n",
    "    if sum(steps.shape)==2:\n",
    "        steps = steps[0].item()\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _evenly_divisible(final_size, current_size, increase_by, steps):\n",
    "    increase_by = tensor(increase_by)\n",
    "    return (((final_size-current_size) % increase_by).sum() == 0) and (((final_size-current_size) - (increase_by*steps)).sum() == 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProgressiveResize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class IncreaseMode(Enum):\n",
    "    \"Increase mode for `ProgressiveResize`\"\n",
    "    Epoch = 'epoch'\n",
    "    Batch = 'batch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressiveResize(Callback):\n",
    "    \"Progressively increase the size of input images during training. Starting from `initial_size` and ending at the valid image size or `final_size`.\"\n",
    "    order = MixedPrecision.order+1 # Needs to run after MixedPrecision\n",
    "    def __init__(self,\n",
    "        initial_size:float|tuple[int,int]=0.5, # Staring size to increase from. Image shape must be square\n",
    "        start:Numeric=0.5, # Earliest upsizing epoch in percent of training time or epoch (index 0)\n",
    "        finish:Numeric=0.75, # Last upsizing epoch in percent of training time or epoch (index 0)\n",
    "        increase_by:int=4, # Progressively increase image size by `increase_by`, or minimum increase per upsizing epoch\n",
    "        increase_mode:IncreaseMode=IncreaseMode.Batch, # Increase image size by training percent or before an epoch starts\n",
    "        resize_mode:str='bilinear', # PyTorch interpolate mode string for upsizing. Resets to existing fastai DataLoader mode at `final_size`.\n",
    "        resize_valid:bool=True, # Apply progressive resizing to valid dataset\n",
    "        final_size:tuple[int,int]|None=None, # Final image size. Set if using a non-fastai DataLoaders, automatically detected from fastai DataLoader with batch_tfms\n",
    "        add_resize:bool=False, # Add a separate resize step. Use for non-fastai DataLoaders or fastai DataLoader without batch_tfms\n",
    "        resize_targ:bool=False, # Applies the separate resize step to targets\n",
    "        empty_cache:bool=False, # Call `torch.cuda.empty_cache()` before a resizing epoch. May prevent Cuda & Magma errors. Don't use with multiple GPUs\n",
    "        verbose:bool=True, # Print a summary of the progressive resizing schedule\n",
    "        logger_callback:str='wandb', # Log image size to `logger_callback` using `Callback.name` if available\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.run_valid = resize_valid\n",
    "        if resize_targ and not add_resize:\n",
    "            warn(f'`resize_targ` requires `add_resize` set to True')\n",
    "        if empty_cache and increase_mode==IncreaseMode.Batch:\n",
    "            warn(f'`empty_cache` requires `increase_mode` set to Epoch')\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Sets up Progressive Resizing\"\n",
    "        if hasattr(self.learn, 'lr_finder') or hasattr(self.learn, \"gather_preds\"):\n",
    "            self.run = False\n",
    "            return\n",
    "\n",
    "        self._resize, self._remove_resize, self._null_resize, self._remove_cutmix = [], False, True, False\n",
    "        self._log_size = getattr(self, f'_{self.logger_callback}_log_size', noop)\n",
    "        self.has_logger = hasattr(self.learn, self.logger_callback) and self._log_size != noop\n",
    "        self.increase_by = tensor(self.increase_by)\n",
    "        self.resize_batch = self.increase_mode == IncreaseMode.Batch\n",
    "\n",
    "        # Dry run at full resolution to pre-allocate memory\n",
    "        # See https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#pre-allocate-memory-in-case-of-variable-input-length\n",
    "        states = get_random_states()\n",
    "        path = self.path/self.model_dir\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        tmp_d = TemporaryDirectory(dir=path)\n",
    "        tmp_p = Path(tmp_d.name).stem\n",
    "        self.learn.save(f'{tmp_p}/_tmp')\n",
    "        try:\n",
    "            b = self.dls.valid.one_batch()\n",
    "            i = getattr(self.dls, 'n_inp', 1 if len(b)==1 else len(b)-1)\n",
    "            self.learn.xb, self.learn.yb = b[:i],b[i:]\n",
    "\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                self.learn.mixed_precision.autocast.__enter__()\n",
    "\n",
    "            self.learn.pred = self.learn.model(*_cast_tensor(self.learn.xb))\n",
    "            self.learn.loss = self.learn.loss_func(self.learn.pred, *_cast_tensor(self.learn.yb))\n",
    "\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                self.learn.mixed_precision.autocast.__exit__(None, None, None)\n",
    "\n",
    "            self.learn.loss.backward()\n",
    "            self.learn.opt.zero_grad()\n",
    "\n",
    "        finally:\n",
    "            self.learn.load(f'{tmp_p}/_tmp', with_opt=True)\n",
    "            tmp_d.cleanup()\n",
    "            set_random_states(**states)\n",
    "\n",
    "        # Try to automatically determine the input size\n",
    "        try:\n",
    "            for n in range(i):\n",
    "                x = detuplify(self.learn.xb[n])\n",
    "                if isinstance(x, TensorImageBase):\n",
    "                    self.final_size = x.shape[-2:]\n",
    "        finally:\n",
    "            if self.final_size is None:\n",
    "                raise ValueError(f'Could not determine image size from DataLoader. Set `final_size`: {self.final_size}')\n",
    "            self.final_size = tensor(self.final_size)\n",
    "            if self.final_size[0] != self.final_size[1]:\n",
    "                raise ValueError(f'`ProgressiveResize` does not support non-square images: `final_size` = {self.final_size.tolist()}')\n",
    "            if not self.resize_batch:\n",
    "                if self.final_size[0] % 2 != 0:\n",
    "                    raise ValueError(f\"In Epoch mode, input image size must be even: {self.final_size.tolist()}\")\n",
    "                if self.increase_by.item() % 2 != 0:\n",
    "                    raise ValueError(f\"In Epoch Mode, `increase_by` must be even: {self.increase_by}\")\n",
    "\n",
    "        # Set the initial size\n",
    "        if isinstance(self.initial_size, float):\n",
    "            self.current_size = (tensor(self.initial_size) * self.final_size).int()\n",
    "        elif isinstance(self.initial_size, tuple):\n",
    "            self.current_size = tensor(self.initial_size)\n",
    "\n",
    "        if self.resize_batch:\n",
    "            # Set when the progressive resizing step is applied in training percent\n",
    "            if self.start >= 1 and isinstance(self.start, int):\n",
    "                self.start = self.start/self.n_epoch\n",
    "            if self.finish >= 1 and isinstance(self.finish, int):\n",
    "                self.finish = self.finish/self.n_epoch\n",
    "            if self.start >= 1:\n",
    "                warn(f'ProgressiveResize start {self.start} is equal or greater than one and will not start in this training run')\n",
    "            if self.finish >= 1:\n",
    "                warn(f'ProgressiveResize finish {self.finish} is equal or greater than one and will not finish in this training run')\n",
    "            n_steps = ((self.final_size-self.current_size) / self.increase_by).int()\n",
    "            if sum(n_steps.shape)==2:\n",
    "                n_steps = n_steps[0].item()\n",
    "            pct = (self.finish - self.start) / (n_steps-1)\n",
    "            self.step_pcts = [self.start + pct*i for i in range(n_steps)]\n",
    "        else:\n",
    "            # Automatically determine the number of steps, increasing `increase_by` as needed\n",
    "            start_epoch  = int(self.n_epoch*self.start)  if isinstance(self.start, float)  else self.start\n",
    "            finish_epoch = int(self.n_epoch*self.finish) if isinstance(self.finish, float) else self.finish\n",
    "            max_steps = finish_epoch - start_epoch\n",
    "            count = 10000 # prevent infinite loop\n",
    "            steps = _num_steps(self.final_size, self.current_size, self.increase_by)\n",
    "            while ((steps > max_steps) or not _evenly_divisible(self.final_size, self.current_size, self.increase_by, steps)) and count > 0:\n",
    "                self.increase_by += 2\n",
    "                steps = _num_steps(self.final_size, self.current_size, self.increase_by)\n",
    "                count -= 1\n",
    "            n_steps = _num_steps(self.final_size, self.current_size, self.increase_by)\n",
    "\n",
    "            # Set when per epoch progressive resizing steps are applied\n",
    "            step_size = max(1, int(max_steps / n_steps))\n",
    "            start_epoch = finish_epoch - ((self.final_size-self.current_size) / self.increase_by)*step_size\n",
    "            if isinstance(start_epoch, torch.Tensor):\n",
    "                if sum(start_epoch.shape)==2: start_epoch = int(start_epoch[0].item())\n",
    "                else:                         start_epoch = int(start_epoch.item())\n",
    "            self.step_epochs = [i for i in range(start_epoch+step_size, finish_epoch+step_size, step_size)]\n",
    "\n",
    "\n",
    "        # Double check that the step size works\n",
    "        if not _evenly_divisible(self.final_size, self.current_size, self.increase_by, n_steps):\n",
    "            raise ValueError(f'Resize amount {self.final_size-self.current_size} not evenly divisible by `increase_by` {self.increase_by}')\n",
    "\n",
    "        if self.verbose:\n",
    "            if self.resize_batch:\n",
    "                msg = f'Progressively increase the initial image size of {self.current_size.tolist()} by {self.increase_by} '\\\n",
    "                      f'pixels every {pct*self.n_epoch:.4g} epochs for {len(self.step_pcts)} resizes. \\nStarting at epoch '\\\n",
    "                      f'{self.step_pcts[0]*self.n_epoch:.4g} and finishing at epoch {self.step_pcts[-1]*self.n_epoch:.4g} '\\\n",
    "                      f'for a final training size of {(self.current_size+(len(self.step_pcts))*self.increase_by).tolist()}.'\n",
    "            else:\n",
    "                msg = f'Progressively increase the initial image size of {self.current_size.tolist()} by {self.increase_by} '\\\n",
    "                      f'pixels every {step_size} epoch{\"s\" if step_size > 1 else \"\"} for {len(self.step_epochs)} resizes.\\nStarting '\\\n",
    "                      f'at epoch {start_epoch+step_size} and finishing at epoch {finish_epoch} for a final training size of '\\\n",
    "                      f'{(self.current_size+(len(self.step_epochs))*self.increase_by).tolist()}.'\n",
    "            print(msg) if in_notebook() else print('\\n' + msg + '\\n')\n",
    "\n",
    "        # If not `add_resize`, check for fastai Augmentation resizes to use\n",
    "        if not self.add_resize:\n",
    "            if hasattr(self.learn, 'cut_mix_up_augment'):\n",
    "                self._has_cutmixupaug = True\n",
    "                # Modify the `CutMixUpAugment` augmentation pipeline\n",
    "                self._process_pipeline(self.learn.cut_mix_up_augment._orig_pipe)\n",
    "\n",
    "                # If `CutMixUpAugment` has an Affine Transform for Augmentations then use it\n",
    "                if len(self._resize) > 0:\n",
    "                    # Check for pre-mixup augment pipeline and modify it\n",
    "                    if self.learn.cut_mix_up_augment._docutmixaug:\n",
    "                        self._process_pipeline(self.learn.cut_mix_up_augment._cutmixaugs_pipe)\n",
    "                        self.learn.cut_mix_up_augment._size = _to_size(self.current_size)\n",
    "                    else:\n",
    "                        # There isn't one, then add it a pre-mixup augment pipeline for resizing\n",
    "                        self.learn.cut_mix_up_augment._cutmixaugs_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size)))\n",
    "                        self.learn.cut_mix_up_augment._docutmixaug = True\n",
    "                        self.learn.cut_mix_up_augment._size = _to_size(self.current_size)\n",
    "                        self._resize.append(self.learn.cut_mix_up_augment._cutmixaugs_pipe[0])\n",
    "                        self._remove_cutmix, self._remove_resize = True, True\n",
    "            else:\n",
    "                self._has_cutmixupaug = False\n",
    "                # If no `CutMixUpAugment` check the train dataloader pipeline for Affine Transforms\n",
    "                self._process_pipeline(self.dls.train.after_batch.fs)\n",
    "\n",
    "            # If `resize_valid` check the valid dataloader pipeline for Affine Transforms\n",
    "            if self.resize_valid:\n",
    "                self._process_pipeline(self.dls.valid.after_batch.fs)\n",
    "\n",
    "        # If `add_resize` or missing a fastai Augmentation resize add a seperate resize\n",
    "        if self.add_resize or len(self._resize) == 0:\n",
    "            self._added_resize = partial(F.interpolate, mode=self.resize_mode, recompute_scale_factor=True)\n",
    "            self.add_resize, self._remove_resize = True, True\n",
    "\n",
    "        # Set created or detected resize to the first size and store original interpolation\n",
    "        self._orig_modes = []\n",
    "        for resize in self._resize:\n",
    "            resize.size = _to_size(self.current_size)\n",
    "            self._orig_modes.append(resize.mode)\n",
    "            resize.mode = self.resize_mode\n",
    "\n",
    "    def before_batch(self):\n",
    "        \"Increases the image size before a batch if set to ProgSizeMode.Batch and applies optional additional resize\"\n",
    "        if self.training and self.resize_batch and len(self.step_pcts) > 0 and self.pct_train >= self.step_pcts[0]:\n",
    "            _ = self.step_pcts.pop(0)\n",
    "            self._increase_size()\n",
    "        if self.add_resize:\n",
    "            self.learn.xb = (self._added_resize(self.x, scale_factor=(self.current_size/self.final_size)[0]),)\n",
    "            if self.resize_targ:\n",
    "                self.learn.yb = (self._added_resize(self.y, scale_factor=(self.current_size/self.final_size)[0]),)\n",
    "\n",
    "    def before_train(self):\n",
    "        \"Increases the image size before the training epoch if set to ProgSizeMode.Epoch\"\n",
    "        if self.epoch==0 and self.has_logger:\n",
    "            self._log_size(False)\n",
    "\n",
    "        if not self.resize_batch and len(self.step_epochs) > 0 and self.epoch >= self.step_epochs[0]:\n",
    "            _ = self.step_epochs.pop(0)\n",
    "            self._increase_size()\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Calls `torch.cuda.empty_cache()` if `empty_cache=True` before a resizing epoch if set to ProgSizeMode.Epoch. May slightly increase single GPU training speed.\"\n",
    "        if not self.resize_batch and self.empty_cache and len(self.step_epochs) > 0 and self.epoch+1 >= self.step_epochs[0]:\n",
    "            del self.learn.xb\n",
    "            del self.learn.yb\n",
    "            del self.learn.pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if self.epoch+1==self.n_epoch and self.has_logger:\n",
    "            self._log_size(False)\n",
    "\n",
    "    def _increase_size(self):\n",
    "        \"Increase the input size\"\n",
    "        if self.has_logger:\n",
    "            self._log_size(False)\n",
    "\n",
    "        self.current_size += self.increase_by\n",
    "        for i, resize in enumerate(self._resize):\n",
    "            if (self.current_size < self.final_size).all():\n",
    "                resize.size = _to_size(self.current_size)\n",
    "                if self._has_cutmixupaug:\n",
    "                    self.learn.cut_mix_up_augment._size = _to_size(self.current_size)\n",
    "            else:\n",
    "                # Reset everything after progressive resizing is done\n",
    "                if self._null_resize:\n",
    "                    resize.size = None\n",
    "                    if self._has_cutmixupaug:\n",
    "                        self.learn.cut_mix_up_augment._size = None\n",
    "                else:\n",
    "                    resize.size = _to_size(self.current_size)\n",
    "                    resize.mode = self._orig_modes[i]\n",
    "\n",
    "        if (self.current_size == self.final_size).all() and self._remove_resize:\n",
    "                self.add_resize = False\n",
    "                if self._remove_cutmix:\n",
    "                    self.learn.cut_mix_up_augment._cutmixaugs_pipe = Pipeline([])\n",
    "                    self.learn.cut_mix_up_augment._docutmixaug = False\n",
    "\n",
    "        if self.has_logger:\n",
    "            self._log_size()\n",
    "\n",
    "    def _process_pipeline(self, pipe, null_resize=None):\n",
    "        'Helper method for processing augmentation pipelines'\n",
    "        for p in pipe:\n",
    "            if isinstance(p, _resize_augs):\n",
    "                self._resize.append(p)\n",
    "                if null_resize is None:\n",
    "                    self._null_resize = self._null_resize and p.size is None\n",
    "                else:\n",
    "                    self._null_resize = null_resize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progressive Resizing initially trains on downsampled images then gradually increases the image size over to the full size for the remainder of training. \n",
    "\n",
    "This can significantly reduce training time at the possible expense of lower model performance. However, Progressive Resizing allows training on more samples within the same compute budget, usually leading to increased performance. \n",
    "\n",
    "The model must be capable of variable image sizes.\n",
    "\n",
    "::: {.callout-important collapse='false'}\n",
    "#### Important: Dataloader Bottleneck\n",
    "<code>ProgressiveResize</code> should increase GPU throughput which may cause other parts of the training pipeline become a bottleneck.\n",
    "\n",
    "An easy way to increase fastai’s DataLoader throughput is by [replacing Pillow with Pillow-SIMD](https://docs.fast.ai/dev/performance.html#pillow-simd).\n",
    ":::\n",
    "\n",
    "When testing Composer's [Progressive Resizing](https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html) callback MosiacML [found]( https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html#technical-details):\n",
    "\n",
    "> In our experiments, Progressive Resizing improves the attainable tradeoffs between training speed and the final quality of the trained model. In some cases, it leads to slightly lower quality than the original model for the same number of training steps. However, Progressive Resizing increases training speed so much (via improved throughput during the early part of training) that it is possible to train for more steps, recover accuracy, and still complete training in less time.\n",
    "\n",
    "`ProgressiveResize` modifies the fastai batch augmentation pipeline by changing the `batch_tfms` size during training. Specifically, it modifies `AffineCoordTfm` size, which is set by any rotate, warp, or resize batch augmentation, and/or `RandomResizedCropGPU` size. This modification prevents unnecessarily resizing images a second time on the GPU, speeding up the process. If there are no `batch_tfms` or if training with a non-fastai DataLoader, set `add_resize=True` to resize the batch on the GPU using PyTorch’s `interpolate`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progressive Resizing works best when the resize steps are spread out over a significant portion of the dataset.\n",
    "\n",
    "::: {.callout-tip collapse='false'}\n",
    "#### Tip: Progressive Resizing & Small Datasets\n",
    "If training small datasets with <code>ProgressiveResize</code>, such as [Imagenette](https://github.com/fastai/imagenette), scale the batch mode increase amount to be larger than the default of 4 by setting `increase_by` to a custom value.\n",
    "\n",
    "In the [example section](#example), `increase_by=16` gives good results for training Imagenette for 20-25 epochs.\n",
    ":::\n",
    "\n",
    "`ProgressiveResize` fully compatible with `CutMixUpAugment`.\n",
    "\n",
    "::: {.callout-note collapse='true'}\n",
    "#### Note: Older Versions of PyTorch\n",
    "If training on older versions of PyTorch with <code>ProgressiveResize</code> results in CUDA or Magma errors, try setting <code>increase_mode=IncreaseMode.Epoch</code> and <code>empty_cache=True</code>.\n",
    "\n",
    "This will upsize once per epoch and call <code>torch.cuda.empty_cache()</code> before a resizing epoch. <code>empty_cache=True</code> may interfere with training multiple models on multi-GPU systems.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastxtend.test_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "class SyncthProgResizeTest(Callback):\n",
    "    order = ProgressiveResize.order+1\n",
    "    def __init__(self, final_size, start_size, increase, step_size, first_epoch, last_epoch, total_resizes):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit(self):\n",
    "        prog = self.learn.progressive_resize\n",
    "        if isinstance(self.start_size, tuple):\n",
    "            assert torch.equal(prog.current_size, tensor(self.start_size).int())\n",
    "        else:\n",
    "            assert torch.equal(prog.current_size, tensor([self.start_size,self.start_size]).int())\n",
    "        assert prog.increase_by==self.increase\n",
    "        assert prog.step_epochs[1]-prog.step_epochs[0]==self.step_size\n",
    "        assert prog.step_epochs[0]==self.first_epoch\n",
    "        assert prog.step_epochs[-1]==self.last_epoch\n",
    "        assert len(prog.step_epochs)==self.total_resizes\n",
    "        size = self.start_size\n",
    "        for i in prog.step_epochs:\n",
    "            size += self.increase\n",
    "        assert size==self.final_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [128, 128] by 32 pixels every 1 epoch for 4 resizes.\n",
      "Starting at epoch 12 and finishing at epoch 15 for a final training size of [256, 256].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(final_size=256, start_size=128, increase=32, step_size=1, first_epoch=12, last_epoch=15, total_resizes=4)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(final_size=[256,256], increase_mode=IncreaseMode.Epoch), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=20\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [128, 128] by 8 pixels every 1 epoch for 16 resizes.\n",
      "Starting at epoch 34 and finishing at epoch 49 for a final training size of [256, 256].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(final_size=256, start_size=128, increase=8, step_size=1, first_epoch=34, last_epoch=49, total_resizes=16)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(final_size=[256,256], increase_mode=IncreaseMode.Epoch), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=66\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [192, 192] by 6 pixels every 2 epochs for 32 resizes.\n",
      "Starting at epoch 163 and finishing at epoch 225 for a final training size of [384, 384].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(final_size=384, start_size=192, increase=6, step_size=2, first_epoch=163, last_epoch=225, total_resizes=32)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(final_size=[384,384], increase_by=6, increase_mode=IncreaseMode.Epoch), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=300\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [192, 192] by 8 pixels every 3 epochs for 24 resizes.\n",
      "Starting at epoch 156 and finishing at epoch 225 for a final training size of [384, 384].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(final_size=384, start_size=192, increase=8, step_size=3, first_epoch=156, last_epoch=225, total_resizes=24)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(final_size=[384,384], increase_by=8, increase_mode=IncreaseMode.Epoch), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=300\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [128, 128] by 4 pixels every 0.6452 epochs for 32 resizes. \n",
      "Starting at epoch 40 and finishing at epoch 60 for a final training size of [256, 256].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "learn = synth_learner(cbs=[ProgressiveResize(final_size=[256,256], increase_by=4, increase_mode=IncreaseMode.Batch)])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=80\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [192, 192] by 4 pixels every 1.596 epochs for 48 resizes. \n",
      "Starting at epoch 150 and finishing at epoch 225 for a final training size of [384, 384].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "learn = synth_learner(cbs=[ProgressiveResize(final_size=[384,384], increase_by=4, increase_mode=IncreaseMode.Batch)])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=300\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "import time\n",
    "from packaging.version import parse\n",
    "import fastai\n",
    "\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "if parse(fastai.__version__) < parse('2.7.11'):\n",
    "    from fastxtend.callback.channelslast import *\n",
    "else:\n",
    "    from fastai.callback.channelslast import *\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.learner import Learner\n",
    "from fastai.vision.augment import Resize, aug_transforms\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models import resnet50, resnet34\n",
    "from fastxtend.callback.cutmixup import CutMixUpAugment\n",
    "from fastxtend.metrics import *\n",
    "from fastxtend.optimizer.fused import adam, ranger\n",
    "from fastxtend.vision.models.xresnet import xresnext50\n",
    "from fastxtend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "free_gpu_memory(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "class ProgressiveResizeTest(Callback):\n",
    "    run_valid, order = True, ProgressiveResize.order-1\n",
    "\n",
    "    def before_train(self):\n",
    "        self.progsize = self.learn.progressive_resize.current_size\n",
    "\n",
    "    def before_batch(self):\n",
    "        assert L(self.x.shape[-2:]) == L(self.progsize.tolist())\n",
    "\n",
    "    def after_batch(self):\n",
    "        self.progsize = self.learn.progressive_resize.current_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [64, 64] by 16 pixels every 0.08333 epochs for 4 resizes. \n",
      "Starting at epoch 0.5 and finishing at epoch 0.75 for a final training size of [128, 128].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.809523</td>\n",
       "      <td>1.559901</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    cbs=[ProgressiveResize(increase_by=16), ProgressiveResizeTest]\n",
    "    learn = Learner(dls, resnet34(num_classes=dls.c), opt_func=adam(foreach=True), cbs=cbs).to_channelslast()\n",
    "    learn.fit_one_cycle(1, 3e-3)\n",
    "    free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [64, 64] by 64 pixels every 1 epoch for 1 resizes.\n",
      "Starting at epoch 2 and finishing at epoch 2 for a final training size of [128, 128].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.933080</td>\n",
       "      <td>1.900782</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.563433</td>\n",
       "      <td>1.386105</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.221522</td>\n",
       "      <td>1.025261</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    cbs=[ProgressiveResize(increase_mode=IncreaseMode.Epoch), ProgressiveResizeTest]\n",
    "    learn = Learner(dls, resnet34(num_classes=dls.c), opt_func=adam(foreach=True), cbs=cbs).to_channelslast()\n",
    "    learn.fit_one_cycle(3, 3e-3)\n",
    "    free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [64, 64] by 16 pixels every 0.08333 epochs for 4 resizes. \n",
      "Starting at epoch 0.5 and finishing at epoch 0.75 for a final training size of [128, 128].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.347264</td>\n",
       "      <td>3.078582</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [64, 64] by 16 pixels every 0.08333 epochs for 4 resizes. \n",
      "Starting at epoch 0.5 and finishing at epoch 0.75 for a final training size of [128, 128].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.803510</td>\n",
       "      <td>1.596348</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    cbs=[ProgressiveResize(increase_by=16), ProgressiveResizeTest, CutMixUpAugment]\n",
    "    learn = Learner(dls, resnet34(num_classes=dls.c), opt_func=adam(foreach=True), cbs=cbs).to_channelslast()\n",
    "    learn.fine_tune(1, 3e-3)\n",
    "    free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [64, 64] by 16 pixels every 0.08333 epochs for 4 resizes. \n",
      "Starting at epoch 0.5 and finishing at epoch 0.75 for a final training size of [128, 128].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.346271</td>\n",
       "      <td>3.759643</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [64, 64] by 16 pixels every 0.08333 epochs for 4 resizes. \n",
      "Starting at epoch 0.5 and finishing at epoch 0.75 for a final training size of [128, 128].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.806576</td>\n",
       "      <td>1.609734</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_160)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(128),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls = dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    cbs=[ProgressiveResize(increase_by=16), ProgressiveResizeTest,\n",
    "         CutMixUpAugment(cutmixup_augs=aug_transforms(max_rotate=45))]\n",
    "    learn = Learner(dls, resnet34(num_classes=dls.c), opt_func=adam(foreach=True), cbs=cbs).to_channelslast()\n",
    "    learn.fine_tune(1, 3e-3)\n",
    "    free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example[^details], a `xresnext50` is trained for 20 & 25 epochs on [Imagenette](https://github.com/fastai/imagenette) at an image size of 224 pixels. Due to the short training run and small dataset, `ProgressiveResize` in batch mode is set to `increase_by=16`.\n",
    "\n",
    "<code>ProgressiveResize</code> yields significant training time savings compared to training at full size. At a normalized compute budget of roughly 6.5 minutes, Progressive Resizing results with 92.7% accuracy compared to 92% accuracy with full sized training.\n",
    "\n",
    "| Mode              | Epochs | Time (Mins) | Accuracy |\n",
    "|:----------------- |:------:|:-----------:|:--------:|\n",
    "| Full Size         | 20     | 6.5         | 92.0%    |\n",
    "| Progressive Batch | 20     | 5.2         | 92.3%    |\n",
    "| Progressive Epoch | 20     | 5.2         | 91.8%    |\n",
    "| Progressive Batch | 25     | 6.5         | 92.7%    |\n",
    "\n",
    "Due to the regularization effect of training on different sized images, Progressive Resizing with `increase_by=16` outperforms full sized training by 0.3% in 25 percent less timeon the same number of epochs[^result] .\n",
    "\n",
    "[^details]: All models are trained on a GeForce 3080 Ti using PyTorch 1.13.1 and Cuda 11.7. Results may differ with other datasets, hardware, and across runs.\n",
    "\n",
    "[^result]: While Progressive Resizing can sometimes outperform full sized trained model in the same number of epochs, it is just as likely to perform worse, depending on setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "free_gpu_memory(learn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Resizing\n",
    "\n",
    "There are two Progressive Resizing `IncreaseMode`:\n",
    "\n",
    "- `increase_mode=IncreaseMode.Batch`\n",
    "- `increase_mode=IncreaseMode.Epoch`\n",
    "\n",
    "this example will show both.\n",
    "\n",
    "#### Batch Resizing\n",
    "\n",
    "`ProgressiveResize` with the default `increase_mode=IncreaseMode.Batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [112, 112] by 16 pixels every 0.8333 epochs for 7 resizes. \n",
      "Starting at epoch 10 and finishing at epoch 15 for a final training size of [224, 224].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.670977</td>\n",
       "      <td>1.883999</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.226364</td>\n",
       "      <td>0.710573</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.251599</td>\n",
       "      <td>1.446574</td>\n",
       "      <td>0.626497</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.136825</td>\n",
       "      <td>1.079901</td>\n",
       "      <td>0.768662</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062239</td>\n",
       "      <td>1.250891</td>\n",
       "      <td>0.718981</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.006945</td>\n",
       "      <td>0.955187</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.957047</td>\n",
       "      <td>1.238453</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.910177</td>\n",
       "      <td>0.900485</td>\n",
       "      <td>0.842548</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.889880</td>\n",
       "      <td>0.963289</td>\n",
       "      <td>0.816560</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.860453</td>\n",
       "      <td>0.881689</td>\n",
       "      <td>0.849936</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.839035</td>\n",
       "      <td>0.952776</td>\n",
       "      <td>0.828535</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.857969</td>\n",
       "      <td>0.863439</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.791430</td>\n",
       "      <td>0.863359</td>\n",
       "      <td>0.858089</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.770404</td>\n",
       "      <td>0.786469</td>\n",
       "      <td>0.887898</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>0.848503</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.745845</td>\n",
       "      <td>0.774377</td>\n",
       "      <td>0.890955</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.769880</td>\n",
       "      <td>0.891974</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.640226</td>\n",
       "      <td>0.731178</td>\n",
       "      <td>0.914395</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.604006</td>\n",
       "      <td>0.706209</td>\n",
       "      <td>0.920764</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.584977</td>\n",
       "      <td>0.698062</td>\n",
       "      <td>0.922548</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 311.8 s\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                       splitter=GrandparentSplitter(valid_name='val'),\n",
    "                       get_items=get_image_files, get_y=parent_label,\n",
    "                       item_tfms=Resize(224),\n",
    "                       batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = Learner(dls, xresnext50(n_out=dls.c), loss_func=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                    opt_func=ranger(foreach=True), metrics=Accuracy()).to_channelslast()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    learn.fit_flat_cos(20, 8e-3, cbs=ProgressiveResize(increase_by=16))\n",
    "    total = time.perf_counter() - start\n",
    "    print(f'Total training time: {scale_time(total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch Resizing\n",
    "\n",
    "`ProgressiveResize` with `increase_mode=IncreaseMode.Epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [112, 112] by 28 pixels every 1 epoch for 4 resizes.\n",
      "Starting at epoch 12 and finishing at epoch 15 for a final training size of [224, 224].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.670977</td>\n",
       "      <td>1.883999</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.226364</td>\n",
       "      <td>0.710573</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.251599</td>\n",
       "      <td>1.446574</td>\n",
       "      <td>0.626497</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.136825</td>\n",
       "      <td>1.079901</td>\n",
       "      <td>0.768662</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062239</td>\n",
       "      <td>1.250891</td>\n",
       "      <td>0.718981</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.006945</td>\n",
       "      <td>0.955187</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.957047</td>\n",
       "      <td>1.238453</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.910177</td>\n",
       "      <td>0.900485</td>\n",
       "      <td>0.842548</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.889880</td>\n",
       "      <td>0.963289</td>\n",
       "      <td>0.816560</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.860453</td>\n",
       "      <td>0.881689</td>\n",
       "      <td>0.849936</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.839285</td>\n",
       "      <td>0.916867</td>\n",
       "      <td>0.835159</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.817720</td>\n",
       "      <td>0.837916</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.792356</td>\n",
       "      <td>0.844864</td>\n",
       "      <td>0.869045</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.780980</td>\n",
       "      <td>0.811714</td>\n",
       "      <td>0.878471</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.780541</td>\n",
       "      <td>0.870851</td>\n",
       "      <td>0.853758</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.766215</td>\n",
       "      <td>0.788430</td>\n",
       "      <td>0.888153</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.709244</td>\n",
       "      <td>0.788267</td>\n",
       "      <td>0.887134</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.649643</td>\n",
       "      <td>0.732368</td>\n",
       "      <td>0.915159</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.611495</td>\n",
       "      <td>0.717171</td>\n",
       "      <td>0.915414</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.708605</td>\n",
       "      <td>0.918471</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 309.3 s\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = Learner(dls, xresnext50(n_out=dls.c), loss_func=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                    opt_func=ranger(foreach=True), metrics=Accuracy()).to_channelslast()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    learn.fit_flat_cos(20, 8e-3, cbs=ProgressiveResize(increase_mode=IncreaseMode.Epoch))\n",
    "    total = time.perf_counter() - start\n",
    "    print(f'Total training time: {scale_time(total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Training\n",
    "\n",
    "fastai model training without Progressive Resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.693837</td>\n",
       "      <td>1.660484</td>\n",
       "      <td>0.539873</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.425402</td>\n",
       "      <td>1.288508</td>\n",
       "      <td>0.682548</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.249855</td>\n",
       "      <td>1.231204</td>\n",
       "      <td>0.726879</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.107746</td>\n",
       "      <td>1.027718</td>\n",
       "      <td>0.794904</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.046856</td>\n",
       "      <td>1.113385</td>\n",
       "      <td>0.782420</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.974740</td>\n",
       "      <td>1.055205</td>\n",
       "      <td>0.800255</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.933220</td>\n",
       "      <td>1.195850</td>\n",
       "      <td>0.756688</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.880307</td>\n",
       "      <td>0.905752</td>\n",
       "      <td>0.845096</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.854195</td>\n",
       "      <td>1.113956</td>\n",
       "      <td>0.772229</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.839854</td>\n",
       "      <td>0.838828</td>\n",
       "      <td>0.868790</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.815095</td>\n",
       "      <td>0.868798</td>\n",
       "      <td>0.861146</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.839955</td>\n",
       "      <td>0.867771</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.763221</td>\n",
       "      <td>0.884713</td>\n",
       "      <td>0.853758</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>0.780010</td>\n",
       "      <td>0.890955</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.740009</td>\n",
       "      <td>0.835440</td>\n",
       "      <td>0.872102</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.710022</td>\n",
       "      <td>0.793270</td>\n",
       "      <td>0.888408</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.683471</td>\n",
       "      <td>0.743397</td>\n",
       "      <td>0.909809</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.630301</td>\n",
       "      <td>0.735851</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.596394</td>\n",
       "      <td>0.715150</td>\n",
       "      <td>0.916688</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.577142</td>\n",
       "      <td>0.701738</td>\n",
       "      <td>0.918981</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 387.2 s\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                       splitter=GrandparentSplitter(valid_name='val'),\n",
    "                       get_items=get_image_files, get_y=parent_label,\n",
    "                       item_tfms=Resize(224),\n",
    "                       batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = Learner(dls, xresnext50(n_out=dls.c), loss_func=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                    opt_func=ranger(foreach=True), metrics=Accuracy()).to_channelslast()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    learn.fit_flat_cos(20, 8e-3)\n",
    "    total = time.perf_counter() - start\n",
    "    print(f'Total training time: {scale_time(total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Resizing with Normalized Compute Budget\n",
    "\n",
    "`ProgressiveResize` with the default `increase_mode=IncreaseMode.Batch` trained to match the [Normal Training's](#normal-training) compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [112, 112] by 16 pixels every 1.042 epochs for 7 resizes. \n",
      "Starting at epoch 12.5 and finishing at epoch 18.75 for a final training size of [224, 224].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.670977</td>\n",
       "      <td>1.883999</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.403678</td>\n",
       "      <td>1.226364</td>\n",
       "      <td>0.710573</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.251599</td>\n",
       "      <td>1.446574</td>\n",
       "      <td>0.626497</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.136825</td>\n",
       "      <td>1.079901</td>\n",
       "      <td>0.768662</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062239</td>\n",
       "      <td>1.250891</td>\n",
       "      <td>0.718981</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.006945</td>\n",
       "      <td>0.955187</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.957047</td>\n",
       "      <td>1.238453</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.910177</td>\n",
       "      <td>0.900485</td>\n",
       "      <td>0.842548</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.889880</td>\n",
       "      <td>0.963289</td>\n",
       "      <td>0.816560</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.860453</td>\n",
       "      <td>0.881689</td>\n",
       "      <td>0.849936</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.839285</td>\n",
       "      <td>0.916867</td>\n",
       "      <td>0.835159</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.817720</td>\n",
       "      <td>0.837916</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.806093</td>\n",
       "      <td>0.869887</td>\n",
       "      <td>0.850701</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.780977</td>\n",
       "      <td>0.805412</td>\n",
       "      <td>0.877962</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.766974</td>\n",
       "      <td>0.899283</td>\n",
       "      <td>0.839490</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.757296</td>\n",
       "      <td>0.811422</td>\n",
       "      <td>0.878726</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.736302</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0.853758</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.723357</td>\n",
       "      <td>0.769306</td>\n",
       "      <td>0.901401</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.714021</td>\n",
       "      <td>0.765733</td>\n",
       "      <td>0.895287</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.697444</td>\n",
       "      <td>0.736115</td>\n",
       "      <td>0.911847</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.663537</td>\n",
       "      <td>0.790711</td>\n",
       "      <td>0.881783</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.617896</td>\n",
       "      <td>0.712593</td>\n",
       "      <td>0.919745</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.583567</td>\n",
       "      <td>0.710089</td>\n",
       "      <td>0.918471</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.562689</td>\n",
       "      <td>0.685103</td>\n",
       "      <td>0.927643</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.551753</td>\n",
       "      <td>0.686037</td>\n",
       "      <td>0.926879</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 390.5 s\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                       splitter=GrandparentSplitter(valid_name='val'),\n",
    "                       get_items=get_image_files, get_y=parent_label,\n",
    "                       item_tfms=Resize(224),\n",
    "                       batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls =  dblock.dataloaders(imagenette, bs=64, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = Learner(dls, xresnext50(n_out=dls.c), loss_func=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "                    opt_func=ranger(foreach=True), metrics=Accuracy()).to_channelslast()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    learn.fit_flat_cos(25, 8e-3, cbs=ProgressiveResize(increase_by=16))\n",
    "    total = time.perf_counter() - start\n",
    "    print(f'Total training time: {scale_time(total)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights & Biases Logging\n",
    "\n",
    "If Weights & Biases is installed and the [`WandbCallback`](https://docs.fast.ai/callback.wandb.html) is added to `Learner`, Progressive Resizing will automatically log the current image size to Weights & Biases as `progressive_resize_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to other Loggers\n",
    "\n",
    "To extend to new loggers, follow the Weights & Biases code below and create patches for `ProgressiveResize` to add a `_{Callback.name}_log_size`, where `Callback.name` is the [name of the logger callback](https://docs.fast.ai/callback.core.html#Callback.name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_size(self:ProgressiveResize, next_step=True):\n",
    "        size = _to_size(self.current_size)\n",
    "        wandb.log({'progressive_resize_size': size[0]}, self.learn.wandb._wandb_step+int(next_step))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to use, pass `logger_callback='{Callback.name}'` to `ProgressiveResize`.\n",
    "\n",
    "`ProgressiveResize` sets its `_log_size` method to `f'_{self.logger_callback}_log_size'`, which should match the patched method.\n",
    "\n",
    "```python\n",
    "self._log_size = getattr(self, f'_{self.logger_callback}_log_size', noop)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
